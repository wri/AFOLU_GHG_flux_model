{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c44f117",
   "metadata": {},
   "source": [
    "<font size=\"6\">Reclassify GLCLU to basic IPCC classes and create change rasters</font> \n",
    "\n",
    "<font size=\"4\">Must be run using the utilities_and_variables.ipynb kernel</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f720e810-b37b-4b20-b8a5-e501b526e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reclassify GLCLU classes to basic IPCC reporting classes.\n",
    "# Operates on the array/chunk. \n",
    "# Classification comes from https://onewri-my.sharepoint.com/:p:/g/personal/david_gibbs_wri_org/EWwyxRfgdeVJi4ezwX7LrfcBjCoqAcjL2jRAZjb_8RU9LQ?e=YUsQiU\n",
    "def reclassify_to_IPCC(GLCLU_block):\n",
    "\n",
    "    # Outputs\n",
    "    IPCC_classes = np.zeros(GLCLU_block.shape)\n",
    "\n",
    "    IPCC_classes[np.where(GLCLU_block <= 1)] = otherland                                 \n",
    "    IPCC_classes[np.where((GLCLU_block >= 2) & (GLCLU_block <= 26))] = grassland          \n",
    "    IPCC_classes[np.where((GLCLU_block >= 27) & (GLCLU_block <= 48))] = forest         \n",
    "    IPCC_classes[np.where((GLCLU_block >= 100) & (GLCLU_block <= 101))] = wetland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 102) & (GLCLU_block <= 126))] = grassland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 127) & (GLCLU_block <= 148))] = forest       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 200) & (GLCLU_block <= 204))] = wetland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 205) & (GLCLU_block <= 207))] = otherland       \n",
    "    IPCC_classes[np.where(GLCLU_block == 241)] = otherland                                \n",
    "    IPCC_classes[np.where(GLCLU_block == 244)] = cropland                                \n",
    "    IPCC_classes[np.where(GLCLU_block == 250)] = settlement                               \n",
    "    IPCC_classes[np.where(GLCLU_block == 254)] = otherland                              \n",
    "    \n",
    "    return IPCC_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0070fd86-a857-445e-92e5-e9ba3dc99caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map basic IPCC change classes.\n",
    "# Operates pixel by pixel, so uses numba (Python compiled to C++).\n",
    "@jit(nopython=True)\n",
    "def change_classes_IPCC(IPCC_previous_block, IPCC_current_block):\n",
    "\n",
    "    # Output array of 0s\n",
    "    IPCC_change_block = np.zeros(IPCC_previous_block.shape)\n",
    "\n",
    "    # Iterates through all pixels in the chunk\n",
    "    for row in range(IPCC_previous_block.shape[0]):\n",
    "        for col in range(IPCC_previous_block.shape[1]):\n",
    "\n",
    "            IPCC_previous = IPCC_previous_block[row, col]\n",
    "            IPCC_current = IPCC_current_block[row, col]\n",
    "\n",
    "            # When land cover chunks have \"no data\"\n",
    "            if (IPCC_previous == 0) and (IPCC_current == 0):\n",
    "                IPCC_change_block[row, col] = 0\n",
    "\n",
    "            else:\n",
    "                # Equation to calculate the IPCC change code\n",
    "                IPCC_change_block[row, col] = ((IPCC_previous - 1) * IPCC_class_max_val) + IPCC_current\n",
    "\n",
    "    return IPCC_change_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b7027b3-48f8-4f73-8da4-5065bfcc60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads input chunks, reclassifies GLCLU classes into IPCC land use reporting classes for each year, and maps changes between classes for consecutive years.\n",
    "# Chunks are defined by a bounding box and a starting year for iteration\n",
    "def reclassify_and_map_change_chunk(bounds, is_final):\n",
    "\n",
    "    bounds_str = boundstr(bounds)    # String form of chunk bounds\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])    # tile_id in YYN/S_XXXE/W\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)   # Chunk length in pixels (as opposed to decimal degrees)\n",
    "\n",
    "    no_data_val = 255\n",
    "\n",
    "    \n",
    "    ### Part 1: download chunks and check for data\n",
    "\n",
    "    # Dictionary of downloaded layers\n",
    "    layers = {}\n",
    "\n",
    "    download_dict = {\n",
    "        \n",
    "        \"land_cover_2000\": f\"{composite_LC_uri}/2000/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2005\": f\"{composite_LC_uri}/2005/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2010\": f\"{composite_LC_uri}/2010/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2015\": f\"{composite_LC_uri}/2015/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2020\": f\"{composite_LC_uri}/2020/raw/{tile_id}.tif\"   \n",
    "    }\n",
    "\n",
    "    # Checks whether tile exists at all. Doesn't try to download chunk if the tile doesn't exist.\n",
    "    tile_exists = check_for_tile(download_dict)\n",
    "\n",
    "    if tile_exists == 0:\n",
    "        return\n",
    "\n",
    "    futures = prepare_to_download_chunk(bounds, download_dict, no_data_val)\n",
    "\n",
    "    if not is_final:\n",
    "        dask_print(f\"Waiting for requests for data in chunk {bounds_str} in {tile_id}: {timestr()}\")\n",
    "    \n",
    "    # Waits for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layer = futures[future]\n",
    "        layers[layer] = future.result()\n",
    "\n",
    "    # Checks chunk for data. Skips the chunk if it has no data in it.\n",
    "    data_in_chunk = check_chunk_for_data(layers, \"land_cover_\", bounds_str, tile_id, no_data_val)\n",
    "\n",
    "    if data_in_chunk == 0:\n",
    "        return\n",
    "\n",
    "   \n",
    "    ### Part 2: reclassify GLCLU classes into IPCC reporting classes \n",
    "    IPCC_class_dict = {}\n",
    "\n",
    "    # Iterates through model years\n",
    "    for year in list(range(first_year, last_year+1, 5)):\n",
    "        \n",
    "        dask_print(f\"Reclassifying {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "\n",
    "        # Reclassifies GLCLU to 6 IPCC classes \n",
    "        IPCC_classes = reclassify_to_IPCC(\n",
    "            layers[f\"land_cover_{year}\"]   \n",
    "        )\n",
    "\n",
    "        # Output arrays to upload to s3. Adds new array to dictionary for each year\n",
    "        IPCC_class_dict[f\"IPCC_classes_{year}\"] = [IPCC_classes, \"uint8\", \"IPCC_basic_classes\", year]                 \n",
    "    \n",
    "    save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, bounds_str, IPCC_class_dict, is_final)\n",
    "\n",
    "    \n",
    "    ### Part 3\n",
    "    IPCC_change_dict = {}\n",
    "\n",
    "    # Iterates through model years in a way that change can be calculated\n",
    "    for year in list(range(first_year+5, last_year+1, 5)):\n",
    "        \n",
    "        dask_print(f\"Getting IPCC class change in {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "\n",
    "        # Maps change between IPCC classes\n",
    "        IPCC_change = change_classes_IPCC(\n",
    "            IPCC_class_dict[f\"IPCC_classes_{year-5}\"][0], # first [0] needed because results_download is a tuple with a dictionary inside it. Second [0] to isolate the array.\n",
    "            IPCC_class_dict[f\"IPCC_classes_{year}\"][0]    # first [0] needed because results_download is a tuple with a dictionary inside it. Second [0] to isolate the array.\n",
    "        )\n",
    "\n",
    "        # Output files to upload to s3\n",
    "        IPCC_change_dict[f\"IPCC_change_{year-5}_{year}\"] = [IPCC_change, \"uint8\", \"IPCC_basic_change\", f'{year-5}_{year}']  \n",
    "\n",
    "    save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, bounds_str, IPCC_change_dict, is_final)\n",
    "\n",
    "    \n",
    "    # Clear memory of unneeded arrays\n",
    "    del IPCC_classes\n",
    "    del IPCC_class_dict\n",
    "    del IPCC_change\n",
    "    del IPCC_change_dict\n",
    "\n",
    "    return f\"Success for {bounds_str}: {timestr()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157f4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 chunks\n",
      "Tile id 50N_010E exists. Proceeding.\n",
      "Requesting data in chunk 10_50_10_50 in 50N_010E: 20240228_18_37_51\n",
      "Waiting for requests for data in chunk 10_50_10_50 in 50N_010E: 20240228_18_38_04\n",
      "Data in chunk 10_50_10_50. Proceeding.\n",
      "{'land_cover_2020': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 250, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 41,  44,  45, ..., 244, 244, 244],\n",
      "       [ 42,  42,  43, ..., 244, 244, 244],\n",
      "       [ 43,  45,  43, ..., 244, 244, 244]], dtype=uint8), 'land_cover_2010': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 44,  43,  44, ..., 244, 244, 244],\n",
      "       [ 42,  44,  44, ..., 244, 244, 244],\n",
      "       [ 45,  45,  46, ..., 244, 244, 244]], dtype=uint8), 'land_cover_2000': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 47,  46,  47, ..., 244, 244, 244],\n",
      "       [ 42,  43,  47, ..., 244, 244, 244],\n",
      "       [ 46,  45,  46, ..., 244, 244, 244]], dtype=uint8), 'land_cover_2015': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 250, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 41,  45,  46, ..., 244, 244, 244],\n",
      "       [ 42,  43,  44, ..., 244, 244, 244],\n",
      "       [ 42,  43,  45, ..., 244, 244, 244]], dtype=uint8), 'land_cover_2005': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 44,  41,  44, ..., 244, 244, 244],\n",
      "       [ 42,  44,  44, ..., 244, 244, 244],\n",
      "       [ 42,  45,  46, ..., 244, 244, 244]], dtype=uint8)}\n",
      "CPU times: user 2.19 s, sys: 378 ms, total: 2.56 s\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Success for 10_50_10_50: 20240228_18_38_04',)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Create IPCC single-year class and change 2x2 deg rasters \n",
    "\n",
    "## Area to analyze\n",
    "## chunk_params arguments: W, S, E, N, chunk size (degrees)\n",
    "# chunk_params = [-180, -60, 180, 80, 2]  # entire world\n",
    "# chunk_params = [-10, 40, 20, 70, 1]    # 30x30 deg (70N_010W), 900 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 2]    # 10x10 deg (50N_010E), 25 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 10]    # 10x10 deg (50N_010E), 1 chunk\n",
    "# chunk_params = [10, 46, 14, 50, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [110, -10, 114, -6, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [10, 48, 12, 50, 1]   # 2x2 deg, 4 chunks\n",
    "# chunk_params = [10, 49, 11, 50, 1]   # 1x1 deg, 1 chunk\n",
    "# chunk_params = [10, 49, 11, 50, 0.5] # 1x1 deg, 4 chunks\n",
    "# chunk_params = [10, 49.5, 10.5, 50, 0.25] # 0.5x0.5 deg, 4 chunks\n",
    "# chunk_params = [10, 42, 11, 43, 0.5] # 1x1 deg, 4 chunks (some GLCLU code=254 for ocean and some land, so data should be output)\n",
    "chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk (has data)\n",
    "\n",
    "# # Range of no-data cases for testing\n",
    "# chunk_params = [110, -10, 120, 0, 2]    # 10x10 deg (00N_110E), 25 chunks (all chunks have land and should be output)\n",
    "# chunk_params = [110, -20, 120, -10, 2]    # 10x10 deg (00N_110E), 25 chunks (all chunks have land and should be output)\n",
    "# chunk_params = [0, 79.75, 0.25, 80, 0.25] # 0.25x0.25 deg, 1 chunk (no 80N_000E tile-- no data)\n",
    "# chunk_params = [112, -12, 116, -8, 2]   # 2x2 deg, 1 chunk (bottom of Java, has data but mostly ocean)\n",
    "# chunk_params = [10.875, 41.75, 11, 42, 0.25] # 0.25x0.25 deg, 1 chunk (entirely GLCLU code=255 for ocean, so no actual data-- nothing should be be output)\n",
    "# chunk_params = [-10, 21.75, -9.75, 22, 0.25] # 0.25x0.25 deg, 1 chunk (has data but entirely desert (fully GLCLU code=0))\n",
    "# chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk (has data)\n",
    "\n",
    "\n",
    "# Makes list of chunks to analyze\n",
    "chunks = get_chunk_bounds(chunk_params)  \n",
    "print(\"Processing\", len(chunks), \"chunks\")\n",
    "\n",
    "# Determines if the output file names for final versions of outputs should be used\n",
    "is_final = False\n",
    "if len(chunks) > 30:\n",
    "    is_final = True\n",
    "    print(\"Running as final model.\")\n",
    "\n",
    "# Creates list of tasks to run (1 task = 1 chunk for all years)\n",
    "delayed_result = [dask.delayed(reclassify_and_map_change_chunk)(chunk, is_final) for chunk in chunks]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c322828-5e41-4706-a9df-09c9e5cafcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Create raster footprint shapefiles from listed rasters\n",
    "## Doesn't use memory. Can be done on 4 GB workers. Only need as many workers as there are folders. \n",
    "\n",
    "# Folders to process and the corresponding output shapefile names\n",
    "input_dicts = [\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/8000_pixels/20240205/\": \"IPCC_basic_classes_2000\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/8000_pixels/20240205/\": \"IPCC_basic_classes_2005\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/8000_pixels/20240205/\": \"IPCC_basic_classes_2010\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/8000_pixels/20240205/\": \"IPCC_basic_classes_2015\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/8000_pixels/20240205/\": \"IPCC_basic_classes_2020\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/8000_pixels/20240205/\": \"IPCC_basic_change_2000_2005\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/8000_pixels/20240205/\": \"IPCC_basic_change_2005_2010\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/8000_pixels/20240205/\": \"IPCC_basic_change_2010_2015\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\": \"IPCC_basic_change_2015_2020\"}\n",
    "          ]\n",
    "\n",
    "# Make raster footprint shapefiles from output rasters\n",
    "delayed_result = [dask.delayed(make_tile_footprint_shp)(input_dict) for input_dict in input_dicts]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816087e-5993-4365-ab96-111ef7e3bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Create 10x10 degree rasters aggregated from 2x2 degree rasters\n",
    "## Doesn't use much memory. Can be done on 30x 8 GB workers (1 hour). \n",
    "## In this case, it's aggregation of the IPCC single-year class rasters and change rasters\n",
    "\n",
    "# Folders to process and the corresponding nodata values for the output rasters (not currently used)\n",
    "s3_in_folder_dicts = [\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/8000_pixels/20240205/\": 0},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/8000_pixels/20240205/\": 0},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/8000_pixels/20240205/\": 0},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/8000_pixels/20240205/\": 0},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/8000_pixels/20240205/\": 0},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/8000_pixels/20240205/\": 255},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/8000_pixels/20240205/\": 255},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/8000_pixels/20240205/\": 255},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\": 255}\n",
    "          ]\n",
    "\n",
    "# Creates the list of aggregated 10x10 rasters that will be created (list of dictionaries of input s3 folder and output aggregated raster name.\n",
    "# These are the basis for the tasks.\n",
    "list_of_s3_name_dicts_total = create_list_for_aggregation(s3_in_folder_dicts)\n",
    "\n",
    "# # For testing. Limits the number of output rasters\n",
    "# list_of_s3_name_dicts_total = list_of_s3_name_dicts_total[0:40]  # First 40 tiles\n",
    "# list_of_s3_name_dicts_total = list_of_s3_name_dicts_total[40:41] # 10N_130E; Internal chunks missing and padding needed on right; FID40\n",
    "# list_of_s3_name_dicts_total = list_of_s3_name_dicts_total[0:1]  # 00N_000E; Padding below and left; FID0\n",
    "# list_of_s3_name_dicts_total = list_of_s3_name_dicts_total[41:42]  # 10S_010E; No padding needed; FID41\n",
    "\n",
    "delayed_result = [dask.delayed(merge_small_tiles_gdal)(s3_name_no_data_dict) for s3_name_no_data_dict in list_of_s3_name_dicts_total]\n",
    "\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93294c31-0b90-4f17-a7a9-6a5697e50b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Making tile index shapefile for: gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/: 20240215_22_12_57\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2005__10x10.shp: 20240215_22_13_30\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2015__10x10.shp: 20240215_22_13_33\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2010_2015__10x10.shp: 20240215_22_13_33\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2015_2020__10x10.shp: 20240215_22_13_34\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2000_200__10x105.shp: 20240215_22_13_34\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2020__10x10.shp: 20240215_22_13_35\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2005_2010__10x10.shp: 20240215_22_13_35\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2010__10x10.shp: 20240215_22_13_35\n",
      "Uploading to s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2000__10x10.shp: 20240215_22_13_36\n",
      "CPU times: user 225 ms, sys: 37.7 ms, total: 263 ms\n",
      "Wall time: 38.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Completed: 20240215_22_13_36',\n",
       " 'Completed: 20240215_22_13_31',\n",
       " 'Completed: 20240215_22_13_36',\n",
       " 'Completed: 20240215_22_13_33',\n",
       " 'Completed: 20240215_22_13_35',\n",
       " 'Completed: 20240215_22_13_35',\n",
       " 'Completed: 20240215_22_13_35',\n",
       " 'Completed: 20240215_22_13_34',\n",
       " 'Completed: 20240215_22_13_35')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Create raster footprint shapefiles from listed rasters\n",
    "## Doesn't use memory. Can be done on 4 GB workers. Only need as many workers as there are folders. \n",
    "\n",
    "# Folders to process and the corresponding output shapefile names\n",
    "input_dicts = [\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/\": \"IPCC_basic_classes_2000__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/40000_pixels/20240205/\": \"IPCC_basic_classes_2005__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/40000_pixels/20240205/\": \"IPCC_basic_classes_2010__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/40000_pixels/20240205/\": \"IPCC_basic_classes_2015__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/40000_pixels/20240205/\": \"IPCC_basic_classes_2020__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/40000_pixels/20240205/\": \"IPCC_basic_change_2000_200__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/40000_pixels/20240205/\": \"IPCC_basic_change_2005_2010__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/40000_pixels/20240205/\": \"IPCC_basic_change_2010_2015__10x10\"},\n",
    "           {\"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/\": \"IPCC_basic_change_2015_2020__10x10\"}\n",
    "          ]\n",
    "\n",
    "# Make raster footprint shapefiles from output rasters\n",
    "delayed_result = [dask.delayed(make_tile_footprint_shp)(input_dict) for input_dict in input_dicts]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483093ae-9c93-4dd6-85b0-b63c1147cf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c45ce-fd6b-43b4-8ccb-46241ce4f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
