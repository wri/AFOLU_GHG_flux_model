{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563bd454-cf3e-42ab-ac66-ed71d98a4782",
   "metadata": {},
   "source": [
    "<font size=\"6\">Run the LULUCF part of the AFOLU model</font> \n",
    "\n",
    "<font size=\"4\">Must be run using the utilities_and_variables.ipynb kernel</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80188c23-a64e-4792-bee8-958be94def04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate LULUCF fluxes and carbon densities\n",
    "# Operates pixel by pixel, so uses numba (Python compiled to C++).\n",
    "@jit(nopython=True)\n",
    "def LULUCF_fluxes(uint8_layers, float32_layers):\n",
    "\n",
    "    \n",
    "    uint8_layers\n",
    "    float32_layers\n",
    "    # print(layers['land_cover_2020'])\n",
    "\n",
    "    # # Output array of 0s\n",
    "    # IPCC_change_block = np.zeros(IPCC_previous_block.shape)\n",
    "\n",
    "    # # Iterates through all pixels in the chunk\n",
    "    # for row in range(IPCC_previous_block.shape[0]):\n",
    "    #     for col in range(IPCC_previous_block.shape[1]):\n",
    "\n",
    "    #         IPCC_previous = IPCC_previous_block[row, col]\n",
    "    #         IPCC_current = IPCC_current_block[row, col]\n",
    "\n",
    "    #         # When land cover chunks have \"no data\"\n",
    "    #         if (IPCC_previous == 0) and (IPCC_current == 0):\n",
    "    #             IPCC_change_block[row, col] = 0\n",
    "\n",
    "    #         else:\n",
    "    #             # Equation to calculate the IPCC change code\n",
    "    #             IPCC_change_block[row, col] = ((IPCC_previous - 1) * IPCC_class_max_val) + IPCC_current\n",
    "\n",
    "    # return input_layers['land_cover_2020'][0, 0] * 2\n",
    "    return uint8_layers, float32_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3387d267-19c0-4584-9a86-5bc71a4c6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def calculate_and_upload_LULUCF_fluxes(bounds, is_final):\n",
    "\n",
    "    bounds_str = boundstr(bounds)    # String form of chunk bounds\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])    # tile_id in YYN/S_XXXE/W\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)   # Chunk length in pixels (as opposed to decimal degrees)\n",
    "\n",
    "    no_data_val = 255\n",
    "\n",
    "    \n",
    "    ### Part 1: Downloads chunks and check for data\n",
    "\n",
    "    # Dictionary of downloaded layers\n",
    "    download_dict = {}\n",
    "    layers = {}\n",
    "\n",
    "    download_dict = {\n",
    "        \"land_cover_2000\": f\"{composite_LC_uri}/2000/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2005\": f\"{composite_LC_uri}/2005/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2010\": f\"{composite_LC_uri}/2010/raw/{tile_id}.tif\",\n",
    "        # \"land_cover_2015\": f\"{composite_LC_uri}/2015/raw/{tile_id}.tif\",\n",
    "        # \"land_cover_2020\": f\"{composite_LC_uri}/2020/raw/{tile_id}.tif\",\n",
    "\n",
    "        \"agc_2000\": f\"s3://gfw2-data/climate/carbon_model/carbon_pools/aboveground_carbon/extent_2000/standard/20230222/{tile_id}_Mg_AGC_ha_2000.tif\",\n",
    "        \"bgc_2000\": f\"s3://gfw2-data/climate/carbon_model/carbon_pools/belowground_carbon/extent_2000/standard/20230222/{tile_id}_Mg_BGC_ha_2000.tif\",\n",
    "        \"deadwood_c_2000\": f\"s3://gfw2-data/climate/carbon_model/carbon_pools/deadwood_carbon/extent_2000/standard/20230222/{tile_id}_Mg_deadwood_C_ha_2000.tif\",\n",
    "        # \"litter_c_2000\": f\"s3://gfw2-data/climate/carbon_model/carbon_pools/litter_carbon/extent_2000/standard/20230222/{tile_id}_Mg_litter_C_ha_2000.tif\",\n",
    "        # \"soil_c_2000\": f\"s3://gfw2-data/climate/carbon_model/carbon_pools/soil_carbon/intermediate_full_extent/standard/20231108/{tile_id}_soil_C_full_extent_2000_Mg_C_ha.tif\",\n",
    "\n",
    "        # \"r_s_ratio\": f\"s3://gfw2-data/climate/carbon_model/BGB_AGB_ratio/processed/20230216/{tile_id}_BGB_AGB_ratio.tif\",\n",
    "\n",
    "        # \"drivers\": f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/tree_cover_loss_drivers/processed/drivers_2022/20230407/{tile_id}_tree_cover_loss_driver_processed.tif\",\n",
    "        # \"planted_forest_type\": f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/plantation_type/SDPTv2/20230911/{tile_id}_plantation_type_oilpalm_woodfiber_other.tif\",\n",
    "        # \"peat\": f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/{tile_id}_peat_mask_processed.tif\",\n",
    "        # \"ecozone\": f\"s3://gfw2-data/fao_ecozones/v2000/raster/epsg-4326/10/40000/class/gdal-geotiff/{tile_id}.tif\",   # Originally from gfw-data-lake, so it's in 400x400 windows \n",
    "        # \"iso\": f\"s3://gfw2-data/gadm_administrative_boundaries/v3.6/raster/epsg-4326/10/40000/adm0/gdal-geotiff/{tile_id}.tif\",  # Originally from gfw-data-lake, so it's in 400x400 windows\n",
    "        # \"ifl_primary\": f\"s3://gfw2-data/climate/carbon_model/ifl_primary_merged/processed/20200724/{tile_id}_ifl_2000_primary_2001_merged.tif\"\n",
    "    }\n",
    "\n",
    "    # for year in range(first_year, last_year+1):\n",
    "    #     download_dict[f\"burned_area_{year}\"] = f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_{year}_{tile_id}.tif\",\n",
    "    #     download_dict[f\"forest_disturbance_{year}\"] = f\"s3://gfw2-data/landcover/annual_forest_disturbance/raw/{year}_{tile_id}.tif\"  \n",
    "\n",
    "    # Checks whether tile exists at all. Doesn't try to download chunk if the tile doesn't exist.\n",
    "    tile_exists = check_for_tile(download_dict)\n",
    "\n",
    "    if tile_exists == 0:\n",
    "        return\n",
    "\n",
    "    # Note: If running in a local Dask cluster, prints to console may be duplicated. Doesn't happen with a Coiled cluster of the same size (1 worker).\n",
    "    # Seems to be a problem with local Dask getting overwhelmed by so many futures being created and downloaded from s3. \n",
    "    futures = prepare_to_download_chunk(bounds, download_dict, no_data_val)\n",
    "\n",
    "    # print(futures)\n",
    "\n",
    "    if not is_final:\n",
    "        print(f\"Waiting for requests for data in chunk {bounds_str} in {tile_id}: {timestr()}\")\n",
    "    \n",
    "    # Waits for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layer = futures[future]\n",
    "        layers[layer] = future.result()\n",
    "\n",
    "    print(layers)\n",
    "    \n",
    "    # Checks chunk for data. Skips the chunk if it has no data in it.\n",
    "    data_in_chunk = check_chunk_for_data(layers, \"land_cover_\", bounds_str, tile_id, no_data_val)\n",
    "\n",
    "    if data_in_chunk == 0:\n",
    "        return\n",
    "\n",
    "    \n",
    "    ### Part 2: Create a separate dictionary for each chunk datatype so that they can be passed to Numba as separate arguments\n",
    "    ### Note: need to add new code if new input chunk types are added\n",
    "\n",
    "    # Initializes empty dictionaries for each type\n",
    "    uint8_dict_layers = {}\n",
    "    float32_dict_layers = {}\n",
    "    \n",
    "    # Iterates through the downloaded chunk dictionary and distributes arrays to a separate dictionary for each data type\n",
    "    for key, array in layers.items():\n",
    "        if array.dtype == np.uint8:\n",
    "            uint8_dict_layers[key] = array\n",
    "        elif array.dtype == np.float32:\n",
    "            float32_dict_layers[key] = array\n",
    "\n",
    "    # Creates numba-compliant typed dict for each type of array\n",
    "    typed_dict_uint8 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.uint8, 2, 'C')  # Assuming 2D arrays of uint8\n",
    "    )\n",
    "\n",
    "    typed_dict_float32 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.float32, 2, 'C')  # Assuming 2D arrays of uint8\n",
    "    )\n",
    "\n",
    "    # Populates the numba-compliant typed dicts\n",
    "    for key, array in uint8_dict_layers.items():\n",
    "        typed_dict_uint8[key] = array\n",
    "\n",
    "    for key, array in float32_dict_layers.items():\n",
    "        typed_dict_float32[key] = array\n",
    "\n",
    "    \n",
    "    ### Part 3: Calculates LULUCF fluxes and densities\n",
    "   \n",
    "    print(f\"Calculating LULUCF fluxes and carbon densities in {bounds_str} in {tile_id}: {timestr()}\")\n",
    "\n",
    "    LULUCF_output_uint8, LULUCF_output_float32 = LULUCF_fluxes(\n",
    "        typed_dict_uint8, typed_dict_float32    \n",
    "    )\n",
    "\n",
    "    print(\"After numba\")\n",
    "    print(LULUCF_output_uint8)\n",
    "    print(LULUCF_output_float32)\n",
    "    \n",
    "    # # Output files to upload to s3\n",
    "    # LULUCF_output_dict[f\"IPCC_change_{year-5}_{year}\"] = [IPCC_change, \"uint8\", \"IPCC_basic_change\", f'{year-5}_{year}']  \n",
    "\n",
    "    # # save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, bounds_str, LULUCF_output_dict, is_final)\n",
    "\n",
    "    \n",
    "    # # # Clear memory of unneeded arrays\n",
    "    # # del LULUCF_output\n",
    "    # # del LULUCF_output_dict\n",
    "\n",
    "    return f\"Success for {bounds_str}: {timestr()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "180bd0eb-dec2-4757-95bb-5f620e29bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 chunks\n",
      "Tile id 50N_010E exists. Proceeding.\n",
      "Requesting data in chunk 10_50_10_50 in 50N_010E: 20240408_21_20_34\n",
      "Waiting for requests for data in chunk 10_50_10_50 in 50N_010E: 20240408_21_20_38\n",
      "{'land_cover_2005': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 44,  41,  44, ..., 244, 244, 244],\n",
      "       [ 42,  44,  44, ..., 244, 244, 244],\n",
      "       [ 42,  45,  46, ..., 244, 244, 244]], dtype=uint8), 'land_cover_2000': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 47,  46,  47, ..., 244, 244, 244],\n",
      "       [ 42,  43,  47, ..., 244, 244, 244],\n",
      "       [ 46,  45,  46, ..., 244, 244, 244]], dtype=uint8), 'agc_2000': array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
      "       [ 0.  ,  0.  ,  0.  , ...,  0.94, 15.98, 19.27],\n",
      "       [ 0.  ,  0.  ,  0.  , ..., 24.91, 13.16, 18.8 ],\n",
      "       ...,\n",
      "       [81.78, 81.78, 96.82, ...,  0.94,  0.94,  0.94],\n",
      "       [89.77, 89.77, 89.3 , ...,  1.88,  0.94,  1.88],\n",
      "       [88.83, 88.36, 91.18, ...,  0.94,  0.94,  0.94]], dtype=float32), 'deadwood_c_2000': array([[0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
      "       [0.    , 0.    , 0.    , ..., 0.0752, 1.2784, 1.5416],\n",
      "       [0.    , 0.    , 0.    , ..., 1.9928, 1.0528, 1.504 ],\n",
      "       ...,\n",
      "       [6.5424, 6.5424, 7.7456, ..., 0.0752, 0.0752, 0.0752],\n",
      "       [7.1816, 7.1816, 7.144 , ..., 0.1504, 0.0752, 0.1504],\n",
      "       [7.1064, 7.0688, 7.2944, ..., 0.0752, 0.0752, 0.0752]],\n",
      "      dtype=float32), 'bgc_2000': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.23146453,\n",
      "         3.9348972 ,  4.7450233 ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  6.13381   ,\n",
      "         3.2405035 ,  4.6292906 ],\n",
      "       ...,\n",
      "       [18.612658  , 18.612658  , 22.035675  , ...,  0.22450306,\n",
      "         0.22450306,  0.22450306],\n",
      "       [20.431135  , 20.431135  , 20.324167  , ...,  0.4490061 ,\n",
      "         0.22450306,  0.4490061 ],\n",
      "       [20.217197  , 20.110228  , 20.752043  , ...,  0.22450306,\n",
      "         0.22450306,  0.22450306]], dtype=float32), 'land_cover_2010': array([[244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       [244, 244, 244, ..., 250, 250, 250],\n",
      "       ...,\n",
      "       [ 44,  43,  44, ..., 244, 244, 244],\n",
      "       [ 42,  44,  44, ..., 244, 244, 244],\n",
      "       [ 45,  45,  46, ..., 244, 244, 244]], dtype=uint8)}\n",
      "Data in chunk 10_50_10_50. Proceeding.\n",
      "Calculating LULUCF fluxes and carbon densities in 10_50_10_50 in 50N_010E: 20240408_21_20_38\n",
      "After numba\n",
      "{land_cover_2005: [[244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " ...\n",
      " [ 44  41  44 ... 244 244 244]\n",
      " [ 42  44  44 ... 244 244 244]\n",
      " [ 42  45  46 ... 244 244 244]], land_cover_2000: [[244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " ...\n",
      " [ 47  46  47 ... 244 244 244]\n",
      " [ 42  43  47 ... 244 244 244]\n",
      " [ 46  45  46 ... 244 244 244]], land_cover_2010: [[244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " [244 244 244 ... 250 250 250]\n",
      " ...\n",
      " [ 44  43  44 ... 244 244 244]\n",
      " [ 42  44  44 ... 244 244 244]\n",
      " [ 45  45  46 ... 244 244 244]]}\n",
      "{agc_2000: [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...  0.94 15.98 19.27]\n",
      " [ 0.    0.    0.   ... 24.91 13.16 18.8 ]\n",
      " ...\n",
      " [81.78 81.78 96.82 ...  0.94  0.94  0.94]\n",
      " [89.77 89.77 89.3  ...  1.88  0.94  1.88]\n",
      " [88.83 88.36 91.18 ...  0.94  0.94  0.94]], deadwood_c_2000: [[0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.0752 1.2784 1.5416]\n",
      " [0.     0.     0.     ... 1.9928 1.0528 1.504 ]\n",
      " ...\n",
      " [6.5424 6.5424 7.7456 ... 0.0752 0.0752 0.0752]\n",
      " [7.1816 7.1816 7.144  ... 0.1504 0.0752 0.1504]\n",
      " [7.1064 7.0688 7.2944 ... 0.0752 0.0752 0.0752]], bgc_2000: [[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.23146453  3.9348972\n",
      "   4.7450233 ]\n",
      " [ 0.          0.          0.         ...  6.13381     3.2405035\n",
      "   4.6292906 ]\n",
      " ...\n",
      " [18.612658   18.612658   22.035675   ...  0.22450306  0.22450306\n",
      "   0.22450306]\n",
      " [20.431135   20.431135   20.324167   ...  0.4490061   0.22450306\n",
      "   0.4490061 ]\n",
      " [20.217197   20.110228   20.752043   ...  0.22450306  0.22450306\n",
      "   0.22450306]]}\n",
      "CPU times: user 60.2 ms, sys: 4.77 ms, total: 65 ms\n",
      "Wall time: 3.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Success for 10_50_10_50: 20240408_21_20_38',)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Create LULUCF flux and carbon stock 2x2 deg rasters \n",
    "\n",
    "## Area to analyze\n",
    "## chunk_params arguments: W, S, E, N, chunk size (degrees)\n",
    "# chunk_params = [-180, -60, 180, 80, 2]  # entire world\n",
    "# chunk_params = [-10, 40, 20, 70, 1]    # 30x30 deg (70N_010W), 900 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 2]    # 10x10 deg (50N_010E), 25 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 10]    # 10x10 deg (50N_010E), 1 chunk\n",
    "# chunk_params = [10, 46, 14, 50, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [110, -10, 114, -6, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [10, 48, 12, 50, 1]   # 2x2 deg, 4 chunks\n",
    "# chunk_params = [10, 49, 11, 50, 1]   # 1x1 deg, 1 chunk\n",
    "# chunk_params = [10, 49, 11, 50, 0.5] # 1x1 deg, 4 chunks\n",
    "# chunk_params = [10, 49.5, 10.5, 50, 0.25] # 0.5x0.5 deg, 4 chunks\n",
    "# chunk_params = [10, 42, 11, 43, 0.5] # 1x1 deg, 4 chunks (some GLCLU code=254 for ocean and some land, so data should be output)\n",
    "chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk (has data)\n",
    "\n",
    "# # Range of no-data cases for testing\n",
    "# chunk_params = [110, -10, 120, 0, 2]    # 10x10 deg (00N_110E), 25 chunks (all chunks have land and should be output)\n",
    "# chunk_params = [110, -20, 120, -10, 2]    # 10x10 deg (00N_110E), 25 chunks (all chunks have land and should be output)\n",
    "# chunk_params = [0, 79.75, 0.25, 80, 0.25] # 0.25x0.25 deg, 1 chunk (no 80N_000E tile-- no data)\n",
    "# chunk_params = [112, -12, 116, -8, 2]   # 2x2 deg, 1 chunk (bottom of Java, has data but mostly ocean)\n",
    "# chunk_params = [10.875, 41.75, 11, 42, 0.25] # 0.25x0.25 deg, 1 chunk (entirely GLCLU code=255 for ocean, so no actual data-- nothing should be be output)\n",
    "# chunk_params = [-10, 21.75, -9.75, 22, 0.25] # 0.25x0.25 deg, 1 chunk (has data but entirely desert (fully GLCLU code=0))\n",
    "# chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk (has data)\n",
    "\n",
    "\n",
    "# Makes list of chunks to analyze\n",
    "chunks = get_chunk_bounds(chunk_params)  \n",
    "print(\"Processing\", len(chunks), \"chunks\")\n",
    "# print(chunks)\n",
    "\n",
    "# Determines if the output file names for final versions of outputs should be used\n",
    "is_final = False\n",
    "if len(chunks) > 30:\n",
    "    is_final = True\n",
    "    print(\"Running as final model.\")\n",
    "\n",
    "# Creates list of tasks to run (1 task = 1 chunk for all years)\n",
    "delayed_result = [dask.delayed(calculate_and_upload_LULUCF_fluxes)(chunk, is_final) for chunk in chunks]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35e8a3-64c6-42e4-ba7b-06762c09cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute without Dask\n",
    "calculate_and_upload_LULUCF_fluxes([10, 49.75, 10.25, 50], is_final=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b5d6e-3592-4792-8032-0485a57f4539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
