{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c44f117",
   "metadata": {},
   "source": [
    "<font size=\"6\">Analysis</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f720e810-b37b-4b20-b8a5-e501b526e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reclassify GLCLU classes to basic IPCC reporting classes.\n",
    "# Operates on the array/chunk. \n",
    "# Classification comes from https://onewri-my.sharepoint.com/:p:/g/personal/david_gibbs_wri_org/EWwyxRfgdeVJi4ezwX7LrfcBjCoqAcjL2jRAZjb_8RU9LQ?e=YUsQiU\n",
    "def reclassify_to_IPCC(GLCLU_block):\n",
    "\n",
    "    # Outputs\n",
    "    IPCC_classes = np.zeros(GLCLU_block.shape)\n",
    "\n",
    "    IPCC_classes[np.where(GLCLU_block <= 1)] = otherland                                 \n",
    "    IPCC_classes[np.where((GLCLU_block >= 2) & (GLCLU_block <= 26))] = grassland          \n",
    "    IPCC_classes[np.where((GLCLU_block >= 27) & (GLCLU_block <= 48))] = forest         \n",
    "    IPCC_classes[np.where((GLCLU_block >= 100) & (GLCLU_block <= 101))] = wetland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 102) & (GLCLU_block <= 126))] = grassland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 127) & (GLCLU_block <= 148))] = forest       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 200) & (GLCLU_block <= 204))] = wetland       \n",
    "    IPCC_classes[np.where((GLCLU_block >= 205) & (GLCLU_block <= 207))] = otherland       \n",
    "    IPCC_classes[np.where(GLCLU_block == 241)] = otherland                                \n",
    "    IPCC_classes[np.where(GLCLU_block == 244)] = cropland                                \n",
    "    IPCC_classes[np.where(GLCLU_block == 250)] = settlement                               \n",
    "    IPCC_classes[np.where(GLCLU_block == 254)] = otherland                              \n",
    "    \n",
    "    return IPCC_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0070fd86-a857-445e-92e5-e9ba3dc99caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map basic IPCC change classes.\n",
    "# Operates pixel by pixel, so uses numba (Python compiled to C++).\n",
    "@jit(nopython=True)\n",
    "def change_classes_IPCC(IPCC_previous_block, IPCC_current_block):\n",
    "\n",
    "    # Output array of 0s\n",
    "    IPCC_change_block = np.zeros(IPCC_previous_block.shape)\n",
    "\n",
    "    # Iterates through all pixels in the chunk\n",
    "    for row in range(IPCC_previous_block.shape[0]):\n",
    "        for col in range(IPCC_previous_block.shape[1]):\n",
    "\n",
    "            IPCC_previous = IPCC_previous_block[row, col]\n",
    "            IPCC_current = IPCC_current_block[row, col]\n",
    "\n",
    "            # When land cover chunks have \"no data\"\n",
    "            if (IPCC_previous == 0) and (IPCC_current == 0):\n",
    "                IPCC_change_block[row, col] = 0\n",
    "\n",
    "            else:\n",
    "                # Equation to calculate the IPCC change code\n",
    "                IPCC_change_block[row, col] = ((IPCC_previous - 1) * IPCC_class_max_val) + IPCC_current\n",
    "\n",
    "    return IPCC_change_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7027b3-48f8-4f73-8da4-5065bfcc60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads input chunks, reclassifies GLCLU classes into IPCC land use reporting classes for each year, and maps changes between classes for consecutive years.\n",
    "# Chunks are defined by a bounding box and a starting year for iteration\n",
    "def reclassify_and_map_change_chunk(bounds, is_final):\n",
    "\n",
    "    bounds_str = boundstr(bounds)    # String form of chunk bounds\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])    # tile_id in YYN/S_XXXE/W\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)   # Chunk length in pixels (as opposed to decimal degrees)\n",
    "\n",
    "    \n",
    "    ### Part 1: download chunks and check for data\n",
    "\n",
    "    # Dictionary of downloaded layers\n",
    "    layers = {}\n",
    "\n",
    "    download_dict = {\n",
    "        \n",
    "        \"land_cover_2000\": f\"{composite_LC_uri}/2000/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2005\": f\"{composite_LC_uri}/2005/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2010\": f\"{composite_LC_uri}/2010/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2015\": f\"{composite_LC_uri}/2015/raw/{tile_id}.tif\",\n",
    "        \"land_cover_2020\": f\"{composite_LC_uri}/2020/raw/{tile_id}.tif\"   \n",
    "    }\n",
    "    \n",
    "    futures = prepare_to_download_chunk(bounds, download_dict)\n",
    "    dask_print(f\"Waiting for requests for data in chunk {bounds_str} in {tile_id}: {timestr()}\")\n",
    "    \n",
    "    # Waits for requests to come back with data from S3\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        layer = futures[future]\n",
    "        layers[layer] = future.result()\n",
    "\n",
    "    # Checks chunk for data\n",
    "    data_in_chunk = check_chunk_for_data(layers, \"land_cover_\", bounds_str, tile_id)\n",
    "\n",
    "    if data_in_chunk == 0:\n",
    "        return\n",
    "\n",
    "    \n",
    "    ### Part 2: reclassify GLCLU classes into IPCC reporting classes \n",
    "    IPCC_class_dict = {}\n",
    "\n",
    "    # Iterates through model years\n",
    "    for year in list(range(first_year, last_year+1, 5)):\n",
    "        \n",
    "        dask_print(f\"Reclassifying {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "\n",
    "        # Reclassifies GLCLU to 6 IPCC classes \n",
    "        IPCC_classes = reclassify_to_IPCC(\n",
    "            layers[f\"land_cover_{year}\"]   \n",
    "        )\n",
    "\n",
    "        # Output files to upload to s3\n",
    "        IPCC_class_dict[f\"IPCC_classes_{year}\"] = [IPCC_classes, \"uint8\", \"IPCC_basic_classes\", year]                 \n",
    "    \n",
    "    save_and_upload(bounds, chunk_length_pixels, tile_id, bounds_str, IPCC_class_dict, is_final)\n",
    "\n",
    "    \n",
    "    ### Part 3\n",
    "    IPCC_change_dict = {}\n",
    "\n",
    "    # Iterates through model years in a way that change can be calculated\n",
    "    for year in list(range(first_year+5, last_year+1, 5)):\n",
    "        \n",
    "        dask_print(f\"Getting IPCC class change in {bounds_str} in {tile_id} for {year}: {timestr()}\")\n",
    "\n",
    "        # Maps change between IPCC classes\n",
    "        IPCC_change = change_classes_IPCC(\n",
    "            IPCC_class_dict[f\"IPCC_classes_{year-5}\"][0], # first [0] needed because results_download is a tuple with a dictionary inside it. Second [0] to isolate the array.\n",
    "            IPCC_class_dict[f\"IPCC_classes_{year}\"][0]    # first [0] needed because results_download is a tuple with a dictionary inside it. Second [0] to isolate the array.\n",
    "        )\n",
    "\n",
    "        # Output files to upload to s3\n",
    "        IPCC_change_dict[f\"IPCC_change_{year-5}_{year}\"] = [IPCC_change, \"uint8\", \"IPCC_basic_change\", f'{year-5}_{year}']  \n",
    "\n",
    "    save_and_upload(bounds, chunk_length_pixels, tile_id, bounds_str, IPCC_change_dict, is_final)\n",
    "\n",
    "    \n",
    "    # Clear memory of unneeded arrays\n",
    "    del IPCC_classes\n",
    "    del IPCC_class_dict\n",
    "    del IPCC_change\n",
    "    del IPCC_change_dict\n",
    "\n",
    "    return f\"success for {bounds_str}: {timestr()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Area to analyze\n",
    "# chunk_params arguments: W, S, E, N, chunk size (degrees)\n",
    "chunk_params = [-180, -50, 180, 80, 2]  # entire world\n",
    "# chunk_params = [-10, 40, 20, 70, 1]    # 30x30 deg (70N_010W), 900 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 2]    # 10x10 deg (50N_010E), 25 chunks\n",
    "# chunk_params = [10, 40, 20, 50, 10]    # 10x10 deg (50N_010E), 1 chunk\n",
    "# chunk_params = [10, 46, 14, 50, 2]   # 4x4 deg, 4 chunks\n",
    "# chunk_params = [10, 48, 12, 50, 1]   # 2x2 deg, 4 chunks\n",
    "# chunk_params = [10, 49, 11, 50, 1]   # 1x1 deg, 1 chunk\n",
    "# chunk_params = [10, 49, 11, 50, 0.5] # 1x1 deg, 4 chunks\n",
    "# chunk_params = [10, 41, 11, 42, 0.5] # 1x1 deg, 4 chunks, part in nodata areas (GLCLU code=255)\n",
    "# chunk_params = [10, 49.5, 10.5, 50, 0.25] # 0.5x0.5 deg, 4 chunks\n",
    "# chunk_params = [10, 49.75, 10.25, 50, 0.25] # 0.25x0.25 deg, 1 chunk (has data)\n",
    "# chunk_params = [0, 79.75, 0.25, 80, 0.25] # 0.25x0.25 deg, 1 chunk (no data)\n",
    "\n",
    "# Makes list of chunks to analyze\n",
    "chunks = get_chunk_bounds(chunk_params)  \n",
    "print(\"Processing\", len(chunks), \"chunks\")\n",
    "\n",
    "# Determines if the output file names for final versions of outputs should be used\n",
    "is_final = False\n",
    "if len(chunks) > 100:\n",
    "    is_final = True\n",
    "\n",
    "# Creates list of tasks to run (1 task = 1 chunk for all years)\n",
    "delayed_result = [dask.delayed(reclassify_and_map_change_chunk)(chunk, is_final) for chunk in chunks]\n",
    "\n",
    "# Actually runs analysis\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c322828-5e41-4706-a9df-09c9e5cafcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a9cd1-a949-44b9-b5f4-1363e4a157e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c45ce-fd6b-43b4-8ccb-46241ce4f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1114ac-9c2c-4cfb-9212-1d96f1aada06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run without dask at all\n",
    "process_chunk([10, 49, 11, 50], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5f88b-9a9d-45ce-ad03-235510e6798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test-- checks that uri is found and recognized\n",
    "tile_id = \"50N_010E\"\n",
    "# uri = f\"s3://gfw2-data/climate/carbon_model/BGB_AGB_ratio/processed/20230216/{tile_id}_BGB_AGB_ratio.tif\"\n",
    "uri = f\"s3://gfw2-data/gadm_administrative_boundaries/v3.6/raster/epsg-4326/10/40000/adm0/gdal-geotiff/{tile_id}.tif\"  # Originally from gfw-data-lake, so it's in 400x400 windows\n",
    "# uri = f\"s3://gfw2-data/fao_ecozones/v2000/raster/epsg-4326/10/40000/class/gdal-geotiff/{tile_id}.tif\"   # Originally from gfw-data-lake, so it's in 400x400 windows \n",
    "bounds = [10, 49.75, 10.25, 50]\n",
    "\n",
    "get_tile_dataset_rio(uri, bounds, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c41e5-b135-4933-8bce-68d2acfcb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_client.restart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53347e4f-aaa0-440d-9080-dc95a31bb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(future) # per https://github.com/dask/distributed/issues/3898#issuecomment-645590511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2de194-d396-4ab8-bd77-4641e4997a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 cp s3://gfw2-data/climate/European_height_carbon_model/outputs/ . --recursive --exclude \"*\" --include \"*10_49_11_50*\"\n",
    "# aws s3 cp s3://gfw2-data/climate/European_height_carbon_model/outputs/ . --recursive --exclude \"*\" --include \"*2002*10_49_11_50*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5045c-a010-4762-88c3-a42a5d3edbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
