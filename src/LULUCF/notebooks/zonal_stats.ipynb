{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3824e156-86ed-4a56-b0ef-531c2287e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies for notebook\n",
    "import sys\n",
    "import os\n",
    "import rioxarray\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xrspatial import zonal_stats\n",
    "from xrspatial.zonal import _stats_count as xr_count\n",
    "from pathlib import Path \n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.distributed import print\n",
    "import distributed\n",
    "import concurrent.futures\n",
    "\n",
    "# Dynamically creating the utilities module using a relative path\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"utilities\", \"../utilities/__init__.py\")\n",
    "utilities = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"utilities\"] = utilities\n",
    "spec.loader.exec_module(utilities)\n",
    "\n",
    "# Importing utilities from utilities module \n",
    "from utilities import constants_and_names as cn\n",
    "from utilities import universal_utilities as uu\n",
    "from utilities import log_utilities as lu\n",
    "from utilities import numba_utilities as nu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9d916-d2ee-4cb6-9238-2e9b90ae040f",
   "metadata": {},
   "source": [
    "<font size=\"5\">Set notebook options</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f093057-9a6e-4f23-ac79-54ccbbe76c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cloud vs local cluster (options = 'full', 'test', 'local' )\n",
    "cluster_type = 'local'\n",
    "\n",
    "#date of ipcc landcover class rasters\n",
    "ipcc_class_date = '20240205'\n",
    "\n",
    "#tile list \n",
    "tile_id = \"00N_000W\"  #this is a placeholder for the data dictionaries, overwritten by tile_id\n",
    "tile_id_list = [\"00N_060W\"]\n",
    "\n",
    "#years list (options: '2000', '2000_2005', '2005_2010', '2010_2015', '2015_2020')\n",
    "#'2000': Get carbon densities in 2000\n",
    "year_list = ['2000', '2000_2005', '2005_2010', '2010_2015', '2015_2020'] \n",
    "\n",
    "#zone list (options: 'ipcc_class', 'climate', 'ecozone', 'ifl_primary', 'drivers')\n",
    "zone_list = ['ipcc_class', 'climate', 'ecozone', 'ifl_primary', 'drivers']\n",
    "#TODO: Add GADM and protected areas as contextual layers\n",
    "\n",
    "#stats list (options: 'agc', 'bgc', 'deadwood', 'litter')\n",
    "stat_list = ['agc', 'bgc', 'deadwood', 'litter']\n",
    "\n",
    "#flux list (options: 'emissions', 'removals', 'net_flux')\n",
    "flux_list = ['emissions', 'removals', 'net_flux']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcad4e0-facb-4b0b-a739-7c76ceee462a",
   "metadata": {},
   "source": [
    "<font size=\"5\">Creating clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c843741f-5aac-408b-950d-802b74eab136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melrose94/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33867 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-0f37cf92-9182-11ef-bf8f-00155da01d69</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:33867/status\" target=\"_blank\">http://127.0.0.1:33867/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">dd8ead50</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:33867/status\" target=\"_blank\">http://127.0.0.1:33867/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 12\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 15.47 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-4d2f0aab-a2cb-49ec-930d-e07ea5c2bcce</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:33663\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:33867/status\" target=\"_blank\">http://127.0.0.1:33867/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 12\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 15.47 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:33745\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:34135/status\" target=\"_blank\">http://127.0.0.1:34135/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.87 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:40185\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-pfod9bc6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:39043\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:34367/status\" target=\"_blank\">http://127.0.0.1:34367/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.87 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:46345\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-5ksw3lmg\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:33983\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:35057/status\" target=\"_blank\">http://127.0.0.1:35057/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.87 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:43205\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-e0o00bq3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:37543\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:33007/status\" target=\"_blank\">http://127.0.0.1:33007/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.87 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:42155\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-iq_n1mkj\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33663' processes=4 threads=12, memory=15.47 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cluster_type == 'full': \n",
    "    # Full cluster with 40 workers\n",
    "    coiled_cluster = coiled.Cluster(\n",
    "        n_workers=40,  \n",
    "        use_best_zone=True, \n",
    "        compute_purchase_option=\"spot_with_fallback\",\n",
    "        idle_timeout=\"10 minutes\",\n",
    "        region=\"us-east-1\",\n",
    "        name=\"AFOLU_zonal_stats\", \n",
    "        workspace='wri-forest-research', \n",
    "        worker_cpu=4,\n",
    "        worker_memory = \"16GiB\" \n",
    "    )\n",
    "    client = coiled_cluster.get_client()\n",
    "    \n",
    "elif cluster_type == 'test': \n",
    "    # Test cluster with 1 worker\n",
    "    coiled_cluster = coiled.Cluster(\n",
    "        n_workers=1,  \n",
    "        use_best_zone=True, \n",
    "        compute_purchase_option=\"spot_with_fallback\",\n",
    "        idle_timeout=\"10 minutes\",\n",
    "        region=\"us-east-1\",\n",
    "        name=\"AFOLU_zonal_stats\", \n",
    "        workspace='wri-forest-research', \n",
    "        worker_cpu=4,\n",
    "        worker_memory = \"16GiB\" \n",
    "    )\n",
    "    client = coiled_cluster.get_client()\n",
    "elif cluster_type == 'local':\n",
    "    # Local cluster with multiple workers\n",
    "    local_cluster = LocalCluster()  \n",
    "    client = Client(local_cluster)\n",
    "else: \n",
    "    print(\"set cluster_type to one of the following: 'full', 'test', 'local'\")\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d8a1e-6d44-439a-88c2-86cca8b64651",
   "metadata": {},
   "source": [
    "<font size=\"5\">Utilities and Variables</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf620ac-b60f-4313-968f-e8904f05d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################\n",
    "# Optional Zone Inputs (Categorical)\n",
    "##########################################################################################################################################\n",
    "\n",
    "\n",
    "#ecozone\n",
    "continent_ecozone_path = \"s3://gfw2-data/climate/carbon_model/fao_ecozones/ecozone_continent/20190116/processed/\"\n",
    "continent_ecozone_pattern = \"fao_ecozones_continents_processed\"\n",
    "\n",
    "#intact forest landscapes/ primary forest\n",
    "ifl_primary_path = \"s3://gfw2-data/climate/carbon_model/ifl_primary_merged/processed/20200724/\"\n",
    "ifl_primary_pattern = \"ifl_2000_primary_2001_merged\"\n",
    "\n",
    "#drivers \n",
    "drivers_path = \"s3://gfw2-data/drivers_of_loss/1_km/processed/20241004/\"\n",
    "drivers_pattern = \"drivers_of_TCL_1_km_20241004\"\n",
    "\n",
    "#protected areas\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#IPCC basic class [for single years only (i.e. 2000, 2005, 2010, 2015, 2020)]\n",
    "ipcc_class_2000_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/\"\n",
    "ipcc_class_2000_pattern = \"IPCC_classes_2000\"\n",
    "\n",
    "ipcc_class_2005_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/40000_pixels/20240205/\"\n",
    "ipcc_class_2005_pattern = \"IPCC_classes_2005\"\n",
    "\n",
    "ipcc_class_2010_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/40000_pixels/20240205/\"\n",
    "ipcc_class_2010_pattern = \"IPCC_classes_2010\"\n",
    "\n",
    "ipcc_class_2015_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/40000_pixels/20240205/\"\n",
    "ipcc_class_2015_pattern = \"IPCC_classes_2015\"\n",
    "\n",
    "ipcc_class_2020_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/40000_pixels/20240205/\"\n",
    "ipcc_class_2020_pattern = \"IPCC_classes_2020\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#IPCC change class [for intervals (i.e. 2000_2005, 2005_2010, 2010_2015, 2015_2020)]\n",
    "ipcc_change_2000_2005_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/40000_pixels/20240205/\"\n",
    "ipcc_change_2000_2005_pattern = \"IPCC_change_2000_2005\"\n",
    "\n",
    "ipcc_change_2005_2010_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/40000_pixels/20240205/\"\n",
    "ipcc_change_2005_2010_pattern = \"IPCC_change_2005_2010\"\n",
    "\n",
    "ipcc_change_2010_2015_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/40000_pixels/20240205/\"\n",
    "ipcc_change_2010_2015_pattern = \"IPCC_change_2010_2015\"\n",
    "\n",
    "ipcc_change_2015_2020_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/\"\n",
    "ipcc_change_2015_2020_pattern = \"IPCC_change_2015_2020\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#node codes  [for intervals (i.e. 2000_2005, 2005_2010, 2010_2015, 2015_2020)]\n",
    "#Note: a tile will have multiple tiffs (40N_010E__10_31_11_32__land_state_node_2000_2005.tif)\n",
    "# land_state_node_2000_2005_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/land_state_node/2000_2005/4000_pixels/20240930/\"\n",
    "# land_state_node_2000_2005_pattern = \"__land_state_node_2000_2005\"\n",
    "\n",
    "# land_state_node_2005_2010_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/land_state_node/2005_2010/4000_pixels/20240930/\"\n",
    "# land_state_node_2005_2010_pattern = \"__land_state_node_2005_2010\"\n",
    "\n",
    "# land_state_node_2010_2015_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/land_state_node/2010_2015/4000_pixels/20240930/\"\n",
    "# land_state_node_2010_2015_pattern = \"__land_state_node_2010_2015\"\n",
    "\n",
    "# land_state_node_2015_2020_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/land_state_node/2015_2020/4000_pixels/20240930/\"\n",
    "# land_state_node_2015_2020_pattern = \"__land_state_node_2015_2020\"\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################################\n",
    "#Optional Stats Inputs (Quantitiative)\n",
    "##########################################################################################################################################\n",
    "#pixel area (m2)\n",
    "pixel_area_path = \"s3://gfw2-data/umd_area_2013/v1.10/raster/epsg-4326/10/40000/area_m/geotiff/\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#AGC density 2000 (MgC per ha)\n",
    "agc_density_2000_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/40000_pixels/20240821/\"\n",
    "agc_density_2000_pattern = \"AGC_density_MgC_ha_2000\"\n",
    "#Note 2005 to 2020 only have 1000 pixels not 40000 pixels like 2000\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#BGC density 2000 (MgC per ha)\n",
    "bgc_density_2000_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/BGC_density_MgC_ha/2000/40000_pixels/20240821/\"\n",
    "bgc_density_2000_pattern = \"BGC_density_MgC_ha_2000\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Deadwood density 2000 (MgC per ha)\n",
    "deadwood_density_2000_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/deadwood_C_density_MgC_ha/2000/40000_pixels/20240821/\"\n",
    "deadwood_density_2000_pattern = \"deadwood_C_density_MgC_ha_2000\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Litter density 2000 (MgC per ha)\n",
    "litter_density_2000_path = \"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/litter_C_density_MgC_ha/2000/40000_pixels/20240821/\"\n",
    "litter_density_2000_pattern = \"litter_C_density_MgC_ha_2000\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#TODO: Update with constants and names variables\n",
    "#TODO: Update final dates for all zone/stat inputs\n",
    "\n",
    "# gadm boundary tiles\n",
    "# iso_gadm_path = 's3://gfw-data-lake/gadm_administrative_boundaries/v3.6/raster/epsg-4326/10/40000/adm0/geotiff/'\n",
    "# iso_gadm_pattern = ''\n",
    "#TODO: Why is iso_gadm showing up as none?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d3a01-6546-4aa2-ab2b-2baaac9b5535",
   "metadata": {},
   "source": [
    "<font size=\"4\">Zone Inputs (Categorical)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d562af91-da36-41ea-9740-2e1e7f27617d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utilities.constants_and_names' has no attribute 'ifl_primary_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     zone_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinent_ecozone\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcn\u001b[38;5;241m.\u001b[39mcontinent_ecozone_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcn\u001b[38;5;241m.\u001b[39mcontinent_ecozone_pattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mifl_primary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01min\u001b[39;00m zone_list: \n\u001b[0;32m---> 13\u001b[0m     zone_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mifl_primary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mifl_primary_path\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcn\u001b[38;5;241m.\u001b[39mifl_primary_pattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrivers\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;129;01min\u001b[39;00m zone_list: \n\u001b[1;32m     15\u001b[0m     zone_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrivers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcn\u001b[38;5;241m.\u001b[39mdrivers_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcn\u001b[38;5;241m.\u001b[39mdrivers_pattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utilities.constants_and_names' has no attribute 'ifl_primary_path'"
     ]
    }
   ],
   "source": [
    "zone_layers = {}\n",
    "\n",
    "for year in year_list: \n",
    "    if year == '2000': \n",
    "        zone_layers[\"ipcc_class_2000\"] = f\"{cn.outputs_path}{cn.IPCC_class_path}/{year}/40000_pixels/{ipcc_class_date}/{tile_id}__{cn.IPCC_class_pattern}_{year}.tif\"\n",
    "    else:\n",
    "        zone_layers[f\"ipcc_change_{year}\"] = f\"{cn.outputs_path}{cn.IPCC_change_path}/{year}/40000_pixels/{ipcc_class_date}/{tile_id}__{cn.IPCC_change_pattern}_{year}.tif\"\n",
    "if 'climate' in zone_list: \n",
    "    zone_layers[\"climate_domain\"] = f\"{cn.climate_domain_path}{tile_id}_{cn.climate_domain_pattern}.tif\"\n",
    "if 'ecozone' in zone_list: \n",
    "    zone_layers[\"continent_ecozone\"] = f\"{cn.continent_ecozone_path}{tile_id}_{cn.continent_ecozone_pattern}.tif\"\n",
    "if 'ifl_primary'in zone_list: \n",
    "    zone_layers[\"ifl_primary\"] = f\"{cn.ifl_primary_path}{tile_id}_{cn.ifl_primary_pattern}.tif\"\n",
    "if 'drivers'in zone_list: \n",
    "    zone_layers[\"drivers\"] = f\"{cn.drivers_path}{tile_id}_{cn.drivers_pattern}.tif\"\n",
    "\n",
    "zone_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a4077-737c-4306-ab22-7008e92a6086",
   "metadata": {},
   "source": [
    "<font size=\"5\">Calculate Densities 2000</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1104dc06-b039-4ad9-8296-3722ca34de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '2000' in year_list:\n",
    "    for tile_id in tile_id_list: \n",
    "        zone_dict = {}\n",
    "        \n",
    "        # Adding contextual layers to zone data dictionary \n",
    "        zone_dict[\"ipcc_class_2000\"] = f\"{ipcc_class_2000_path}{tile_id}__{ipcc_class_2000_pattern}.tif\"\n",
    "        zone_dict[\"climate_domain\"] = f\"{climate_domain_path}{tile_id}_{climate_domain_pattern}.tif\"\n",
    "        zone_dict[\"continent_ecozone\"] = f\"{continent_ecozone_path}{tile_id}_{continent_ecozone_pattern}.tif\"\n",
    "        \n",
    "        \n",
    "        zone_first_tiles = uu.first_file_name_in_s3_folder(zone_dict)\n",
    "        zone_dict_with_data_types = uu.add_file_type_to_dict(zone_first_tiles)\n",
    "        #NOTE: uu.check_for_tile() doesn't work if there is not a second item (ie data_type), in the download dictionary\n",
    "        #NOTE: uu.zone_first_tiles() overwrites tile_id w/ first tile so you have to update it again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb7f52-58b5-470a-9be0-1cdd9245171b",
   "metadata": {},
   "source": [
    "<font size=\"4\">Stat Inputs (Quantitative)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e7075382-9b39-48b7-9b8e-41126b9e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dict = {}\n",
    "stat_dict[\"pixel_area\"] = f\"{pixel_area_path}{tile_id}.tif\"\n",
    "stat_dict[\"agc_density_2000\"] = f\"{agc_density_2000_path}{tile_id}__{agc_density_2000_pattern}.tif\"\n",
    "stat_dict[\"bgc_density_2000\"] = f\"{bgc_density_2000_path}{tile_id}__{bgc_density_2000_pattern}.tif\"\n",
    "stat_dict[\"deadwood_density_2000\"] = f\"{deadwood_density_2000_path}{tile_id}__{deadwood_density_2000_pattern}.tif\"\n",
    "stat_dict[\"litter_density_2000\"] = f\"{litter_density_2000_path}{tile_id}__{litter_density_2000_pattern}.tif\"\n",
    "\n",
    "stat_first_tiles = uu.first_file_name_in_s3_folder(stat_dict)\n",
    "stat_dict_with_data_types = uu.add_file_type_to_dict(stat_first_tiles)\n",
    "#NOTE: uu.check_for_tile() doesn't work if there is not a second item (ie data_type), in the download dictionary\n",
    "#NOTE: uu.zone_first_tiles() overwrites tile_id w/ first tile so you have to update it again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485d2e5-f8c3-44ec-ac49-d1c66383668a",
   "metadata": {},
   "source": [
    "<font size=\"4\">Download Zone and Stat Inputs Layers</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f4b3057-e529-42c0-a304-4973517d286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'climate_domain': ['s3://gfw2-data/climate/carbon_model/inputs_for_carbon_pools/processed/fao_ecozones_bor_tem_tro/20190418/00N_060W_fao_ecozones_bor_tem_tro_processed.tif', 'Int16'], 'continent_ecozone': ['s3://gfw2-data/climate/carbon_model/fao_ecozones/ecozone_continent/20190116/processed/00N_060W_fao_ecozones_continents_processed.tif', 'Int16'], 'ipcc_class_2000': ['s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/00N_060W__IPCC_classes_2000.tif', 'Byte']}\n",
      "{'pixel_area': ['s3://gfw2-data/umd_area_2013/v1.10/raster/epsg-4326/10/40000/area_m/geotiff/00N_060W.tif', 'Float32'], 'agc_density_2000': ['s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/40000_pixels/20240821/00N_060W__AGC_density_MgC_ha_2000.tif', 'Float32'], 'bgc_density_2000': ['s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/BGC_density_MgC_ha/2000/40000_pixels/20240821/00N_060W__BGC_density_MgC_ha_2000.tif', 'Float32'], 'deadwood_density_2000': ['s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/deadwood_C_density_MgC_ha/2000/40000_pixels/20240821/00N_060W__deadwood_C_density_MgC_ha_2000.tif', 'Float32'], 'litter_density_2000': ['s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/litter_C_density_MgC_ha/2000/40000_pixels/20240821/00N_060W__litter_C_density_MgC_ha_2000.tif', 'Float32']}\n",
      "flm: Tile id 00N_060W exists for some inputs. Proceeding: 20241023_16_25_54 \n",
      "True\n",
      "flm: Requesting data in chunk -60_-10_-60_-10 in 00N_060W: 20241023_16_25_54\n",
      "{<Future at 0x7fa4a32339d0 state=finished returned ndarray>: 'climate_domain', <Future at 0x7fa4a32128f0 state=finished returned ndarray>: 'continent_ecozone', <Future at 0x7fa4a2e400d0 state=finished returned ndarray>: 'ipcc_class_2000'}\n",
      "flm: Tile id 00N_060W exists for some inputs. Proceeding: 20241023_16_26_04 \n",
      "True\n",
      "flm: Requesting data in chunk -60_-10_-60_-10 in 00N_060W: 20241023_16_26_04\n",
      "{<Future at 0x7fa4a32b1ab0 state=finished returned ndarray>: 'pixel_area', <Future at 0x7fa4a34f9180 state=finished returned ndarray>: 'agc_density_2000', <Future at 0x7fa4a34f8460 state=finished returned ndarray>: 'bgc_density_2000', <Future at 0x7fa4a3213070 state=finished returned ndarray>: 'deadwood_density_2000', <Future at 0x7fa4a3213fa0 state=finished returned ndarray>: 'litter_density_2000'}\n"
     ]
    }
   ],
   "source": [
    "is_final = False\n",
    "logger = lu.setup_logging()\n",
    "\n",
    "#bounds = uu.get_10x10_tile_bounds(tile_id)\n",
    "bounds = (-60, -10, -59.75, -9.75)\n",
    "chunk_length_pixels = uu.calc_chunk_length_pixels(bounds)\n",
    "\n",
    "# Replace tile_id in dictionaries with data_types\n",
    "updated_zone_dict = uu.replace_tile_id_in_dict(zone_dict_with_data_types, tile_id)\n",
    "print(updated_zone_dict)\n",
    "updated_stat_dict = uu.replace_tile_id_in_dict(stat_dict_with_data_types, tile_id)\n",
    "print(updated_stat_dict)\n",
    "\n",
    "# Download zone Layers\n",
    "tile_exists = uu.check_for_tile(updated_zone_dict, is_final, logger)\n",
    "print(tile_exists)\n",
    "# if not tile_exists:\n",
    "#     return f\"Skipped chunk {bounds_str} because {tile_id} does not exist for any inputs: {timestr()}\"\n",
    "\n",
    "zone_futures = uu.prepare_to_download_chunk(bounds, updated_zone_dict, chunk_length_pixels, is_final, logger)\n",
    "print(zone_futures)\n",
    "\n",
    "# Download Stat Layers\n",
    "tile_exists = uu.check_for_tile(updated_stat_dict, is_final, logger)\n",
    "print(tile_exists)\n",
    "# if not tile_exists:\n",
    "#     return f\"Skipped chunk {bounds_str} because {tile_id} does not exist for any inputs: {timestr()}\"\n",
    "\n",
    "stat_futures = uu.prepare_to_download_chunk(bounds, updated_stat_dict, chunk_length_pixels, is_final, logger)\n",
    "print(stat_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d782d9d-298a-46bd-948d-2636e8ad5d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type in layer 'continent_ecozone': int16\n",
      "Dimensions in layer 'continent_ecozone': (1000, 1000)\n",
      "Data type in layer 'climate_domain': int16\n",
      "Dimensions in layer 'climate_domain': (1000, 1000)\n",
      "Data type in layer 'ipcc_class_2000': uint8\n",
      "Dimensions in layer 'ipcc_class_2000': (1000, 1000)\n",
      "Unique values in layer continent_ecozone: [2020]\n",
      "Unique values in layer climate_domain: [1]\n",
      "Unique values in layer ipcc_class_2000: [1 3 5]\n"
     ]
    }
   ],
   "source": [
    "zone_layers = {}\n",
    "zone_layers_unique_values = {}\n",
    "\n",
    "# Waits for requests to come back with data from S3\n",
    "for zone_future in concurrent.futures.as_completed(zone_futures):\n",
    "    zone_layer = zone_futures[zone_future]\n",
    "    zone_layers[zone_layer] = zone_future.result()\n",
    "\n",
    "    # Get unique values for each layer and compute them\n",
    "    unique_values = dask.array.unique(zone_layers[zone_layer])\n",
    "    zone_layers_unique_values[zone_layer] = unique_values.compute()\n",
    "\n",
    "# Print data type and dimensions for each zone array\n",
    "for layer, array in zone_layers.items():\n",
    "    print(f\"Data type in layer '{layer}': {array.dtype}\")\n",
    "    print(f\"Dimensions in layer '{layer}': {array.shape}\")\n",
    "\n",
    "# Print unique values for each zone array\n",
    "for layer, unique_vals in zone_layers_unique_values.items():\n",
    "    print(f\"Unique values in layer {layer}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1602b4e5-783f-4578-8301-2e59e5cd8a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type in layer 'litter_density_2000': float32\n",
      "Dimensions in layer 'litter_density_2000': (1000, 1000)\n",
      "Data type in layer 'agc_density_2000': float32\n",
      "Dimensions in layer 'agc_density_2000': (1000, 1000)\n",
      "Data type in layer 'pixel_area': float32\n",
      "Dimensions in layer 'pixel_area': (1000, 1000)\n",
      "Data type in layer 'deadwood_density_2000': float32\n",
      "Dimensions in layer 'deadwood_density_2000': (1000, 1000)\n",
      "Data type in layer 'bgc_density_2000': float32\n",
      "Dimensions in layer 'bgc_density_2000': (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "stat_layers = {}\n",
    "\n",
    "# Waits for requests to come back with data from S3\n",
    "for stat_future in concurrent.futures.as_completed(stat_futures):\n",
    "    stat_layer = stat_futures[stat_future]\n",
    "    layer = stat_future.result()\n",
    "\n",
    "    # Mask nodata values using rioxarray's rio.nodata attribute\n",
    "    if hasattr(layer, 'rio'):\n",
    "        nodata_value = layer.rio.nodata\n",
    "        if nodata_value is not None:\n",
    "            # Mask nodata values in the array\n",
    "            layer = layer.where(layer != nodata_value)\n",
    "\n",
    "    # Store the masked layer\n",
    "    stat_layers[stat_layer] = layer\n",
    "    \n",
    "\n",
    "# Print data type and dimensions for each zone array\n",
    "for layer, array in stat_layers.items():\n",
    "    print(f\"Data type in layer '{layer}': {array.dtype}\")\n",
    "    print(f\"Dimensions in layer '{layer}': {array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae0037-ac46-490a-89c8-221fa2609740",
   "metadata": {},
   "source": [
    "<font size=\"4\">Bit shifting to get unique zone id for all zone_layers inputs</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b091c6f7-1106-4d56-b265-921af90af0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in combined result:\n",
      "[ 8137 16329 24521]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# Function to calculate the number of bits needed to represent the maximum value in the array\n",
    "def calculate_bits_needed(max_value):\n",
    "    return int(np.ceil(np.log2(max_value + 1)))\n",
    "\n",
    "# Convert numpy arrays to dask arrays if needed\n",
    "def ensure_dask_array(array, chunks=\"auto\"):\n",
    "    if isinstance(array, np.ndarray):\n",
    "        # Convert numpy array to dask array\n",
    "        return da.from_array(array, chunks=chunks)\n",
    "    return array  # Already a dask array\n",
    "\n",
    "# Ensure all layers have a consistent data type (int16) for bit-shifting\n",
    "def ensure_dtype(layer_array, dtype=np.int16):\n",
    "    if layer_array.dtype != dtype:\n",
    "        return layer_array.astype(dtype)\n",
    "    return layer_array\n",
    "\n",
    "# Prepare to dynamically combine layers using bit-shifting\n",
    "def combine_zone_layers(sorted_layers):\n",
    "    combined_array = None\n",
    "    total_shift = 0\n",
    "\n",
    "    # Loop through each layer\n",
    "    for layer_name, layer_array in sorted_layers:\n",
    "        # Convert to dask.array if it's a numpy array\n",
    "        layer_array = ensure_dask_array(layer_array)\n",
    "\n",
    "        # Convert layer to int16 if necessary for safe bit-shifting\n",
    "        layer_array = ensure_dtype(layer_array)\n",
    "\n",
    "        # Find the maximum value in the layer (using Dask's max function)\n",
    "        max_value = da.max(layer_array).compute()  # Compute to get the actual maximum value\n",
    "\n",
    "        # Determine the number of bits needed to represent this layer\n",
    "        bits_needed = calculate_bits_needed(max_value)\n",
    "\n",
    "        # Print unique values in the current layer before shifting\n",
    "        #print(f\"Unique values in layer '{layer_name}' before shifting: {np.unique(layer_array.compute())}\")\n",
    "\n",
    "        # Shift the layer by the cumulative number of bits (based on previous layers)\n",
    "        shifted_layer = layer_array << total_shift\n",
    "\n",
    "        # Print unique values in the current layer after shifting\n",
    "        #print(f\"Unique values in layer '{layer_name}' after shifting: {np.unique(shifted_layer.compute())}\")\n",
    "\n",
    "        # If this is the first layer, initialize the combined array\n",
    "        if combined_array is None:\n",
    "            combined_array = shifted_layer\n",
    "        else:\n",
    "            # Use bitwise OR to combine the shifted layer with the previous layers\n",
    "            combined_array = combined_array | shifted_layer\n",
    "\n",
    "        # Update the total bit shift for the next layer\n",
    "        total_shift += bits_needed\n",
    "\n",
    "    return combined_array\n",
    "\n",
    "# Sort zone_layers items to ensure consistent layer order\n",
    "zone_layers_sorted = sorted(zone_layers.items())\n",
    "#TODO: Overwrite zone layers as 1 object\n",
    "\n",
    "# Combine the zone layers dynamically\n",
    "combined_zone_array = combine_zone_layers(zone_layers_sorted)\n",
    "\n",
    "# Compute the final result from the combined Dask array\n",
    "combined_zone_result = combined_zone_array.compute()\n",
    "\n",
    "# Print the unique values in the combined result\n",
    "unique_values_combined_zones = np.unique(combined_zone_result)\n",
    "print(\"Unique values in combined result:\")\n",
    "print(unique_values_combined_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "294a2768-1fdd-4000-be28-4b3b86c1eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUT = COMBINED ZONE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ebb125-f615-4083-8a8e-9744ba541c3c",
   "metadata": {},
   "source": [
    "<font size=\"4\">Multiply densities/ fluxes by area to calculate gross values</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af853e4b-955e-4a38-b285-41123c5399d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictType[unicode_type,array(float32, 2d, C)]<iv=None>({agc_total_MgC: [[12.334657  12.691151  12.833748  ... 12.085113  12.19206   12.334657 ]\n",
       " [12.976335  12.726789  12.833737  ...  8.021086  12.156402  12.441595 ]\n",
       " [12.798079  13.154571  13.796258  ... 12.370288  12.013796  12.156393 ]\n",
       " ...\n",
       " [12.111825  11.292496  11.577479  ... 11.862463  12.147448  11.577479 ]\n",
       " [11.898077  11.755586  11.648716  ... 11.68434   11.57747   11.862453 ]\n",
       " [11.755577  11.506216  11.684331  ... 11.4705925 11.933691  12.076183 ]], bgc_total_MgC: [[3.7690954 3.878029  3.921602  ... 3.326815  3.356256  3.3955102]\n",
       " [3.9651725 3.888919  3.921599  ... 2.2080612 3.3464396 3.4249485]\n",
       " [3.910703  4.019636  4.215716  ... 3.4053187 3.3071826 3.3464372]\n",
       " ...\n",
       " [3.8250296 3.5662777 3.6562781 ... 2.494807  2.5547423 2.4348714]\n",
       " [3.7575257 3.7125258 3.6787755 ... 2.4573452 2.4348695 2.4948049]\n",
       " [3.7125232 3.6337724 3.690023  ... 2.4123921 2.5097868 2.5397546]], deadwood_total_MgC: [[0.7400794  0.76146907 0.77002484 ... 0.7251068  0.7315237  0.7400794 ]\n",
       " [0.77858007 0.7636074  0.7700242  ... 0.48126513 0.7293841  0.7464957 ]\n",
       " [0.7678847  0.7892743  0.8277754  ... 0.74221724 0.7208277  0.7293836 ]\n",
       " ...\n",
       " [0.7267095  0.6775498  0.69464874 ... 0.71174777 0.7288469  0.69464874]\n",
       " [0.7138846  0.70533514 0.698923   ... 0.70106035 0.6946482  0.71174717]\n",
       " [0.70533466 0.69037294 0.7010599  ... 0.6882355  0.7160214  0.724571  ]], litter_total_MgC: [[0.12334657 0.12691152 0.12833747 ... 0.12085112 0.12192061 0.12334657]\n",
       " [0.12976335 0.1272679  0.12833737 ... 0.08021086 0.12156402 0.12441596]\n",
       " [0.12798078 0.13154571 0.13796258 ... 0.12370287 0.12013795 0.12156393]\n",
       " ...\n",
       " [0.12111825 0.11292496 0.1157748  ... 0.11862464 0.12147447 0.1157748 ]\n",
       " [0.11898077 0.11755586 0.11648717 ... 0.11684339 0.11577471 0.11862454]\n",
       " [0.11755577 0.11506216 0.11684331 ... 0.11470593 0.11933691 0.12076183]], area_ha: [[0.07584957 0.07584957 0.07584957 ... 0.07584957 0.07584957 0.07584957]\n",
       " [0.07584951 0.07584951 0.07584951 ... 0.07584951 0.07584951 0.07584951]\n",
       " [0.07584946 0.07584946 0.07584946 ... 0.07584946 0.07584946 0.07584946]\n",
       " ...\n",
       " [0.07579365 0.07579365 0.07579365 ... 0.07579365 0.07579365 0.07579365]\n",
       " [0.07579359 0.07579359 0.07579359 ... 0.07579359 0.07579359 0.07579359]\n",
       " [0.07579353 0.07579353 0.07579353 ... 0.07579353 0.07579353 0.07579353]]})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "# JIT compiled function\n",
    "@jit(nopython=True)\n",
    "def calculate_total_mgc(agc, bgc, deadwood, litter, pixel_area):\n",
    "    # Get the shape of the arrays (assuming they are the same shape)\n",
    "    total_mgc_agc = np.zeros_like(agc)\n",
    "    total_mgc_bgc = np.zeros_like(bgc)\n",
    "    total_mgc_deadwood = np.zeros_like(deadwood)\n",
    "    total_mgc_litter = np.zeros_like(litter)\n",
    "    area_ha = np.zeros_like(litter)\n",
    "    \n",
    "    # Loop over each pixel\n",
    "    for i in range(agc.shape[0]):\n",
    "        for j in range(agc.shape[1]):\n",
    "            # Convert pixel_area from square meters to hectares\n",
    "            square_meters_to_hectares = 10000.0\n",
    "            area_in_hectares = pixel_area[i, j] / square_meters_to_hectares\n",
    "            \n",
    "            # Calculate total MgC for each density type\n",
    "            total_mgc_agc[i, j] = agc[i, j] * area_in_hectares\n",
    "            total_mgc_bgc[i, j] = bgc[i, j] * area_in_hectares\n",
    "            total_mgc_deadwood[i, j] = deadwood[i, j] * area_in_hectares\n",
    "            total_mgc_litter[i, j] = litter[i, j] * area_in_hectares\n",
    "            area_ha[i,j] = area_in_hectares\n",
    "    \n",
    "    # Return as a dictionary\n",
    "    return {\n",
    "        'agc_total_MgC': total_mgc_agc,\n",
    "        'bgc_total_MgC': total_mgc_bgc,\n",
    "        'deadwood_total_MgC': total_mgc_deadwood,\n",
    "        'litter_total_MgC': total_mgc_litter, \n",
    "        'area_ha': area_ha\n",
    "    }\n",
    "\n",
    "# Call the JIT-compiled function and return a dictionary\n",
    "total_mgc_dict = calculate_total_mgc(\n",
    "    stat_layers['agc_density_2000'], stat_layers['bgc_density_2000'], stat_layers['deadwood_density_2000'], stat_layers['litter_density_2000'], stat_layers['pixel_area'])\n",
    "\n",
    "total_mgc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ae637-82d6-4298-8552-72f4e11be4ad",
   "metadata": {},
   "source": [
    "<font size=\"4\">Calculate Zonal Stats</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cba858a6-9ff0-445b-8762-721c22095d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error during deserialization of the task graph. This frequently\noccurs if the Scheduler and Client have different environments.\nFor more information, see\nhttps://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/scheduler.py:4611\u001b[0m, in \u001b[0;36mupdate_graph\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/serialize.py:439\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/serialize.py:101\u001b[0m, in \u001b[0;36mpickle_loads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/pickle.py:94\u001b[0m, in \u001b[0;36mloads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/__init__.py:1\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/aspect.py:10\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/utils.py:4\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/__init__.py:12\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/pipeline.py:5\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/transfer_functions/__init__.py:14\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/PIL/Image.py:100\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libtiff.so.5: cannot open shared object file: No such file or directory",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#Make sure zone is a numpy array\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#combined_zone_result = np.array(combined_zone_result, dtype=np.int16, copy=True)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Call the function and get the zonal stats as a DataFrame\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m zonal_stats_df \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_zonal_stats_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_mgc_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_zone_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the resulting DataFrame\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(zonal_stats_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[144], line 58\u001b[0m, in \u001b[0;36mcompute_zonal_stats_to_dataframe\u001b[0;34m(total_mgc_dict, combined_zone_result)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Gather the results from the futures and convert them to DataFrames\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, future \u001b[38;5;129;01min\u001b[39;00m zonal_stats_futures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 58\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Convert the stats dictionary to a DataFrame for this layer\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stats)\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/distributed/client.py:322\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/distributed/client.py:330\u001b[0m, in \u001b[0;36mFuture._result\u001b[0;34m(self, raiseit)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raiseit:\n\u001b[1;32m    329\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m exc\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error during deserialization of the task graph. This frequently\noccurs if the Scheduler and Client have different environments.\nFor more information, see\nhttps://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "from xrspatial import zonal_stats\n",
    "\n",
    "\n",
    "# #Function to compute zonal stats using Dask futures and return a pandas DataFrame\n",
    "# def compute_zonal_stats_to_dataframe(layers, zone):\n",
    "#     zonal_stats_futures = {}\n",
    "\n",
    "#     # Iterate over the layers in the total_mgc_dict\n",
    "#     for layer_name, layer_data in layers.items():\n",
    "        \n",
    "#         # Use Dask futures to compute zonal statistics in parallel\n",
    "#         future = client.submit(zonal_stats, zones=zone, values=layer_data, stats_funcs=['mean', 'sum', 'min', 'max'])\n",
    "#         zonal_stats_futures[layer_name] = future\n",
    "\n",
    "#     # Create an empty list to hold all data frames for each layer\n",
    "#     all_layer_dfs = []\n",
    "\n",
    "#     # Gather the results from the futures and convert them to DataFrames\n",
    "#     for layer_name, future in zonal_stats_futures.items():\n",
    "#         stats = future.result()\n",
    "\n",
    "#         # Convert the stats dictionary to a DataFrame for this layer\n",
    "#         df = pd.DataFrame(stats)\n",
    "#         df['layer'] = layer_name  # Add a column for the layer name\n",
    "\n",
    "#         # Append this DataFrame to the list\n",
    "#         all_layer_dfs.append(df)\n",
    "\n",
    "#     # Concatenate all DataFrames into one DataFrame\n",
    "#     final_df = pd.concat(all_layer_dfs)\n",
    "\n",
    "#     return final_df\n",
    "\n",
    "def compute_zonal_stats_to_dataframe(total_mgc_dict, combined_zone_result):\n",
    "    zonal_stats_futures = {}\n",
    "\n",
    "    # Ensure that the combined_zone_result is an xr DataArray for zonal_stats function\n",
    "    combined_zone_result = xr.DataArray(combined_zone_result)  \n",
    "\n",
    "    # Iterate over the layers in the total_mgc_dict\n",
    "    for layer_name, layer_data in total_mgc_dict.items():\n",
    "        # Ensure layer_data is an xr DataArray for zonal_stats function\n",
    "        layer_data = xr.DataArray(layer_data) \n",
    "\n",
    "        # Use Dask futures to compute zonal statistics in parallel\n",
    "        future = client.submit(zonal_stats, zones=combined_zone_result, values=layer_data, stats_funcs=['count', 'sum', 'min', 'max'])\n",
    "        zonal_stats_futures[layer_name] = future\n",
    "\n",
    "    # Create an empty list to hold all data frames for each layer\n",
    "    all_layer_dfs = []\n",
    "\n",
    "    # Gather the results from the futures and convert them to DataFrames\n",
    "    for layer_name, future in zonal_stats_futures.items():\n",
    "        stats = future.result()\n",
    "\n",
    "        # Convert the stats dictionary to a DataFrame for this layer\n",
    "        df = pd.DataFrame(stats)\n",
    "        df['layer'] = layer_name  # Add a column for the layer name\n",
    "\n",
    "        # Append this DataFrame to the list\n",
    "        all_layer_dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one DataFrame\n",
    "    final_df = pd.concat(all_layer_dfs)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "#Make sure zone is a numpy array\n",
    "#combined_zone_result = np.array(combined_zone_result, dtype=np.int16, copy=True)\n",
    "\n",
    "# Call the function and get the zonal stats as a DataFrame\n",
    "zonal_stats_df = compute_zonal_stats_to_dataframe(total_mgc_dict, combined_zone_result)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(zonal_stats_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc3b37bf-1f1e-4ed0-93ce-4b9ce126f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melrose94/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/dask/dataframe/multi.py:1297: UserWarning: Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indices of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error during deserialization of the task graph. This frequently\noccurs if the Scheduler and Client have different environments.\nFor more information, see\nhttps://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/scheduler.py:4611\u001b[0m, in \u001b[0;36mupdate_graph\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/serialize.py:439\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/serialize.py:101\u001b[0m, in \u001b[0;36mpickle_loads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/distributed/protocol/pickle.py:94\u001b[0m, in \u001b[0;36mloads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/__init__.py:1\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/aspect.py:10\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/xrspatial/utils.py:4\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/__init__.py:12\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/pipeline.py:5\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/datashader/transfer_functions/__init__.py:14\u001b[0m\n",
      "File \u001b[0;32m/opt/coiled/env/lib/python3.10/site-packages/PIL/Image.py:103\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libtiff.so.5: cannot open shared object file: No such file or directory",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, array \u001b[38;5;129;01min\u001b[39;00m stat_layers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Ensure each layer is a Dask array and wrap it in an xarray.DataArray\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     array \u001b[38;5;241m=\u001b[39m da\u001b[38;5;241m.\u001b[39mfrom_array(array)\n\u001b[0;32m---> 36\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_all_zonal_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_zone_da\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[0;32mIn[123], line 22\u001b[0m, in \u001b[0;36mrun_all_zonal_stats\u001b[0;34m(zone, layer, layer_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m layer_da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(layer)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Apply zonal stats\u001b[39;00m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mzonal_stats\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzones\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstats_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m---> 22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_count\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_min\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m })\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/dask/dataframe/core.py:5435\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   5432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5433\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshuffle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_index\n\u001b[0;32m-> 5435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpartitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdivisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdivisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5441\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5442\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/dask/dataframe/shuffle.py:242\u001b[0m, in \u001b[0;36mset_index\u001b[0;34m(df, index, npartitions, shuffle, compute, drop, upsample, divisions, partition_size, sort, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     index2 \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m divisions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     divisions, mins, maxes, presorted \u001b[38;5;241m=\u001b[39m \u001b[43m_calculate_divisions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_size\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m presorted \u001b[38;5;129;01mand\u001b[39;00m npartitions \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mnpartitions:\n\u001b[1;32m    247\u001b[0m         divisions \u001b[38;5;241m=\u001b[39m mins \u001b[38;5;241m+\u001b[39m [maxes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/dask/dataframe/shuffle.py:54\u001b[0m, in \u001b[0;36m_calculate_divisions\u001b[0;34m(df, partition_col, repartition, npartitions, upsample, partition_size, ascending)\u001b[0m\n\u001b[1;32m     51\u001b[0m maxes \u001b[38;5;241m=\u001b[39m partition_col\u001b[38;5;241m.\u001b[39mmap_partitions(M\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     divisions, sizes, mins, maxes \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdivisions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# When there are nulls and a column is non-numeric, a TypeError is sometimes raised as a result of\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# 1) computing mins/maxes above, 2) every null being switched to NaN, and 3) NaN being a float.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Also, Pandas ExtensionDtypes may cause TypeErrors when dealing with special nulls such as pd.NaT or pd.NA.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# If this happens, we hint the user about eliminating nulls beforehand.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_numeric_dtype(partition_col\u001b[38;5;241m.\u001b[39mdtype):\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/anaconda3/envs/coiled_updated/lib/python3.10/site-packages/distributed/client.py:2244\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         exc \u001b[38;5;241m=\u001b[39m CancelledError(key)\n\u001b[1;32m   2243\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error during deserialization of the task graph. This frequently\noccurs if the Scheduler and Client have different environments.\nFor more information, see\nhttps://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import dask.array as da\n",
    "from xrspatial import zonal_stats  \n",
    "\n",
    "# Ensure combined_zone_result is converted to a Dask array (if it's not already)\n",
    "combined_zone_result = da.from_array(combined_zone_result)\n",
    "\n",
    "# Wrap combined_zone_result in an xarray.DataArray\n",
    "combined_zone_da = xr.DataArray(combined_zone_result)\n",
    "\n",
    "# Function to process all zonal stats calls for a tile\n",
    "def run_all_zonal_stats(zone, layer, layer_name):\n",
    "    \n",
    "    # Convert Dask array to xarray.DataArray\n",
    "    layer_da = xr.DataArray(layer)\n",
    "    \n",
    "    # Apply zonal stats\n",
    "    result = zonal_stats(\n",
    "        zones=zone,\n",
    "        values=layer_da,\n",
    "        stats_funcs=[\"sum\", \"count\", \"min\", \"max\"]\n",
    "    ).set_index(\"zone\").rename(columns={\n",
    "        \"count\": f\"{layer_name}_count\",\n",
    "        \"sum\": f\"{layer_name}_sum\",\n",
    "        \"min\": f\"{layer_name}_min\",\n",
    "        \"max\": f\"{layer_name}_max\"\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# For loop to run all zonal stats per tile\n",
    "futures = []\n",
    "\n",
    "for layer, array in stat_layers.items():\n",
    "    # Ensure each layer is a Dask array and wrap it in an xarray.DataArray\n",
    "    array = da.from_array(array)\n",
    "    result = run_all_zonal_stats(combined_zone_da, array, layer)\n",
    "    results.append(result)\n",
    "\n",
    "print(results)\n",
    "#TODO change to use future instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87583b-508f-4070-91d2-ed6bf0ad593f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5757966-8d77-4fcb-80f4-a50a70d3831c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319f8e4-8e95-479a-947f-26f4d109898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_zone_result)\n",
    "print(combined_zone_result.dtype)\n",
    "print(combined_zone_result.shape)\n",
    "\n",
    "for layer, array in stat_layers.items():\n",
    "    print(layer)\n",
    "    print(array)\n",
    "    print(array.dtype)\n",
    "    print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992579b-2f88-4a70-8f89-f461ab21b811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b088c5-6487-4b1b-94d4-835bb89ed0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fc22d-4a14-4228-86c4-1de9b12c76d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14c232b-687e-4495-9d60-8347a3472cfc",
   "metadata": {},
   "source": [
    "<font size=\"4\">Reverse bit shifting to get original layer values for combined zone inputs</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d600e3-2d42-45ef-805b-413282e65ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST Example dask data frame with zonal stats values by bit-shifted zone\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "zone_df = pd.DataFrame({'bit_shifted_values': unique_values_combined_zones})\n",
    "\n",
    "# Print the Dask DataFrame to verify\n",
    "print(zone_df)\n",
    "print(zone_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c96e9-3d34-4a97-9a65-6c9694805080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reverse the bit-shifting process\n",
    "def reverse_bit_shifting(df, column_name, sorted_layers):\n",
    "    \"\"\"\n",
    "    Reverse the bit-shifting operation and extract the original values for each layer.\n",
    "\n",
    "    Parameters:\n",
    "    - df: the Pandas DataFrame containing the combined bit-shifted values.\n",
    "    - column_name: the name of the column that contains the bit-shifted values.\n",
    "    - sorted_layers: a dictionary containing the original Dask arrays (for each layer) sorted alpahbaetically.\n",
    "\n",
    "    Returns:\n",
    "    - df: a Pandas DataFrame with new columns for each original layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate bits_needed_per_layer based on max values from Dask arrays in sorted_layers\n",
    "    bits_needed_per_layer = []\n",
    "    \n",
    "    for layer_name, layer_array in sorted_layers:\n",
    "        # Ensure the layer is a Dask array and calculate max value\n",
    "        layer_array = ensure_dask_array(layer_array)\n",
    "        max_value = da.max(layer_array).compute()  # Compute the maximum value\n",
    "        \n",
    "        # Determine the number of bits needed to represent this layer\n",
    "        bits_needed = calculate_bits_needed(max_value)\n",
    "        bits_needed_per_layer.append(bits_needed)\n",
    "\n",
    "    total_shift = sum(bits_needed_per_layer)  # Start with the total bits used\n",
    "\n",
    "    # Reverse bit-shifting: loop through each layer in reverse order\n",
    "    layers = [layer_name for layer_name, _ in sorted_layers]  # Get the sorted layer names\n",
    "    for i in range(len(layers)-1, -1, -1):\n",
    "        layer = layers[i]\n",
    "        bits_needed = bits_needed_per_layer[i]\n",
    "        total_shift -= bits_needed\n",
    "        # Create a mask for extracting the current layer\n",
    "        mask = (1 << bits_needed) - 1\n",
    "        # Shift right and apply the mask to extract the current layer's values\n",
    "        df[layer] = df[column_name].apply(lambda x: (x >> total_shift) & mask)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Reverse the bit-shifting\n",
    "parse_zone_data = reverse_bit_shifting(zone_df, 'bit_shifted_values', zone_layers_sorted)\n",
    "\n",
    "# Print the Pandas DataFrame to verify the results\n",
    "print(parse_zone_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a770a-4fe8-4bd8-bf5b-51798183ff5c",
   "metadata": {},
   "source": [
    "<font size=\"5\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "04274265-7cb9-4b95-8852-17d3023370f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local client shut down\n"
     ]
    }
   ],
   "source": [
    "if cluster_type in ['full', 'test']: \n",
    "    coiled_cluster.shutdown()\n",
    "    print('coiled cluster shut down')\n",
    "elif cluster_type == 'local':\n",
    "    client.shutdown()\n",
    "    print('local client shut down')\n",
    "else: \n",
    "    print(\"No clusters were shut down. Check that cluster_type is set to one of the following: 'full', 'test', 'local'\")\n",
    "\n",
    "# coiled_client.restart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f66fc8-da5f-4a64-9baa-1375f213084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d536db7-c9ee-4d0f-9aa3-ec662ebe7dc7",
   "metadata": {},
   "source": [
    "<font size=\"5\">Zone Inputs (Categorical)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4e768-f8c3-43d3-a920-7091736ffe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gadm boundary tiles\n",
    "# iso_gadm_uri = 's3://gfw-data-lake/gadm_administrative_boundaries/v3.6/raster/epsg-4326/10/40000/adm0/geotiff/'\n",
    "# iso_gadm_pattern = ''\n",
    "\n",
    "# climate_domain_path = \"s3://gfw2-data/climate/carbon_model/inputs_for_carbon_pools/processed/fao_ecozones_bor_tem_tro/20190418/\"\n",
    "# climate_domain_pattern = \"fao_ecozones_bor_tem_tro_processed\"\n",
    "\n",
    "# continent_ecozone_path = \"s3://gfw2-data/climate/carbon_model/fao_ecozones/ecozone_continent/20190116/processed/\"\n",
    "# continent_ecozone_pattern = \"fao_ecozones_continents_processed\"\n",
    "\n",
    "\n",
    "\n",
    "# # MODEL OUTPUT SHAPEFILES\n",
    "# # # IPCC reporting classes\n",
    "# # ipcc_class_2000 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2000__10x10.shp'\n",
    "# # ipcc_class_2005 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2005__10x10.shp'\n",
    "# # ipcc_class_2010 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2010__10x10.shp'\n",
    "# # ipcc_class_2015 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2015__10x10.shp'\n",
    "# # ipcc_class_2020 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/40000_pixels/20240205/raster_footprints_IPCC_basic_classes_2020__10x10.shp'\n",
    "\n",
    "# # # IPCC change classes\n",
    "# # ipcc_change_2005 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2000_2005__10x105.shp'\n",
    "# # ipcc_change_2010 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2005_2010__10x10.shp'\n",
    "# # ipcc_change_2015 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2010_2015__10x10.shp'\n",
    "# # ipcc_change_2020 = 's3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/raster_footprints_IPCC_basic_change_2015_2020__10x10.shp'\n",
    "\n",
    "# # 2000 carbon densities \n",
    "# AGC_density_2000 = 'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/40000_pixels/20240729/raster_footprints_AGC_2000__global__10x10.shp'\n",
    "# BGC_density_2000 = 'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/BGC_density_MgC_ha/2000/40000_pixels/20240729/raster_footprints_BGC_2000__global__10x10.shp'\n",
    "# deadwood_C_density_2000 = 'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/deadwood_C_density_MgC_ha/2000/40000_pixels/20240729/raster_footprints_deadwood_C_2000__global__10x10.shp'\n",
    "# litter_C_density = 'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/litter_C_density_MgC_ha/2000/40000_pixels/20240729/raster_footprints_litter_C_2000__global__10x10.shp'\n",
    "\n",
    "#TODO: Include land state nodes? --> no shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d8c79-c523-4067-aa17-30fdda751f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rasterize vector data\n",
    "# name path column\n",
    "\n",
    "# shapefile = gpd.read_file(path)\n",
    "# utm = shapefile.to_crs(\"EPSG:4326\")\n",
    "# geom = utm[['geometry', column]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04398b2a-4f46-4743-9f27-96547d18553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lazily \"computing\" tile sets\n",
    "# iso_gadm = get_tile_dataset(iso_gadm_uri, tile, \"iso\")\n",
    "# iso_gadm = iso_gadm.where(iso_gadm != 9999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
