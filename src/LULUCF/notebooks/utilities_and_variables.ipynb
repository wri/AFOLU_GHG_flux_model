{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b03b028-4f73-430d-99ee-2f0c3abdfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import math\n",
    "import ctypes\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.distributed import print as dask_print\n",
    "import dask.config\n",
    "import distributed\n",
    "\n",
    "# scipy basics\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.transform\n",
    "import rasterio.windows\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "from rioxarray.merge import merge_arrays\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from numba import jit\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7941a7-20f8-4bf9-b233-4f11a42b4007",
   "metadata": {},
   "source": [
    "<font size=\"6\">Cluster management</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533792-2e4c-4693-b73e-0896ed25e66a",
   "metadata": {},
   "source": [
    "<font size=\"5\">Creating clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d54031-7caf-4ebf-9a0a-b2742f01b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full cluster\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=40,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"AFOLU_flux_model\", \n",
    "    account='jterry64', # Necessary to use the AWS environment that Justin set up in Coiled\n",
    "    worker_memory = \"64GiB\" \n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677f6327-d54b-4918-9528-e9f9ad3d95d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c258bf4e952445b8a4390883c914605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Package - bcrypt, bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Package - bcrypt, bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Package Info</span> ──────────────────────────────────────────╮\n",
       "│                                  ╷                                                               │\n",
       "│  <span style=\"font-weight: bold\"> Package                        </span>│<span style=\"font-weight: bold\"> Note                                                        </span>  │\n",
       "│ ╶────────────────────────────────┼─────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                     │ https://pypi.org/pypi                                         │\n",
       "│                                  ╵                                                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────── \u001b[1;32mPackage Info\u001b[0m ──────────────────────────────────────────╮\n",
       "│                                  ╷                                                               │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage                       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mNote                                                       \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶────────────────────────────────┼─────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                     │ https://pypi.org/pypi                                         │\n",
       "│                                  ╵                                                               │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Not Synced with Cluster</span> ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  <span style=\"font-weight: bold\"> Package  </span>│<span style=\"font-weight: bold\"> Error                                                                   </span>│<span style=\"font-weight: bold\"> Risk    </span>  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge      │ Warning   │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────── \u001b[1;31mNot Synced with Cluster\u001b[0m ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mError                                                                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mRisk   \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ bcrypt==4.1.0 has no install candidate for linux-64 on conda-forge      │ Warning   │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7301585de69a463093ca2d90db3ff511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-4a113cb0-c75c-11ee-91ab-00155d1a3851</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> coiled.Cluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://cluster-rqfvh.dask.host/fs35ksT-Oeh8vuJ8/status\" target=\"_blank\">https://cluster-rqfvh.dask.host/fs35ksT-Oeh8vuJ8/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">Cluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">AFOLU_flux_model</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://cluster-rqfvh.dask.host/fs35ksT-Oeh8vuJ8/status\" target=\"_blank\">https://cluster-rqfvh.dask.host/fs35ksT-Oeh8vuJ8/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-26082be5-6ae0-4c24-bdc2-7962df4c3312</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.0.83.139:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.0.83.139:8787/status\" target=\"_blank\">http://10.0.83.139:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.0.83.139:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cluster\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=4,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"AFOLU_flux_model\", \n",
    "    account='jterry64', # Necessary to use the AWS environment that Justin set up in Coiled\n",
    "    worker_memory = \"32GiB\" \n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cf73e-6053-48ca-a53e-f8b5f82ec626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "local_client = Client(processes=False)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da34549-1d5e-4651-9285-66a5bb0e49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client = Client()\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa755d07-33cf-42b7-b8bf-d1ef9360e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster with multiple workers\n",
    "local_cluster = LocalCluster()  \n",
    "local_client = Client(local_cluster)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab8d1f-ffda-421f-869f-f5ab03a4eb5d",
   "metadata": {},
   "source": [
    "<font size=\"5\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89d4f0-98e5-4144-bac9-3d70d4b60de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_client.restart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab2ee2-0137-4c03-9ec5-2b7513f3c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75688b5e-8b9c-4c1b-a2e3-19209c69062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b80cda-51e8-4f33-b820-c71fb77b5887",
   "metadata": {},
   "source": [
    "<font size=\"6\">Variables</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185f97d9-ee21-42ad-9e49-097878c8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "composite_LC_uri = 's3://gfw2-data/landcover/composite'\n",
    "\n",
    "s3_out_dir = 'climate/AFOLU_flux_model/LULUCF/outputs'\n",
    "\n",
    "IPCC_class_max_val = 6\n",
    "\n",
    "# IPCC codes\n",
    "forest = 1\n",
    "cropland = 2\n",
    "settlement = 3\n",
    "wetland = 4\n",
    "grassland = 5\n",
    "otherland = 6\n",
    "\n",
    "first_year = 2000\n",
    "last_year = 2020\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket('gfw2-data')\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "full_raster_dims = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58988e0-ec13-4ffc-91ad-a2b9c524d449",
   "metadata": {},
   "source": [
    "<font size=\"6\">General functions</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa51beb-6d2b-4db2-a374-db2dd3c176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestr():\n",
    "    return time.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "def boundstr(bounds):\n",
    "    bounds_str = \"_\".join([str(round(x)) for x in bounds])\n",
    "    return bounds_str\n",
    "\n",
    "def calc_chunk_length_pixels(bounds):\n",
    "    chunk_length_pixels = int((bounds[3]-bounds[1]) * (40000/10))\n",
    "    return chunk_length_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a7c613-1283-4ccf-abf7-bd908315945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of all chunk boundaries within a bounding box for chunks of a given size\n",
    "def get_chunk_bounds(chunk_params):\n",
    "\n",
    "    min_x = chunk_params[0]\n",
    "    min_y = chunk_params[1]\n",
    "    max_x = chunk_params[2]\n",
    "    max_y = chunk_params[3]\n",
    "    chunk_size = chunk_params[4]\n",
    "    \n",
    "    x, y = (min_x, min_y)\n",
    "    chunks = []\n",
    "\n",
    "    # Polygon Size\n",
    "    while y < max_y:\n",
    "        while x < max_x:\n",
    "            bounds = [\n",
    "                x,\n",
    "                y,\n",
    "                x + chunk_size,\n",
    "                y + chunk_size,\n",
    "            ]\n",
    "            chunks.append(bounds)\n",
    "            x += chunk_size\n",
    "        x = min_x\n",
    "        y += chunk_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8e89ff-01ff-4446-83db-39c3910d0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the encompassing tile_id string in the form YYN/S_XXXE/W based on a coordinate\n",
    "def xy_to_tile_id(top_left_x, top_left_y):\n",
    "\n",
    "    lat_ceil = math.ceil(top_left_y/10.0) * 10\n",
    "    lng_floor = math.floor(top_left_x/10.0) * 10\n",
    "    \n",
    "    lng: str = f\"{str(lng_floor).zfill(3)}E\" if (lng_floor >= 0) else f\"{str(-lng_floor).zfill(3)}W\"\n",
    "    lat: str = f\"{str(lat_ceil).zfill(2)}N\" if (lat_ceil >= 0) else f\"{str(-lat_ceil).zfill(2)}S\"\n",
    "\n",
    "    return f\"{lat}_{lng}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09504ef-06ec-444d-8ea3-bd15154c6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazily opens tile within provided bounds (i.e. one chunk) and returns as a numpy array\n",
    "# If it can't open the chunk (no data in it), it returns an array of the specified nodata value.\n",
    "# TODO: It would be better if this just didn't return any array at all if there's no chunk. Returning an array of nodata is pretty inefficient.  \n",
    "def get_tile_dataset_rio(uri, bounds, chunk_length_pixels, no_data_val):\n",
    "\n",
    "    bounds_str = boundstr(bounds)\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(uri) as ds:\n",
    "            window = rasterio.windows.from_bounds(*bounds, ds.transform)\n",
    "            data = ds.read(1, window=window)\n",
    "    except:\n",
    "        data = np.full((chunk_length_pixels, chunk_length_pixels), no_data_val)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13dfd7a3-1173-4a04-88dd-6d847ccb9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares list of chunks to download.\n",
    "# Chunks are defined by a bounding box.\n",
    "def prepare_to_download_chunk(bounds, download_dict, no_data_val):\n",
    " \n",
    "    futures = {}\n",
    "\n",
    "    bounds_str = boundstr(bounds)\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)\n",
    "\n",
    "    # Submit requests to S3 for input chunks but don't actually download them yet. This queueing of the requests before downloading them speeds up the downloading\n",
    "    # Approach is to download all the input chunks up front for every year to make downloading more efficient, even though it means storing more upfront\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        \n",
    "        dask_print(f\"Requesting data in chunk {bounds_str} in {tile_id}: {timestr()}\")\n",
    "\n",
    "        for key, value in download_dict.items():\n",
    "            futures[executor.submit(get_tile_dataset_rio, value, bounds, chunk_length_pixels, no_data_val)] = key\n",
    "\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c26e191-cadf-47f1-8135-436b319081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if tiles exist at all\n",
    "def check_for_tile(download_dict):\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while i < len(list(download_dict.values())):\n",
    "\n",
    "        s3_key = list(download_dict.values())[i][15:]\n",
    "\n",
    "        # Breaks the loop if the tile exists\n",
    "        try:\n",
    "            s3.head_object(Bucket='gfw2-data', Key=s3_key)\n",
    "            dask_print(f\"Tile id {list(download_dict.values())[i][-12:-4]} exists. Proceeding.\")\n",
    "            return 1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    dask_print(f\"Tile id {list(download_dict.values())[0][-12:-4]} does not exist. Skipping chunk.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118219c7-4151-42c8-a044-30a1f1709039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks whether a chunk has data in it\n",
    "def check_chunk_for_data(layers, item_to_check, bounds_str, tile_id, no_data_val):\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while i < len(list(layers.values())):\n",
    "\n",
    "        # Checks if all the pixels have the nodata value\n",
    "        min = np.min(list(layers.values())[i])  # Can't use np.all because it doesn't work in chunks that are mostly water; says nodata in chunk even if there is land\n",
    "\n",
    "        # Breaks the loop if there is data in the chunk\n",
    "        if min < no_data_val:\n",
    "            dask_print(f\"Data in chunk {bounds_str}. Proceeding.\")\n",
    "            return 1\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    dask_print(f\"No data in chunk {bounds_str} for any input.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a63159-8e5e-4787-9fb8-0b696de77492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves array as a raster locally, then uploads it to s3\n",
    "def save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, bounds_str, output_dict, is_final):\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call\n",
    "\n",
    "    transform = rasterio.transform.from_bounds(*bounds, width=chunk_length_pixels, height=chunk_length_pixels)\n",
    "\n",
    "    file_info = f'{tile_id}__{bounds_str}'\n",
    "\n",
    "    # For every output file, saves from array to local raster, then to s3.\n",
    "    # Can't save directly to s3, unfortunately, so need to save locally first.\n",
    "    for key, value in output_dict.items():\n",
    "\n",
    "        data_array = value[0]\n",
    "        data_meaning = value[2]\n",
    "        year_out = value[3]\n",
    "\n",
    "        array_dtype = data_array.dtype\n",
    "\n",
    "        if not is_final:\n",
    "            dask_print(f\"Saving {bounds_str} in {tile_id} for {year_out}: {timestr()}\")\n",
    "\n",
    "        if is_final:\n",
    "            file_name = f\"{file_info}__{key}.tif\"\n",
    "        else:\n",
    "            file_name = f\"{file_info}__{key}__{timestr()}.tif\"\n",
    "\n",
    "        with rasterio.open(f\"/tmp/{file_name}\", 'w', driver='GTiff', width=chunk_length_pixels, height=chunk_length_pixels, count=1, dtype='uint8', crs='EPSG:4326', transform=transform, compress='lzw', blockxsize=400, blockysize=400) as dst:\n",
    "            dst.write(data_array.astype(rasterio.uint8), 1)\n",
    "\n",
    "        s3_path = f\"{s3_out_dir}/{data_meaning}/{year_out}/{chunk_length_pixels}_pixels/{time.strftime('%Y%m%d')}\"\n",
    "\n",
    "        if not is_final:\n",
    "            dask_print(f\"Uploading {bounds_str} in {tile_id} for {year_out} to {s3_path}: {timestr()}\")\n",
    "\n",
    "        s3_client.upload_file(f\"/tmp/{file_name}\", \"gfw2-data\", Key=f\"{s3_path}/{file_name}\")\n",
    "\n",
    "        # Deletes the local raster\n",
    "        os.remove(f\"/tmp/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d4e5c0-48e6-4169-834e-e1fac16f8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists rasters in an s3 folder and returns their names as a list\n",
    "def list_rasters_in_folder(full_in_folder):\n",
    "\n",
    "    cmd = ['aws', 's3', 'ls', full_in_folder]\n",
    "    s3_contents_bytes = subprocess.check_output(cmd)\n",
    "\n",
    "    # Converts subprocess results to useful string\n",
    "    s3_contents_str = s3_contents_bytes.decode('utf-8')\n",
    "    s3_contents_list = s3_contents_str.splitlines()\n",
    "    rasters = [line.split()[-1] for line in s3_contents_list]\n",
    "    rasters = [i for i in rasters if \"tif\" in i]\n",
    "\n",
    "    return rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ddc2d7-2427-4f47-8e16-ed01c507f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploads a shapefile to s3\n",
    "def upload_shp(full_in_folder, in_folder, shp):\n",
    "\n",
    "    dask_print(f\"Uploading to {full_in_folder}{shp}: {timestr()}\")\n",
    "\n",
    "    shp_pattern = shp[:-4]\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")  # Needs to be in the same function as the upload_file call\n",
    "    s3_client.upload_file(f\"/tmp/{shp}\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp}\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.dbf\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.dbf\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.prj\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.prj\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.shx\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.shx\")\n",
    "\n",
    "    os.remove(f\"/tmp/{shp}\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.dbf\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.prj\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.shx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42b56bce-7231-4a98-8bda-be30e47e25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a shapefile of the footprints of rasters in a folder, for checking geographical completeness of rasters\n",
    "def make_tile_footprint_shp(input_dict):\n",
    "\n",
    "    in_folder = list(input_dict.keys())[0]\n",
    "    pattern = list(input_dict.values())[0]\n",
    "\n",
    "    # Task properties\n",
    "    dask_print(f\"Making tile index shapefile for: {in_folder}: {timestr()}\")\n",
    "\n",
    "    # Folder including s3 key\n",
    "    s3_in_folder = f's3://{in_folder}'\n",
    "    vsis3_in_folder = f'/vsis3/{in_folder}'\n",
    "\n",
    "    # List of all the filenames in the folder\n",
    "    filenames = list_rasters_in_folder(s3_in_folder)\n",
    "\n",
    "    # List of the tile paths in the folder\n",
    "    tile_paths = []\n",
    "    tile_paths = [vsis3_in_folder + filename for filename in filenames]\n",
    "\n",
    "    file_paths = 's3_paths.txt'\n",
    "\n",
    "    with open(f\"/tmp/{file_paths}\", 'w') as file:\n",
    "        for item in tile_paths:\n",
    "            file.write(item + '\\n')\n",
    "\n",
    "    # Output shapefile name\n",
    "    shp = f\"raster_footprints_{pattern}.shp\"\n",
    "\n",
    "    cmd = [\"gdaltindex\", \"-t_srs\", \"EPSG:4326\", f\"/tmp/{shp}\", \"--optfile\", f\"/tmp/{file_paths}\"]\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "    # Uploads shapefile to s3\n",
    "    upload_shp(s3_in_folder, in_folder, shp)\n",
    "\n",
    "    return(f\"Completed: {timestr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12628166-1647-41be-87af-35e873510f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    return [x for xs in nested_list for x in xs]\n",
    "\n",
    "def create_list_for_aggregation(s3_in_folders):\n",
    "\n",
    "    list_of_s3_name_dicts_total = []   # Final list of dictionaries of s3 paths and output aggregated 10x10 rasters\n",
    "    \n",
    "    # Iterates through all the desired s3 folders\n",
    "    for s3_in_folder in s3_in_folders:\n",
    "    \n",
    "        simple_file_names = []   # List of output aggregatd 10x10 rasters\n",
    "    \n",
    "        # Raw filenames in a folder\n",
    "        filenames = list_rasters_in_folder(f\"s3://{s3_in_folder}\")\n",
    "    \n",
    "        # Iterates through all the files in a folder and converts them to the output names. \n",
    "        # Essentially [tile_id]__[pattern].tif. Drops the chunk bounds from the middle.\n",
    "        for filename in filenames:\n",
    "        \n",
    "            result = filename[:10] + filename[filename.rfind(\"__\") + len(\"__\"):]   # Extracts the relevant parts of the raw file names\n",
    "            simple_file_names.append(result)   # New list of simplified file names used for 10x10 degree outputs\n",
    "    \n",
    "        # Removes duplicate simplified file names.\n",
    "        # There are duplicates because each 10x10 output raster has many constituent chunks, each of which have the same aggregated, final name\n",
    "        simple_file_names = np.unique(simple_file_names).tolist()   \n",
    "    \n",
    "        # Makes a list of dictionaries, where the key is the input s3 path and the value is the output aggregated name\n",
    "        list_of_s3_name_dicts = [{key: value} for value in simple_file_names for key in [s3_in_folder]]\n",
    "    \n",
    "        # dask_print(list_of_s3_name_dicts)\n",
    "    \n",
    "        # Adds the dictionary of s3 paths and output names for this folder to the list for all folders\n",
    "        list_of_s3_name_dicts_total.append(list_of_s3_name_dicts)\n",
    "    \n",
    "    # Output of above is a nested list, where each input folder is its own inner list. Need to flatten to a list.\n",
    "    list_of_s3_name_dicts_total = flatten_list(list_of_s3_name_dicts_total)\n",
    "    \n",
    "    print(f\"There are {len(list_of_s3_name_dicts_total)} chunks to process in {len(s3_in_folders)} input folders.\")\n",
    "\n",
    "    return list_of_s3_name_dicts_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2ae67e-adbe-465d-8d97-2bf00fe9b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves an xarray data array locally as a raster and then uploads it to s3\n",
    "def save_and_upload_raster_10x10(**kwargs):\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call\n",
    "\n",
    "    data_array = kwargs['data']   # The data being saved\n",
    "    out_file_name = kwargs['out_file_name']   # The output file name\n",
    "    out_folder = kwargs['out_folder']   # The output folder\n",
    "\n",
    "    dask_print(f\"Saving {out_file_name} locally\")\n",
    "\n",
    "    profile_kwargs = {'compress': 'lzw'}   # Adds attribute to compress the output raster \n",
    "    data_array.rio.to_raster(f\"/tmp/{out_file_name}\", **profile_kwargs)\n",
    "\n",
    "    dask_print(f\"Saving {out_file_name} to {out_folder[10:]}{out_file_name}\")\n",
    "\n",
    "    s3_client.upload_file(f\"/tmp/{out_file_name}\", \"gfw2-data\", Key=f\"{out_folder[10:]}{out_file_name}\")\n",
    "\n",
    "    # Deletes the local raster\n",
    "    os.remove(f\"/tmp/{out_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35d26b3-ab0f-4cde-a18b-5e62e169a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merges rasters that are <10x10 degrees into 10x10 degree rasters in the standard grid\n",
    "def merge_small_tiles(s3_name_dict):\n",
    "\n",
    "    in_folder = list(s3_name_dict.keys())[0]   # The input s3 folder for the small rasters\n",
    "    out_file_name = list(s3_name_dict.values())[0]   # The output file name for the combined rasters\n",
    "\n",
    "    s3_in_folder = f's3://{in_folder}'   # The input s3 folder with s3:// prepended\n",
    "    vsis3_in_folder = f'/vsis3/{in_folder}'   # The input s3 folder with /vsis3/ prepended\n",
    "\n",
    "    # Lists all the rasters in the specified s3 folder\n",
    "    filenames = list_rasters_in_folder(s3_in_folder)   \n",
    "\n",
    "    # Gets the tile_id from the output file name in the standard format\n",
    "    tile_id = out_file_name[:8]\n",
    "\n",
    "    # Limits the input rasters to the specified tile_id (the relevant 10x10 area)\n",
    "    filenames_in_focus_area = [i for i in filenames if tile_id in i]\n",
    "    \n",
    "    # Lists the tile paths for the relevant rasters\n",
    "    tile_paths = []\n",
    "    tile_paths = [s3_in_folder + filename for filename in filenames_in_focus_area]\n",
    "\n",
    "    dask_print(f\"Opening small rasters in {tile_id} in {s3_in_folder}\")\n",
    "\n",
    "    # Opens the relevant rasters in a list of xarray data arrays\n",
    "    small_rasters = [rioxarray.open_rasterio(tile_path, chunks=True) for tile_path in tile_paths]\n",
    "\n",
    "    dask_print(f\"Merging {tile_id} in {s3_in_folder}\")\n",
    "\n",
    "    # Merges the relevant small data arrays in the list\n",
    "    merged = merge_arrays(small_rasters)  # https://corteva.github.io/rioxarray/stable/examples/merge.html\n",
    "\n",
    "    # Names the output folder. Same as the input folder but with the dimensions in pixels replaced\n",
    "    out_folder = re.sub(r'\\d+_pixels', f'{full_raster_dims}_pixels', in_folder)\n",
    "\n",
    "    # Saves the merged xarray data array locally and then to s3 \n",
    "    save_and_upload_raster_10x10(data=merged, out_file_name=out_file_name, out_folder=out_folder)\n",
    "\n",
    "    del merged\n",
    "\n",
    "    return f\"success for {s3_name_dict}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f254f23-71b0-459d-b850-4929e843b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 280 chunks to process in 1 input folders.\n",
      "Opening small rasters in 00N_000E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Opening small rasters in 00N_010E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Opening small rasters in 00N_020E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Merging 00N_000E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Saving 00N_000E__IPCC_change_2015_2020.tif locally\n",
      "Saving 00N_000E__IPCC_change_2015_2020.tif to climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/00N_000E__IPCC_change_2015_2020.tif\n",
      "Merging 00N_010E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Merging 00N_020E in s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\n",
      "Saving 00N_010E__IPCC_change_2015_2020.tif locally\n",
      "Saving 00N_020E__IPCC_change_2015_2020.tif locally\n",
      "Saving 00N_010E__IPCC_change_2015_2020.tif to climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/00N_010E__IPCC_change_2015_2020.tif\n",
      "Saving 00N_020E__IPCC_change_2015_2020.tif to climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/40000_pixels/20240205/00N_020E__IPCC_change_2015_2020.tif\n",
      "CPU times: user 1.22 s, sys: 357 ms, total: 1.57 s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"success for {'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/': '00N_000E__IPCC_change_2015_2020.tif'}\",\n",
       " \"success for {'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/': '00N_010E__IPCC_change_2015_2020.tif'}\",\n",
       " \"success for {'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/': '00N_020E__IPCC_change_2015_2020.tif'}\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_in_folders = [\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2000/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2005/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2010/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2015/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2000_2005/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2005_2010/8000_pixels/20240205/\",\n",
    "           # \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2010_2015/8000_pixels/20240205/\",\n",
    "           \"gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_change/2015_2020/8000_pixels/20240205/\"\n",
    "          ]\n",
    "\n",
    "list_of_s3_name_dicts_total = create_list_for_aggregation(s3_in_folders)\n",
    "\n",
    "# For testing. Limits the number of output rasters\n",
    "list_of_s3_name_dicts_total = list_of_s3_name_dicts_total[0:3]\n",
    "\n",
    "delayed_result = [dask.delayed(merge_small_tiles)(s3_name_dict) for s3_name_dict in list_of_s3_name_dicts_total]\n",
    "\n",
    "results = dask.compute(*delayed_result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67726a-a758-4d83-a82d-9b958ce245d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bdeb5-5f69-418b-8e74-615012303950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd112da-e043-469a-8df2-0fc8db847c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f2871-0459-45c9-a1e6-b3fa53f30e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6a475-b681-4f08-a6e5-09a3d8a4f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Function to track the number of land use changes per pixel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
