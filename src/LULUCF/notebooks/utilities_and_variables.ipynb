{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b03b028-4f73-430d-99ee-2f0c3abdfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import subprocess\n",
    "import re\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "from osgeo import gdal\n",
    "from dask.distributed import Client, get_worker\n",
    "\n",
    "# dask/parallelization libraries\n",
    "import coiled\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.distributed import print\n",
    "import distributed\n",
    "\n",
    "# scipy basics\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.windows\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "\n",
    "# numba\n",
    "from numba import jit\n",
    "from numba.typed import Dict\n",
    "from numba.core import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7941a7-20f8-4bf9-b233-4f11a42b4007",
   "metadata": {},
   "source": [
    "<font size=\"6\">Cluster management</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533792-2e4c-4693-b73e-0896ed25e66a",
   "metadata": {},
   "source": [
    "<font size=\"5\">Creating clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27d54031-7caf-4ebf-9a0a-b2742f01b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa1c04f8c314e6f982f024f3feb42e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Package - bcrypt, The 'bcrypt' conda package was yanked from conda-forge\n",
       "Install a newer version using `conda install -c conda-forge bcrypt`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Package - bcrypt, The 'bcrypt' conda package was yanked from conda-forge\n",
       "Install a newer version using `conda install -c conda-forge bcrypt`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────────── <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Package Info</span> ──────────────────────────────────────────╮\n",
       "│                                ╷                                                                 │\n",
       "│  <span style=\"font-weight: bold\"> Package                      </span>│<span style=\"font-weight: bold\"> Note                                                          </span>  │\n",
       "│ ╶──────────────────────────────┼───────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                   │ https://pypi.org/simple/                                        │\n",
       "│                                ╵                                                                 │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────────── \u001b[1;32mPackage Info\u001b[0m ──────────────────────────────────────────╮\n",
       "│                                ╷                                                                 │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage                     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mNote                                                         \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶──────────────────────────────┼───────────────────────────────────────────────────────────────╴ │\n",
       "│   et-xmlfile                   │ https://pypi.org/simple/                                        │\n",
       "│                                ╵                                                                 │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────── <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Not Synced with Cluster</span> ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  <span style=\"font-weight: bold\"> Package  </span>│<span style=\"font-weight: bold\"> Error                                                                   </span>│<span style=\"font-weight: bold\"> Risk    </span>  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ The 'bcrypt' conda package was yanked from conda-forge                  │ Warning   │\n",
       "│            │ Install a newer version using `conda install -c conda-forge bcrypt`     │           │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────── \u001b[1;31mNot Synced with Cluster\u001b[0m ─────────────────────────────────────╮\n",
       "│            ╷                                                                         ╷           │\n",
       "│  \u001b[1m \u001b[0m\u001b[1mPackage \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mError                                                                  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mRisk   \u001b[0m\u001b[1m \u001b[0m  │\n",
       "│ ╶──────────┼─────────────────────────────────────────────────────────────────────────┼─────────╴ │\n",
       "│   bcrypt   │ The 'bcrypt' conda package was yanked from conda-forge                  │ Warning   │\n",
       "│            │ Install a newer version using `conda install -c conda-forge bcrypt`     │           │\n",
       "│            ╵                                                                         ╵           │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d69fb39f7824cb38a1a8faaf78c2963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-00354852-6094-11ef-9212-00155d25d6c4</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> coiled.Cluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://cluster-bqjye.dask.host/YYxOdTWGei0LANoH/status\" target=\"_blank\">https://cluster-bqjye.dask.host/YYxOdTWGei0LANoH/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">Cluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">AFOLU_flux_model</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://cluster-bqjye.dask.host/YYxOdTWGei0LANoH/status\" target=\"_blank\">https://cluster-bqjye.dask.host/YYxOdTWGei0LANoH/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 5\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 20\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 151.06 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8f5ac73f-6e02-436f-8f64-693b47c3781e</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.0.40.139:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 5\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.0.40.139:8788/status\" target=\"_blank\">http://10.0.40.139:8788/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 20\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 151.06 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: AFOLU_flux_model-worker-01d18d8f62</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.0.35.173:37175\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.0.35.173:8787/status\" target=\"_blank\">http://10.0.35.173:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 30.22 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.0.35.173:40805\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-96aqx07f\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: AFOLU_flux_model-worker-3a26dac89d</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.0.45.216:42157\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.0.45.216:8787/status\" target=\"_blank\">http://10.0.45.216:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 30.21 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.0.45.216:46105\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-i7y_5eau\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: AFOLU_flux_model-worker-ab4b7aa0bc</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.0.41.67:37375\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.0.41.67:8787/status\" target=\"_blank\">http://10.0.41.67:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 30.21 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.0.41.67:34467\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-jicwcugq\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: AFOLU_flux_model-worker-e842063b0e</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.0.41.143:45651\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.0.41.143:8787/status\" target=\"_blank\">http://10.0.41.143:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 30.22 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.0.41.143:42393\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-cq5au4_t\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: AFOLU_flux_model-worker-ff41144a15</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.0.32.94:41001\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 4\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.0.32.94:8787/status\" target=\"_blank\">http://10.0.32.94:8787/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 30.20 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.0.32.94:37763\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /scratch/dask-scratch-space/worker-bow1gvqq\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.0.40.139:8786' processes=5 threads=20, memory=151.06 GiB>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full cluster\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=60,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"AFOLU_flux_model\", \n",
    "    account='wri-forest-research', \n",
    "    worker_cpu=4, # Adequate for carbon pool 2000\n",
    "    worker_memory = \"32GiB\" # Adequate for carbon pool 2000\n",
    "    # worker_cpu=8,\n",
    "    # worker_memory = \"64GiB\"\n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f6327-d54b-4918-9528-e9f9ad3d95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cluster\n",
    "coiled_cluster = coiled.Cluster(\n",
    "    n_workers=2,\n",
    "    use_best_zone=True, \n",
    "    compute_purchase_option=\"spot_with_fallback\",\n",
    "    idle_timeout=\"20 minutes\",\n",
    "    region=\"us-east-1\",\n",
    "    name=\"AFOLU_flux_model\", \n",
    "    account='wri-forest-research', \n",
    "    worker_cpu=4,\n",
    "    worker_memory = \"32GiB\" # Adequate for carbon pool 2000\n",
    "    # worker_cpu=8,\n",
    "    # worker_memory = \"64GiB\"\n",
    ")\n",
    "\n",
    "# Coiled cluster (cloud run)\n",
    "coiled_client = coiled_cluster.get_client()\n",
    "coiled_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cf73e-6053-48ca-a53e-f8b5f82ec626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local single-process cluster (local run). Will run .compute() on just one process, not a whole cluster.\n",
    "local_client = Client(processes=False)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da34549-1d5e-4651-9285-66a5bb0e49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client = Client()\n",
    "local_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa755d07-33cf-42b7-b8bf-d1ef9360e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local cluster with multiple workers\n",
    "local_cluster = LocalCluster()  \n",
    "local_client = Client(local_cluster)\n",
    "local_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab8d1f-ffda-421f-869f-f5ab03a4eb5d",
   "metadata": {},
   "source": [
    "<font size=\"5\">Shutting down cloud and local clusters</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89d4f0-98e5-4144-bac9-3d70d4b60de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_client.restart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0dab2ee2-0137-4c03-9ec5-2b7513f3c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coiled_cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75688b5e-8b9c-4c1b-a2e3-19209c69062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b80cda-51e8-4f33-b820-c71fb77b5887",
   "metadata": {},
   "source": [
    "<font size=\"6\">Variables and constants</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185f97d9-ee21-42ad-9e49-097878c8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General paths and constants\n",
    "\n",
    "LC_uri = 's3://gfw2-data/landcover'\n",
    "\n",
    "s3_out_dir = 'climate/AFOLU_flux_model/LULUCF/outputs'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket('gfw2-data')\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "tile_id_pattern = r\"[0-9]{2}[A-Z][_][0-9]{3}[A-Z]\"  # Pattern for tile_ids in regex form\n",
    "\n",
    "IPCC_class_max_val = 6  # Maximum value of IPCC class codes\n",
    "\n",
    "# IPCC codes\n",
    "forest = 1\n",
    "cropland = 2\n",
    "settlement = 3\n",
    "wetland = 4\n",
    "grassland = 5\n",
    "otherland = 6\n",
    "\n",
    "first_year = 2000  # First year of model\n",
    "last_year = 2020   # Last year of model\n",
    "\n",
    "full_raster_dims = 40000    # Size of a 10x10 deg raster in pixels\n",
    "\n",
    "interval_years = 5   # Number of years in interval. #TODO: calculate programmatically in numba function rather than coded here-- for greater flexibility.\n",
    "\n",
    "# Threshold for height loss to be counted as tree loss (meters)\n",
    "sig_height_loss_threshold = 5 \n",
    "\n",
    "biomass_to_carbon_non_mangrove = 0.47   # Conversion of biomass to carbon for non-mangrove forests\n",
    "biomass_to_carbon_mangrove = 0.45   # Conversion of biomass to carbon for mangroves (IPCC wetlands supplement table 4.2)\n",
    "\n",
    "# Default root:shoot when no Huang et al. 2021 is available. The average slope of the AGB:BGB relationship in Figure 3 of Mokany et al. 2006.\n",
    "# and is only used where Huang et al. 2021 can't reach (remote Pacific islands).\n",
    "default_r_s = 0.26   \n",
    "\n",
    "rate_ratio_spreadsheet = 'http://gfw2-data.s3.amazonaws.com/climate/AFOLU_flux_model/LULUCF/rate_ratio_lookup_tables/rate_and_ratio_lookup_tables_20240718.xlsx'\n",
    "mangrove_rate_ratio_tab = 'mang gain C ratio, for model'\n",
    "\n",
    "# Non-mangrove deadwood C:AGC and litter C:AGC constants\n",
    "# Deadwood and litter carbon as fractions of AGC are from\n",
    "# https://cdm.unfccc.int/methodologies/ARmethodologies/tools/ar-am-tool-12-v3.0.pdf\n",
    "# \"Clean Development Mechanism A/R Methodological Tool: \n",
    "# Estimation of carbon stocks and change in carbon stocks in dead wood and litter in A/R CDM project activities version 03.0\"\n",
    "# Tables on pages 18 (deadwood) and 19 (litter).\n",
    "# They depend on the climate domain, elevation, and precipitation. \n",
    "tropical_low_elev_low_precip_deadwood_c_ratio = 0.02\n",
    "tropical_low_elev_low_precip_litter_c_ratio = 0.04\n",
    "tropical_low_elev_med_precip_deadwood_c_ratio = 0.01\n",
    "tropical_low_elev_med_precip_litter_c_ratio = 0.01\n",
    "tropical_low_elev_high_precip_deadwood_c_ratio = 0.06\n",
    "tropical_low_elev_high_precip_litter_c_ratio = 0.01\n",
    "tropical_high_elev_deadwood_c_ratio = 0.07\n",
    "tropical_high_elev_litter_c_ratio = 0.01\n",
    "non_tropical_deadwood_c_ratio = 0.08\n",
    "non_tropical_litter_c_ratio = 0.04\n",
    "\n",
    "mang_no_data_val = 255   # NoData value in mangrove AGB raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249f3686-de11-4f0e-8229-50db1d898c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc334fe-b9ee-431d-af11-869633963b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCLU codes\n",
    "cropland = 244\n",
    "builtup = 250\n",
    "\n",
    "tree_dry_min_height_code = 27\n",
    "tree_dry_max_height_code = 48\n",
    "tree_wet_min_height_code = 127\n",
    "tree_wet_max_height_code = 148\n",
    "\n",
    "tree_threshold = 5   # Height minimum for trees (meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099235fc-f9ea-490d-a0bc-07c9858fc278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name paths and patterns\n",
    "\n",
    "log_path = \"climate/AFOLU_flux_model/LULUCF/model_logs/\"\n",
    "combined_log = \"AFOLU_model_log\"\n",
    "\n",
    "agb_2000_path = \"s3://gfw2-data/climate/WHRC_biomass/WHRC_V4/Processed/\"\n",
    "agb_2000_pattern = \"t_aboveground_biomass_ha_2000\"\n",
    "\n",
    "mangrove_agb_2000_path = \"s3://gfw2-data/climate/carbon_model/mangrove_biomass/processed/standard/20190220/\"\n",
    "mangrove_agb_2000_pattern = \"mangrove_agb_t_ha_2000\"\n",
    "\n",
    "elevation_path = \"s3://gfw2-data/climate/carbon_model/inputs_for_carbon_pools/processed/elevation/20190418/\"\n",
    "elevation_pattern = \"elevation\"\n",
    "\n",
    "climate_domain_path = \"s3://gfw2-data/climate/carbon_model/inputs_for_carbon_pools/processed/fao_ecozones_bor_tem_tro/20190418/\"\n",
    "climate_domain_pattern = \"fao_ecozones_bor_tem_tro_processed\"\n",
    "\n",
    "precipitation_path = \"s3://gfw2-data/climate/carbon_model/inputs_for_carbon_pools/processed/precip/20190418/\"\n",
    "precipitation_pattern = \"precip_mm_annual\"\n",
    "\n",
    "r_s_ratio_path = \"s3://gfw2-data/climate/carbon_model/BGB_AGB_ratio/processed/20230216/\"\n",
    "r_s_ratio_pattern = \"BGB_AGB_ratio\"\n",
    "\n",
    "continent_ecozone_path = \"s3://gfw2-data/climate/carbon_model/fao_ecozones/ecozone_continent/20190116/processed/\"\n",
    "continent_ecozone_pattern = \"fao_ecozones_continents_processed\"\n",
    "\n",
    "\n",
    "### IPCC classes and change\n",
    "IPCC_class_path = \"IPCC_basic_classes\"\n",
    "IPCC_class_pattern = \"IPCC_classes\"\n",
    "IPCC_change_path = \"IPCC_basic_change\"\n",
    "IPCC_change_pattern = \"IPCC_change\"\n",
    "\n",
    "land_state_pattern = \"land_state_node\"\n",
    "\n",
    "agb_dens_pattern = \"AGB_density_MgAGB_ha\"\n",
    "agc_dens_pattern = \"AGC_density_MgC_ha\"\n",
    "bgc_dens_pattern = \"BGC_density_MgC_ha\"\n",
    "deadwood_c_dens_pattern = \"deadwood_C_density_MgC_ha\"\n",
    "litter_c_dens_pattern = \"litter_C_density_MgC_ha\"\n",
    "agc_flux_pattern = \"AGC_flux_MgC_ha\"\n",
    "bgc_flux_pattern = \"BGC_flux_MgC_ha\"\n",
    "deadwood_c_flux_pattern = \"deadwood_C_flux_MgC_ha\"\n",
    "litter_c_flux_pattern = \"litter_C_flux_MgC_ha\"\n",
    "\n",
    "land_cover = \"land_cover\"\n",
    "vegetation_height = \"vegetation_height\"\n",
    "\n",
    "agb_2000 = \"agb_2000\"\n",
    "mangrove_agb_2000 = \"mangrove_agb_2000\"\n",
    "agc_2000 = \"agc_2000\"\n",
    "bgc_2000 = \"bgc_2000\"\n",
    "deadwood_c_2000 = \"deadwood_c_2000\"\n",
    "litter_c_2000 = \"litter_c_2000\"\n",
    "soil_c_2000 = \"soil_c_2000\"\n",
    "\n",
    "r_s_ratio = \"r_s_ratio\"\n",
    "\n",
    "burned_area = \"burned_area\"\n",
    "forest_disturbance = \"forest_disturbance\"\n",
    "\n",
    "planted_forest_type_layer = \"planted_forest_type\"\n",
    "planted_forest_tree_crop_layer = \"planted_forest_tree_crop\"\n",
    "\n",
    "elevation = \"elevation\"\n",
    "climate_domain = \"climate_domain\"\n",
    "precipitation = \"precipitation\"\n",
    "continent_ecozone = \"continent_ecozone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a65af5-e7d9-4623-bf5f-0440dbf1179b",
   "metadata": {},
   "source": [
    "<font size=\"6\">Logging</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65abdad0-d2ec-45e8-82ce-39a73ca7ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log compilation and uploading\n",
    "# From https://chatgpt.com/share/e/4fe1e9c8-05a0-4e9d-8eee-64168891b5e2\n",
    "def compile_and_upload_log(logs, stage, chunk_count, chunk_size_deg, start_time_str, end_time_str, log_note):\n",
    "\n",
    "    log_name = f\"logs/{combined_log}_{stage}_{time.strftime('%Y%m%d_%H_%M_%S')}.txt\"\n",
    "\n",
    "    # Converts the start time of the stage run from string to datetime so it can be compared to the log entries' times\n",
    "    start_time = datetime.strptime(start_time_str, \"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "    # Retrieves the number of workers\n",
    "    n_workers = len(coiled_client.scheduler_info()['workers'])  # Get the number of connected workers\n",
    "\n",
    "    # Retrieves scheduler info for other cluster properties\n",
    "    scheduler_info = coiled_cluster.scheduler_info  # Access scheduler info directly as a dictionary\n",
    "    \n",
    "    # Gets memory per worker.\n",
    "    # Can't get it to report the worker instance type\n",
    "    try:\n",
    "        worker_memory_bytes = scheduler_info['workers'][next(iter(scheduler_info['workers']))]['memory_limit']\n",
    "        worker_memory_gb = worker_memory_bytes / (1024 ** 3)  # Convert bytes to GB\n",
    "        worker_memory = f\"{worker_memory_gb:.2f} GB\"  # Format to 2 decimal places\n",
    "        # worker_type = coiled_cluster.config.get('worker_options', {}).get('instance_type', \"Unknown\")\n",
    "    except KeyError:\n",
    "        worker_memory = \"Unknown\"\n",
    "        # worker_type = \"Unknown\"\n",
    "    \n",
    "    # Create header lines\n",
    "    header_lines = [\n",
    "        f\"Stage: {stage}\",\n",
    "        f\"Model version: {model_version}\",\n",
    "        f\"Number of workers: {n_workers}\",\n",
    "        f\"Memory per worker: {worker_memory}\",\n",
    "        f\"Number of chunks: {chunk_count}\",\n",
    "        f\"Chunk size (degrees): {chunk_size_deg}\",\n",
    "        # f\"Worker Type: {worker_type}\",\n",
    "        f\"Log note: {log_note}\",\n",
    "        f\"Starting time: {start_time_str}\",\n",
    "        \"\",\n",
    "        \"Filtered logs:\",\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    # Filter lines containing both 'distributed.worker' and 'flm', \n",
    "    # and where the datetime is greater than start_time\n",
    "    filtered_logs = []\n",
    "    for worker_id, log in logs.items():\n",
    "        for line in log.split('\\n'):\n",
    "            if 'distributed.worker' in line and 'flm' in line:\n",
    "                # Extract the datetime from the end of the log line\n",
    "                log_time_str = line.split()[-1]\n",
    "                try:\n",
    "                    log_time = datetime.strptime(log_time_str, \"%Y%m%d_%H_%M_%S\")\n",
    "                    # Include the line only if log_time is greater than start_time\n",
    "                    if log_time > start_time:\n",
    "                        filtered_logs.append(line)\n",
    "                except ValueError:\n",
    "                    # If the datetime format is incorrect, skip this line\n",
    "                    continue\n",
    "\n",
    "    end_time = f\"Stage ended at: {end_time_str}\"\n",
    "\n",
    "    # Combine the header and filtered logs into a single string\n",
    "    combined_filtered_logs = \"\\n\".join(header_lines) + \"\\n\".join(filtered_logs) + \"\\n\".join(end_time)\n",
    "    \n",
    "    # Save the filtered logs to a text file\n",
    "    with open(log_name, \"w\") as file:\n",
    "        file.write(combined_filtered_logs)\n",
    "    \n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call\n",
    "    s3_client.upload_file(log_name, \"gfw2-data\", Key=f\"{log_path}{log_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37c021b-0b87-470c-b262-b0e31a505708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines whether statement should be printed to the console as well as logged\n",
    "def print_and_log(text, is_final, logger):\n",
    "\n",
    "    logger.info(f\"flm: {text}\")\n",
    "    if not is_final:\n",
    "        print(f\"flm: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c6003d-ce89-4284-9630-7fb6e40ac528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for the distributed workers\n",
    "# https://chatgpt.com/share/e/6f80ccde-6a85-4837-94a0-4fcf09b96e43\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger('distributed.worker')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.hasHandlers():\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58988e0-ec13-4ffc-91ad-a2b9c524d449",
   "metadata": {},
   "source": [
    "<font size=\"6\">General functions</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa51beb-6d2b-4db2-a374-db2dd3c176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time in Eastern US timezone as a string\n",
    "def timestr():\n",
    "    # return time.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "    # Define the Eastern Time timezone\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    \n",
    "    # Get the current time in UTC and convert to Eastern Time\n",
    "    eastern_time = datetime.now(eastern)\n",
    "    \n",
    "    # Format the time as a string\n",
    "    return eastern_time.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "\n",
    "# Chunk bounds as a string\n",
    "def boundstr(bounds):\n",
    "    bounds_str = \"_\".join([str(round(x)) for x in bounds])\n",
    "    return bounds_str\n",
    "\n",
    "# Chunk length in pixels\n",
    "def calc_chunk_length_pixels(bounds):\n",
    "    chunk_length_pixels = int((bounds[3]-bounds[1]) * (40000/10))\n",
    "    return chunk_length_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4acc83c4-3b8d-41f7-b423-8450ab29d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps GDAL data type to the appropriate string value\n",
    "gdal_dtype_mapping = {\n",
    "    gdal.GDT_Byte: 'Byte',\n",
    "    gdal.GDT_UInt16: 'UInt16',\n",
    "    gdal.GDT_Int16: 'Int16',\n",
    "    gdal.GDT_UInt32: 'UInt32',\n",
    "    gdal.GDT_Int32: 'Int32',\n",
    "    gdal.GDT_Float32: 'Float32',\n",
    "    gdal.GDT_Float64: 'Float64'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599e9dd3-60ea-4b42-9760-51721f20ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the W, S, E, N bounds of a 10x10 degree tile\n",
    "def get_10x10_tile_bounds(tile_id):\n",
    "    \n",
    "    if \"S\" in tile_id:\n",
    "        max_y = -1 * (int(tile_id[:2]))\n",
    "        min_y = -1 * (int(tile_id[:2])+10)\n",
    "    else: \n",
    "        max_y = (int(tile_id[:2]))\n",
    "        min_y = (int(tile_id[:2])-10)\n",
    "\n",
    "    if \"W\" in tile_id:\n",
    "        max_x = -1 * (int(tile_id[4:7])-10)\n",
    "        min_x = -1 * (int(tile_id[4:7]))\n",
    "    else: \n",
    "        max_x = (int(tile_id[4:7])+10)\n",
    "        min_x = (int(tile_id[4:7]))\n",
    "\n",
    "    return min_x, min_y, max_x, max_y      # W, S, E, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a7c613-1283-4ccf-abf7-bd908315945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of all chunk boundaries within a bounding box for chunks of a given size\n",
    "def get_chunk_bounds(chunk_params):\n",
    "\n",
    "    min_x = chunk_params[0]\n",
    "    min_y = chunk_params[1]\n",
    "    max_x = chunk_params[2]\n",
    "    max_y = chunk_params[3]\n",
    "    chunk_size = chunk_params[4]\n",
    "    \n",
    "    x, y = (min_x, min_y)\n",
    "    chunks = []\n",
    "\n",
    "    # Polygon Size\n",
    "    while y < max_y:\n",
    "        while x < max_x:\n",
    "            bounds = [\n",
    "                x,\n",
    "                y,\n",
    "                x + chunk_size,\n",
    "                y + chunk_size,\n",
    "            ]\n",
    "            chunks.append(bounds)\n",
    "            x += chunk_size\n",
    "        x = min_x\n",
    "        y += chunk_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8e89ff-01ff-4446-83db-39c3910d0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the encompassing tile_id string in the form YYN/S_XXXE/W based on a coordinate\n",
    "def xy_to_tile_id(top_left_x, top_left_y):\n",
    "\n",
    "    lat_ceil = math.ceil(top_left_y/10.0) * 10\n",
    "    lng_floor = math.floor(top_left_x/10.0) * 10\n",
    "    \n",
    "    lng: str = f\"{str(lng_floor).zfill(3)}E\" if (lng_floor >= 0) else f\"{str(-lng_floor).zfill(3)}W\"\n",
    "    lat: str = f\"{str(lat_ceil).zfill(2)}N\" if (lat_ceil >= 0) else f\"{str(-lat_ceil).zfill(2)}S\"\n",
    "\n",
    "    return f\"{lat}_{lng}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c09504ef-06ec-444d-8ea3-bd15154c6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazily opens tile within provided bounds (i.e. one chunk) and returns as a numpy array\n",
    "# If it can't open the uri for the chunk (tile does not exist), it returns nothing. \n",
    "# Originally, I had it return an array of the NoData value if the chunk didn't exist but that seems inefficient.\n",
    "def get_tile_dataset_rio(uri, bounds, chunk_length_pixels):\n",
    "\n",
    "    bounds_str = boundstr(bounds)\n",
    "\n",
    "    # If the uri exists, the relevant window is opened and returned and returned as an array.\n",
    "    # Note that this chunk could still just have NoData values, which would be downloaded.\n",
    "    try:\n",
    "        with rasterio.open(uri) as ds:\n",
    "            window = rasterio.windows.from_bounds(*bounds, ds.transform)\n",
    "            data = ds.read(1, window=window)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    # If the uri does not exist, no array is returned\n",
    "    except:\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13dfd7a3-1173-4a04-88dd-6d847ccb9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares list of chunks to download.\n",
    "# Chunks are defined by a bounding box.\n",
    "def prepare_to_download_chunk(bounds, download_dict, is_final, logger):\n",
    " \n",
    "    futures = {}\n",
    "    \n",
    "    bounds_str = boundstr(bounds)\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)\n",
    "\n",
    "    # Submit requests to S3 for input chunks but don't actually download them yet. This queueing of the requests before downloading them speeds up the downloading\n",
    "    # Approach is to download all the input chunks up front for every year to make downloading more efficient, even though it means storing more upfront\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "\n",
    "        print_and_log(f\"Requesting data in chunk {bounds_str} in {tile_id}: {timestr()}\", is_final, logger)\n",
    "            \n",
    "        for key, value in download_dict.items():\n",
    "            futures[executor.submit(get_tile_dataset_rio, value, bounds, chunk_length_pixels)] = key\n",
    "\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c26e191-cadf-47f1-8135-436b319081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if tiles exist at all\n",
    "def check_for_tile(download_dict, is_final, logger):\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while i < len(list(download_dict.values())):\n",
    "\n",
    "        s3_key = list(download_dict.values())[i][15:]\n",
    "        tile_id = re.findall(tile_id_pattern, list(download_dict.values())[i])[0]  # Extracts the tile_id from the s3 path\n",
    "\n",
    "        # Breaks the loop if the tile exists. No need to keep checking other tiles because one exists.\n",
    "        try:\n",
    "            s3.head_object(Bucket='gfw2-data', Key=s3_key)\n",
    "            \n",
    "            print_and_log(f\"Tile id {tile_id} exists for some inputs. Proceeding: {timestr()} \", is_final, logger)\n",
    "                           \n",
    "            return True\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        i+=1\n",
    "\n",
    "    print_and_log(f\"Tile id {tile_id} does not exists. Skipping chunk: {timestr()}\", is_final, logger)\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "118219c7-4151-42c8-a044-30a1f1709039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks whether a chunk has data in it.\n",
    "# There are two options for how to assess if a chunk has data (any_or_all argument): if any assessed input has data, or if all assessed inputs have data. \n",
    "# Any: To have data, a chunk have have at least one of the assessed inputs (layers).\n",
    "# All: To have data, a chunk must have all necessary inputs (layers).\n",
    "# If one or more necessary input is missing, the loop is terminated and the chunk ultimately skipped. \n",
    "def check_chunk_for_data(required_layers, item_to_check, bounds_str, tile_id, any_or_all, is_final, logger):\n",
    "\n",
    "    # Checks if ANY of the assessed inputs are present\n",
    "    if any_or_all == \"any\":\n",
    "\n",
    "        i=0\n",
    "\n",
    "        while i < len(list(required_layers.values())):\n",
    "    \n",
    "            # Checks if all the pixels have the nodata value. \n",
    "            # Assume no data in the chunk if the min and max values are the same for EVERY input raster.\n",
    "            # Can't use np.all because it doesn't work in chunks that are mostly water; says nodata in chunk even if there is land\n",
    "            # So, instead compare np.min and np.max.\n",
    "            min = np.min(list(required_layers.values())[i])  \n",
    "            max = np.max(list(required_layers.values())[i])\n",
    "            \n",
    "            # Breaks the loop if there is data in the chunk.\n",
    "            # Don't need to keep checking chunk for data because the condition has been met\n",
    "            # (at least one chunk has data).\n",
    "            # The one print statement regardless of whether the model is full-scale or not.\n",
    "            if min != max:  # if min and max are different, there must be data in the chunk\n",
    "                logger.info(f\"flm: Data in chunk {bounds_str}. Proceeding: {timestr()}\")  \n",
    "                print(f\"flm: Data in chunk {bounds_str}. Proceeding: {timestr()}\")\n",
    "                return True\n",
    "    \n",
    "            i+=1\n",
    "\n",
    "        # The one print statement regardless of whether the model is full-scale or not\n",
    "        logger.info(f\"flm: No data in chunk {bounds_str} for assessed inputs: {timestr()}\")   \n",
    "        print(f\"flm: No data in chunk {bounds_str} for assessed inputs: {timestr()}\")\n",
    "        return False\n",
    "\n",
    "    # Checks if ALL of the assessed inputs are present\n",
    "    elif any_or_all == \"all\":\n",
    "    \n",
    "        # Iterates through all the required input layers\n",
    "        for i, (key, value) in enumerate(required_layers.items()):\n",
    "    \n",
    "            # Assume no data in the chunk if the min and max values are the same for EVERY input raster.\n",
    "            # Can't use np.all because it doesn't work in chunks that are mostly water; says nodata in chunk even if there is land\n",
    "            # So, instead compare np.min and np.max.\n",
    "            min = np.min(value)  \n",
    "            max = np.max(value)\n",
    "    \n",
    "            # Breaks the loop if min and max couldn't be calculated, i.e. chunk doesn't exist.\n",
    "            # Don't need to keep checking chunk for data because at least one input doesn't have data,\n",
    "            # so not ALL of the inputs exist\n",
    "            if (min == None) and (max == None):\n",
    "\n",
    "                # The one print statement regardless of whether the model is full-scale or not\n",
    "                logger.info(f\"flm: Chunk {bounds_str} does not exist for {key}. Skipping chunk: {timestr()}\")  # The one print statement regardless of whether the model is full-scale or not\n",
    "                print(f\"flm: Chunk {bounds_str} does not exist for {key}. Skipping chunk: {timestr()}\")\n",
    "                return False    \n",
    "\n",
    "        # If all required inputs are checked (for loop is completed), ALL inputs exist.\n",
    "        # The one print statement regardless of whether the model is full-scale or not\n",
    "        logger.info(f\"flm: Chunk {bounds_str} has data for all assessed inputs: {timestr()}\")   # The one print statement regardless of whether the model is full-scale or not\n",
    "        print(f\"flm: Chunk {bounds_str} has data for all assessed inputs: {timestr()}\")\n",
    "        return True\n",
    "\n",
    "    else: \n",
    "\n",
    "        raise Exception(\"any_or_all argument not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a63159-8e5e-4787-9fb8-0b696de77492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves array as a raster locally, then uploads it to s3. NoData value for outputs is optional\n",
    "def save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, bounds_str, output_dict, is_final, logger, no_data_val = None):\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call\n",
    "\n",
    "    transform = rasterio.transform.from_bounds(*bounds, width=chunk_length_pixels, height=chunk_length_pixels)\n",
    "\n",
    "    file_info = f'{tile_id}__{bounds_str}'\n",
    "\n",
    "    # For every output file, saves from array to local raster, then to s3.\n",
    "    # Can't save directly to s3, unfortunately, so need to save locally first.\n",
    "    for key, value in output_dict.items():\n",
    "\n",
    "        data_array = value[0]\n",
    "        data_type = value[1]\n",
    "        data_meaning = value[2]\n",
    "        year_out = value[3]\n",
    "\n",
    "        if is_final:\n",
    "            file_name = f\"{file_info}__{key}.tif\"\n",
    "        else:\n",
    "            file_name = f\"{file_info}__{key}__{timestr()}.tif\"\n",
    "\n",
    "        print_and_log(f\"Saving {bounds_str} in {tile_id} for {year_out}: {timestr()}\", is_final, logger)\n",
    "\n",
    "        # Includes NoData value in output raster\n",
    "        if no_data_val is not None:\n",
    "            with rasterio.open(f\"/tmp/{file_name}\", 'w', driver='GTiff', width=chunk_length_pixels, height=chunk_length_pixels, count=1, \n",
    "                               dtype=data_type, crs='EPSG:4326', transform=transform, compress='lzw', blockxsize=400, blockysize=400, nodata=no_data_val) as dst:\n",
    "                               # dtype=data_type, crs='EPSG:4326', transform=transform, compress='lzw', nodata=no_data_val) as dst:\n",
    "                dst.write(data_array, 1)\n",
    "\n",
    "        # No NoData value in output raster\n",
    "        else:\n",
    "            with rasterio.open(f\"/tmp/{file_name}\", 'w', driver='GTiff', width=chunk_length_pixels, height=chunk_length_pixels, count=1, \n",
    "                               dtype=data_type, crs='EPSG:4326', transform=transform, compress='lzw', blockxsize=400, blockysize=400) as dst:\n",
    "                dst.write(data_array, 1)\n",
    "        \n",
    "        s3_path = f\"{s3_out_dir}/{data_meaning}/{year_out}/{chunk_length_pixels}_pixels/{time.strftime('%Y%m%d')}\"\n",
    "\n",
    "        print_and_log(f\"Uploading {bounds_str} in {tile_id} for {year_out} to {s3_path}: {timestr()}\", is_final, logger)\n",
    "        \n",
    "        s3_client.upload_file(f\"/tmp/{file_name}\", \"gfw2-data\", Key=f\"{s3_path}/{file_name}\")\n",
    "\n",
    "        # Deletes the local raster\n",
    "        os.remove(f\"/tmp/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13d4e5c0-48e6-4169-834e-e1fac16f8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists rasters in an s3 folder and returns their names as a list\n",
    "def list_rasters_in_folder(full_in_folder):\n",
    "\n",
    "    cmd = ['aws', 's3', 'ls', full_in_folder]\n",
    "    s3_contents_bytes = subprocess.check_output(cmd)\n",
    "\n",
    "    # Converts subprocess results to useful string\n",
    "    s3_contents_str = s3_contents_bytes.decode('utf-8')\n",
    "    s3_contents_list = s3_contents_str.splitlines()\n",
    "    rasters = [line.split()[-1] for line in s3_contents_list]\n",
    "    rasters = [i for i in rasters if \"tif\" in i]\n",
    "\n",
    "    return rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24ddc2d7-2427-4f47-8e16-ed01c507f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploads a shapefile to s3\n",
    "def upload_shp(full_in_folder, in_folder, shp):\n",
    "\n",
    "    print(f\"flm: Uploading to {full_in_folder}{shp}: {timestr()}\")\n",
    "\n",
    "    shp_pattern = shp[:-4]\n",
    "\n",
    "    s3_client = boto3.client(\"s3\")  # Needs to be in the same function as the upload_file call\n",
    "    s3_client.upload_file(f\"/tmp/{shp}\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp}\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.dbf\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.dbf\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.prj\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.prj\")\n",
    "    s3_client.upload_file(f\"/tmp/{shp_pattern}.shx\", \"gfw2-data\", Key=f\"{in_folder[10:]}{shp_pattern}.shx\")\n",
    "\n",
    "    os.remove(f\"/tmp/{shp}\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.dbf\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.prj\")\n",
    "    os.remove(f\"/tmp/{shp_pattern}.shx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42b56bce-7231-4a98-8bda-be30e47e25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a shapefile of the footprints of rasters in a folder, for checking geographical completeness of rasters\n",
    "def make_tile_footprint_shp(input_dict):\n",
    "\n",
    "    in_folder = list(input_dict.keys())[0]\n",
    "    pattern = list(input_dict.values())[0]\n",
    "\n",
    "    # Task properties\n",
    "    print(f\"flm: Making tile index shapefile for: {in_folder}: {timestr()}\")\n",
    "\n",
    "    # Folder including s3 key\n",
    "    s3_in_folder = f's3://{in_folder}'\n",
    "    vsis3_in_folder = f'/vsis3/{in_folder}'\n",
    "\n",
    "    # List of all the filenames in the folder\n",
    "    filenames = list_rasters_in_folder(s3_in_folder)\n",
    "\n",
    "    # List of the tile paths in the folder\n",
    "    tile_paths = []\n",
    "    tile_paths = [vsis3_in_folder + filename for filename in filenames]\n",
    "\n",
    "    file_paths = 's3_paths.txt'\n",
    "\n",
    "    with open(f\"/tmp/{file_paths}\", 'w') as file:\n",
    "        for item in tile_paths:\n",
    "            file.write(item + '\\n')\n",
    "\n",
    "    # Output shapefile name\n",
    "    shp = f\"raster_footprints_{pattern}.shp\"\n",
    "\n",
    "    cmd = [\"gdaltindex\", \"-t_srs\", \"EPSG:4326\", f\"/tmp/{shp}\", \"--optfile\", f\"/tmp/{file_paths}\"]\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "    # Uploads shapefile to s3\n",
    "    upload_shp(s3_in_folder, in_folder, shp)\n",
    "\n",
    "    return(f\"Completed: {timestr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a2ae67e-adbe-465d-8d97-2bf00fe9b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves an xarray data array locally as a raster and then uploads it to s3\n",
    "def save_and_upload_raster_10x10(**kwargs):\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call\n",
    "\n",
    "    data_array = kwargs['data']   # The data being saved\n",
    "    out_file_name = kwargs['out_file_name']   # The output file name\n",
    "    out_folder = kwargs['out_folder']   # The output folder\n",
    "\n",
    "    print(f\"flm: Saving {out_file_name} locally\")\n",
    "\n",
    "    profile_kwargs = {'compress': 'lzw'}   # Adds attribute to compress the output raster \n",
    "    # data_array.rio.to_raster(f\"{out_file_name}\", **profile_kwargs)\n",
    "    data_array.rio.to_raster(f\"/tmp/{out_file_name}\", **profile_kwargs)\n",
    "\n",
    "    print(f\"flm: Saving {out_file_name} to {out_folder[10:]}{out_file_name}\")\n",
    "\n",
    "    s3_client.upload_file(f\"/tmp/{out_file_name}\", \"gfw2-data\", Key=f\"{out_folder[10:]}{out_file_name}\")\n",
    "\n",
    "    # Deletes the local raster\n",
    "    os.remove(f\"/tmp/{out_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12628166-1647-41be-87af-35e873510f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of 2x2 deg tiles to aggregate into 10x10 deg tiles, where the list is a list of dictionaries of the form \n",
    "# [{'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/8000_pixels/20240821/': \n",
    "# ['00N_110E__AGC_density_MgC_ha_2000.tif', '00N_120E__AGC_density_MgC_ha_2000.tif']}, \n",
    "# {'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/BGC_density_MgC_ha/2000/8000_pixels/20240821/': \n",
    "# ['00N_110E__BGC_density_MgC_ha_2000.tif', '00N_120E__BGC_density_MgC_ha_2000.tif']}]\n",
    "def create_list_for_aggregation(s3_in_folders):\n",
    "\n",
    "    list_of_s3_names_total = []   # Final list of dictionaries of input s3 paths and output aggregated 10x10 raster names\n",
    "    \n",
    "    # Iterates through all the input s3 folders\n",
    "    for s3_in_folder in s3_in_folders:\n",
    "    \n",
    "        simple_file_names = []   # List of output aggregatd output 10x10 rasters\n",
    "    \n",
    "        # Raw filenames in an input folder, e.g., ['00N_000E__6_-2_8_0__IPCC_classes_2020.tif', '00N_000E__6_-4_8_-2__IPCC_classes_2020.tif',...]\n",
    "        filenames = list_rasters_in_folder(f\"s3://{s3_in_folder}\")\n",
    "    \n",
    "        # Iterates through all the files in a folder and converts them to the output names. \n",
    "        # Essentially [tile_id]__[pattern].tif. Drops the chunk bounds from the middle.\n",
    "        for filename in filenames:\n",
    "        \n",
    "            result = filename[:10] + filename[filename.rfind(\"__\") + len(\"__\"):]   # Extracts the relevant parts of the raw file names\n",
    "            simple_file_names.append(result)   # New list of simplified file names used for 10x10 degree outputs\n",
    "\n",
    "        # Removes duplicate simplified file names.\n",
    "        # There are duplicates because each 10x10 output raster has many constituent chunks, each of which have the same aggregated, final name\n",
    "        # e.g., ['00N_000E__IPCC_classes_2020.tif', '00N_010E__IPCC_classes_2020.tif', ...]\n",
    "        simple_file_names = np.unique(simple_file_names).tolist()\n",
    "\n",
    "        # Makes nested lists of the file names. Nested for next step.  \n",
    "        # e.g., [['00N_110E__AGC_density_MgC_ha_2000.tif']]\n",
    "        simple_file_names = [[item] for item in simple_file_names]\n",
    "    \n",
    "        # Makes a list of dictionaries, where the key is the input s3 path and the value is the output aggregated name\n",
    "        # e.g., [{'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/8000_pixels/20240821/': ['00N_110E__AGC_density_MgC_ha_2000.tif']}] \n",
    "        list_of_s3_name_dicts = [{key: value} for value in simple_file_names for key in [s3_in_folder]]\n",
    "    \n",
    "        # Adds the dictionary of s3 paths and output names for this folder to the list for all folders\n",
    "        list_of_s3_names_total.append(list_of_s3_name_dicts)\n",
    "    \n",
    "    # Output of above is a nested list, where each input folder is its own inner list. Need to flatten to a list.\n",
    "    # e.g., [{'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/AGC_density_MgC_ha/2000/8000_pixels/20240821/': ['00N_110E__AGC_density_MgC_ha_2000.tif', '00N_120E__AGC_density_MgC_ha_2000.tif']}, \n",
    "    # {'gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/BGC_density_MgC_ha/2000/8000_pixels/20240821/': ['00N_110E__BGC_density_MgC_ha_2000.tif', '00N_120E__BGC_density_MgC_ha_2000.tif']}]\n",
    "    list_of_s3_names_total = flatten_list(list_of_s3_names_total)\n",
    "    \n",
    "    print(f\"flm: There are {len(list_of_s3_names_total)} 10x10 deg rasters to create across {len(s3_in_folders)} input folders.\")\n",
    "\n",
    "    return list_of_s3_names_total\n",
    "\n",
    "# Flattens a nested list\n",
    "def flatten_list(nested_list):\n",
    "    return [x for xs in nested_list for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e615713f-7dcd-4a35-bb29-4efbd4dfa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merges rasters that are <10x10 degrees into 10x10 degree rasters in the standard grid.\n",
    "# Approach is to merge rasters with gdal.Warp and then upload them to s3.\n",
    "def merge_small_tiles_gdal(s3_name_dict):\n",
    "\n",
    "    in_folder = list(s3_name_dict.keys())[0]   # The input s3 folder for the small rasters\n",
    "    out_file_name = list(s3_name_dict.values())[0][0]   # The output file name for the combined rasters\n",
    "\n",
    "    s3_in_folder = f's3://{in_folder}'   # The input s3 folder with s3:// prepended\n",
    "    vsis3_in_folder = f'/vsis3/{in_folder}'   # The input s3 folder with /vsis3/ prepended\n",
    "\n",
    "    # Lists all the rasters in the specified s3 folder\n",
    "    filenames = list_rasters_in_folder(s3_in_folder)\n",
    "\n",
    "    # Gets the tile_id from the output file name in the standard format\n",
    "    tile_id = out_file_name[:8]\n",
    "\n",
    "    # Limits the input rasters to the specified tile_id (the relevant 10x10 area)\n",
    "    filenames_in_focus_area = [i for i in filenames if tile_id in i]\n",
    "    \n",
    "    # Lists the tile paths for the relevant rasters\n",
    "    tile_paths = []\n",
    "    tile_paths = [vsis3_in_folder + filename for filename in filenames_in_focus_area]\n",
    "\n",
    "    print(f\"flm: Merging small rasters in {tile_id} in {vsis3_in_folder}\")\n",
    "\n",
    "    # Names the output folder. Same as the input folder but with the dimensions in pixels replaced\n",
    "    out_folder = re.sub(r'\\d+_pixels', f'{full_raster_dims}_pixels', in_folder[10:])   # [10:] to remove the gfw2-data/ at the front\n",
    "\n",
    "    min_x, min_y, max_x, max_y = get_10x10_tile_bounds(tile_id)\n",
    "\n",
    "    output_extent = [min_x, min_y, max_x, max_y]  # Specify the extent in the order [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    # Dynamically sets the datatype for the merged raster based on the input rasters (courtesy of https://chatgpt.com/share/e/a91c4c98-b2b1-4680-a4a7-453f1a878052)\n",
    "    # Determines the data type of the first raster\n",
    "    first_raster_path = tile_paths[0]\n",
    "    ds = gdal.Open(first_raster_path)\n",
    "    raster_datatype = ds.GetRasterBand(1).DataType\n",
    "    raster_nodata_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    ds = None\n",
    "\n",
    "    # Defaults to Float32 if not found\n",
    "    dtype_str = gdal_dtype_mapping.get(raster_datatype, 'Float32')  \n",
    "\n",
    "    # Merges the rasters (courtesy of ChatGPT: https://chatgpt.com/share/e/13158ebb-dd0a-41d8-8dfb-9ee12e4c804e)\n",
    "    # This is the only system I found that maintains the extent of all the constituent rasters and doesn't change their resolution or pixel size or shift them.\n",
    "    # I also tried various gdal_translate, build_vrt, and numpy padding approaches, none of which worked in all cases.\n",
    "    merged_file = f\"/tmp/merged_{out_file_name}\"\n",
    "\n",
    "    merge_command = [\n",
    "        'gdal_merge.py',\n",
    "        '-o', merged_file,\n",
    "        '-of', 'GTiff',\n",
    "        '-co', 'COMPRESS=DEFLATE',\n",
    "        '-co', 'TILED=YES',   # If not included, the size of the merged small rasters can be many times their sum. Answer at https://gis.stackexchange.com/a/258215\n",
    "        '-co', 'BLOCKXSIZE=400',  # Internal tiling\n",
    "        '-co', 'BLOCKYSIZE=400',  # Internal tiling\n",
    "        '-ul_lr', str(min_x), str(max_y), str(max_x), str(min_y),\n",
    "        '-ot', dtype_str,\n",
    "        '-a_nodata', str(raster_nodata_value)\n",
    "    ]\n",
    "\n",
    "    # Add the input tile paths\n",
    "    merge_command.extend(tile_paths)\n",
    "\n",
    "    try:\n",
    "        subprocess.check_call(merge_command)\n",
    "        print(f\"flm: Successfully merged rasters into {merged_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"flm: Error merging rasters: {e}\")\n",
    "        return f\"failure for {s3_name_dict}\"\n",
    "\n",
    "    s3_client = boto3.client(\"s3\") # Needs to be in the same function as the upload_file call for uploading to work\n",
    "\n",
    "    print(f\"flm: Saving {out_file_name} to s3: {out_folder}{out_file_name}\")\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(merged_file, \"gfw2-data\", Key=f\"{out_folder}{out_file_name}\")\n",
    "        print(f\"flm: Successfully uploaded {out_file_name} to s3\")\n",
    "    except boto3.exceptions.S3UploadFailedError as e:\n",
    "        print(f\"flm: Error uploading file to s3: {e}\")\n",
    "        return f\"failure for {s3_name_dict}\"\n",
    "\n",
    "    # Deletes the local merged raster\n",
    "    os.remove(merged_file)\n",
    "\n",
    "    return f\"success for {s3_name_dict}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e67726a-a758-4d83-a82d-9b958ce245d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def accrete_node(combo, new):\n",
    "    combo = combo*10 + new\n",
    "    return combo\n",
    "\n",
    "# accrete_node(1, 1)\n",
    "# accrete_node(13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a6b289c-9eeb-405a-9d97-912f23158ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a separate dictionary for each chunk datatype so that they can be passed to Numba as separate arguments.\n",
    "### Numba functions can accept (and return) dictionaries of arrays as long as each dictionary only has arrays of one data type (e.g., uint8, float32)\n",
    "### Note: need to add new code if inputs with other data types are added\n",
    "def create_typed_dicts(layers):\n",
    "\n",
    "    # Initializes empty dictionaries for each type\n",
    "    uint8_dict_layers = {}\n",
    "    int16_dict_layers = {}\n",
    "    int32_dict_layers = {}\n",
    "    float32_dict_layers = {}\n",
    "    \n",
    "    # Iterates through the downloaded chunk dictionary and distributes arrays to a separate dictionary for each data type\n",
    "    for key, array in layers.items():\n",
    "\n",
    "        # Skips the dictionary entry if it has no data (generally because the chunk doesn't exist for that input)\n",
    "        if array is None:\n",
    "            continue\n",
    "\n",
    "        # If there is data, it puts the data in the corresponding dictionary for that datatype\n",
    "        if array.dtype == np.uint8:\n",
    "            uint8_dict_layers[key] = array\n",
    "        elif array.dtype == np.int16:\n",
    "            int16_dict_layers[key] = array\n",
    "        elif array.dtype == np.int32:\n",
    "            int32_dict_layers[key] = array\n",
    "        elif array.dtype == np.float32:\n",
    "            float32_dict_layers[key] = array\n",
    "        else:\n",
    "            pass\n",
    "            # raise TypeError(f\"{key} dtype not in list\")\n",
    "\n",
    "    # print(f\"uint8 datasets: {uint8_dict_layers.keys()}\")\n",
    "    # print(f\"int16 datasets: {int16_dict_layers.keys()}\")\n",
    "    # print(f\"int32 datasets: {int32_dict_layers.keys()}\")\n",
    "    # print(f\"float32 datasets: {float32_dict_layers.keys()}\")\n",
    "    \n",
    "    # Creates numba-compliant typed dict for each type of array\n",
    "    typed_dict_uint8 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.uint8, 2, 'C')  # Assuming 2D arrays of uint8\n",
    "    )\n",
    "\n",
    "    typed_dict_int16 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.int16, 2, 'C')  # Assuming 2D arrays of int16\n",
    "    )\n",
    "    \n",
    "    typed_dict_int32 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.int32, 2, 'C')  # Assuming 2D arrays of int32\n",
    "    )\n",
    "    \n",
    "    typed_dict_float32 = Dict.empty(\n",
    "        key_type=types.unicode_type, \n",
    "        value_type=types.Array(types.float32, 2, 'C')  # Assuming 2D arrays of float32\n",
    "    )\n",
    "\n",
    "    # Populates the numba-compliant typed dicts\n",
    "    for key, array in uint8_dict_layers.items():\n",
    "        typed_dict_uint8[key] = array\n",
    "\n",
    "    for key, array in int16_dict_layers.items():\n",
    "        typed_dict_int16[key] = array\n",
    "\n",
    "    for key, array in int32_dict_layers.items():\n",
    "        typed_dict_int32[key] = array\n",
    "\n",
    "    for key, array in float32_dict_layers.items():\n",
    "        typed_dict_float32[key] = array\n",
    "\n",
    "    return typed_dict_uint8, typed_dict_int16, typed_dict_int32, typed_dict_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c338d3-d871-4c8a-822b-7b0a57152471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates numpy array of rates or ratios from a tab in an Excel spreadsheet, e.g., removal factors or carbon pool ratios\n",
    "def convert_lookup_table_to_array(spreadsheet, sheet_name, fields_to_keep):\n",
    "\n",
    "    # Fetches the file content. Courtesy of ChatGPT: https://chatgpt.com/share/e/aff31681-c9a7-40fe-85c1-73a1cab62066\n",
    "    response = requests.get(spreadsheet)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "\n",
    "    # Converts to Excel. Courtesy of ChatGPT: https://chatgpt.com/share/e/aff31681-c9a7-40fe-85c1-73a1cab62066\n",
    "    excel_df = pd.read_excel(BytesIO(response.content), sheet_name=sheet_name)\n",
    "\n",
    "    # Retains only the relevant columns\n",
    "    filtered_data = excel_df[fields_to_keep]\n",
    "\n",
    "    # Converts from dataframe to Numpy array\n",
    "    filtered_array = filtered_data.to_numpy().astype(float)  # Need to convery Pandas dataframe to numpy array because Numba jit-decorated function can't use dataframes. \n",
    "    filtered_array = filtered_array.astype(float)  # Convert from object dtype to float dtype-- necessary for numba to use it\n",
    "    \n",
    "    return filtered_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f969f7c5-f6bd-4637-8f70-f75dee152709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates arrays of 0s for any missing inputs and puts them in the corresponding typed dictionary\n",
    "def complete_inputs(existing_input_list, typed_dict, datatype, chunk_length_pixels, bounds_str, tile_id, is_final, logger):\n",
    "    for dataset_name in existing_input_list:\n",
    "        if dataset_name not in typed_dict.keys():\n",
    "            typed_dict[dataset_name] = np.full((chunk_length_pixels, chunk_length_pixels), 0, dtype=datatype)\n",
    "            print_and_log(f\"Created {dataset_name} for chunk {bounds_str} in {tile_id}: {timestr()}\", is_final, logger)\n",
    "    return typed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b91ad844-3dcd-458d-9723-c5b8dd4fabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates stats for a chunk (numpy array)\n",
    "# From https://chatgpt.com/share/e/5599b6b0-1aaa-4d54-98d3-c720a436dd9a\n",
    "def calculate_stats(array, name, bounds_str, tile_id, in_out):\n",
    "    if array is None or not np.any(array):  # Check if the array is None or empty\n",
    "        return {\n",
    "            'chunk_id': bounds_str,\n",
    "            'tile_id': tile_id,\n",
    "            'layer_name': name,\n",
    "            'in_out': in_out,\n",
    "            'min_value': 'no data',\n",
    "            'mean_value': 'no data',\n",
    "            'max_value': 'no data',\n",
    "            'data_type': 'no data'\n",
    "        }\n",
    "    else:    # Only calculates stats if there is data in the array\n",
    "        return {\n",
    "            'chunk_id': bounds_str,\n",
    "            'tile_id': tile_id,\n",
    "            'layer_name': name,\n",
    "            'in_out': in_out,\n",
    "            'min_value': np.min(array),\n",
    "            'mean_value': np.mean(array),\n",
    "            'max_value': np.max(array),\n",
    "            'data_type': array.dtype.name\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ca2675a-e7e6-436c-acaa-12668b06baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates chunk-level stats for all inputs and outputs and saves to Excel spreadsheet\n",
    "# Also calculates the min and max value for each input and output across all chunks\n",
    "# From https://chatgpt.com/share/e/5599b6b0-1aaa-4d54-98d3-c720a436dd9a\n",
    "def calculate_chunk_stats(all_stats, stage):\n",
    "    \n",
    "    # Convert accumulated statistics to a DataFrame\n",
    "    df_all_stats = pd.DataFrame(all_stats)\n",
    "    sorted_stats = df_all_stats.sort_values(by=['in_out', 'layer_name']).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate the min and max values for each layer_name\n",
    "    min_max_stats = df_all_stats.groupby('layer_name').agg(\n",
    "        min_value=('min_value', 'min'),\n",
    "        max_value=('max_value', 'max')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Write the combined statistics to a single Excel file\n",
    "    with pd.ExcelWriter(f'chunk_stats/{stage}_chunk_statistics_{timestr()}.xlsx') as writer:\n",
    "        sorted_stats.to_excel(writer, sheet_name='chunk_stats', index=False)\n",
    "    \n",
    "        # Write the min and max statistics to the second sheet\n",
    "        min_max_stats.to_excel(writer, sheet_name='min_max_for_layers', index=False)\n",
    "\n",
    "    print(sorted_stats.head())  # Show first few rows of the stats DataFrame for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5fb041d-2fee-4970-91f6-241530a53a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tile_dataset_rio(\"s3://gfw2-data/climate/carbon_model/carbon_pools/aboveground_carbon/extent_2000/standard/20230222/70N_010W_Mg_AGC_ha_2000.tif\", [-10, 69, -9, 70, 1], 4000, 255)\n",
    "# get_tile_dataset_rio(\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/burn_year/burn_year_10x10_clip/ba_2019_70N_010W.tif\", [-10, 69, -9, 70, 1], 4000, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c19ab460-0122-4dba-9f48-9f3ee3b0e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_dict = {}\n",
    "# download_dict[\"agc_2000\"] = \"s3://gfw2-data/climate/carbon_model/carbon_pools/aboveground_carbon/extent_2000/standard/20230222/70N_020E_Mg_AGC_ha_2000.tif\"\n",
    "# data = prepare_to_download_chunk([-10, 69, -9, 70, 1], download_dict, 255)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0db6a475-b681-4f08-a6e5-09a3d8a4f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Function to track the number of land use changes per pixel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
