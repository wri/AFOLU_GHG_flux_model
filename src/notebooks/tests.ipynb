{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "31316c93-4680-443c-b687-3cacccf932b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "### Used this code to confirm I have upload privileges to s3\n",
    "\n",
    "def upload_test_file_to_s3(bucket_name, object_name, region='us-west-2'):\n",
    "    import boto3\n",
    "    from io import BytesIO\n",
    "\n",
    "    # Initialize S3 client\n",
    "    s3_client = boto3.client('s3', region_name=region)\n",
    "    \n",
    "    # Create a test file in memory\n",
    "    test_file = BytesIO(b'This is a test file for S3 upload.')\n",
    "    \n",
    "    # Try to upload the test file\n",
    "    try:\n",
    "        response = s3_client.upload_fileobj(test_file, bucket_name, object_name)\n",
    "        print(\"File uploaded successfully!\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Failed to upload file:\", e)\n",
    "\n",
    "# Usage\n",
    "bucket_name = 'wri-users'\n",
    "object_name = 'eglen/test-upload.txt'\n",
    "upload_test_file_to_s3(bucket_name, object_name, region='us-east-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "65f5d147-2847-47a7-94dc-8660bcd3ff53",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Setup a local Dask client\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(client)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/site-packages/distributed/client.py:1014\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m preload_argv \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.client.preload-argv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreloads \u001b[38;5;241m=\u001b[39m preloading\u001b[38;5;241m.\u001b[39mprocess_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[0;32m-> 1014\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m Client\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecreate_tasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/site-packages/distributed/client.py:1216\u001b[0m, in \u001b[0;36mClient.start\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1216\u001b[0m     \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/site-packages/distributed/utils.py:431\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 431\u001b[0m         \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/site-packages/distributed/utils.py:420\u001b[0m, in \u001b[0;36msync.<locals>.wait\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m         loop\u001b[38;5;241m.\u001b[39madd_callback(cancel)\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/dask_notebook/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Tested this code using dask, was able to upload to WRI users\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Setup a local Dask client\n",
    "client = Client()\n",
    "print(client)\n",
    "\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "def upload_to_s3(bucket, key, content):\n",
    "    s3 = boto3.client('s3')\n",
    "    file = BytesIO(content.encode())\n",
    "    s3.upload_fileobj(file, bucket, key)\n",
    "    return f\"Uploaded {key} to {bucket}\"\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "# Define bucket and object names\n",
    "bucket_name = 'wri-users'\n",
    "object_names = ['eglen/test-upload-1.txt', 'eglen/test-upload-2.txt', 'eglen/test-upload-3.txt']\n",
    "\n",
    "# Create delayed tasks for uploading files\n",
    "tasks = [delayed(upload_to_s3)(bucket_name, name, f\"Contents for {name}\") for name in object_names]\n",
    "\n",
    "# Compute tasks in parallel\n",
    "results = client.compute(tasks, sync=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2a824-3b6d-46e2-a4ea-67a5dc75df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now testing uploading to gfw2-data - confirmed this works too\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Setup a local Dask client\n",
    "client = Client()\n",
    "print(client)\n",
    "\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "def upload_to_s3(bucket, key, content):\n",
    "    s3 = boto3.client('s3')\n",
    "    file = BytesIO(content.encode())\n",
    "    s3.upload_fileobj(file, bucket, key)\n",
    "    return f\"Uploaded {key} to {bucket}\"\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "# Define bucket and object names\n",
    "bucket_name = 'gfw2-data'\n",
    "object_names = ['climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/test-upload-1.txt', 'climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/test-upload-2.txt', 'climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/test-upload-3.txt']\n",
    "\n",
    "# Create delayed tasks for uploading files\n",
    "tasks = [delayed(upload_to_s3)(bucket_name, name, f\"Contents for {name}\") for name in object_names]\n",
    "\n",
    "# Compute tasks in parallel\n",
    "results = client.compute(tasks, sync=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad60897-d5fa-4253-bf6f-e39ab3fe8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the client\n",
    "client.close()\n",
    "print(\"Dask client has been shut down.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2ce2405d-95ac-4c45-9fe5-481decb91c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile id er_other exists. Proceeding.\n"
     ]
    }
   ],
   "source": [
    "tile_id = \"00N_110E\"\n",
    "\n",
    "download_dict = {\n",
    "    # f\"{land_cover}_2000\": f\"{LC_uri}/composite/2000/raw/{tile_id}.tif\",\n",
    "    # f\"{land_cover}_2005\": f\"{LC_uri}/composite/2005/raw/{tile_id}.tif\",\n",
    "    # f\"{land_cover}_2010\": f\"{LC_uri}/composite/2010/raw/{tile_id}.tif\",\n",
    "    # f\"{land_cover}_2015\": f\"{LC_uri}/composite/2015/raw/{tile_id}.tif\"\n",
    "    f\"{land_cover}_2020\": f\"s3://gfw2-data/climate/AFOLU_flux_model/LULUCF/outputs/IPCC_basic_classes/2020/{tile_id}.tif\",\n",
    "    planted_forest_type_layer: f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/plantation_type/SDPTv2/20230911/{tile_id}_plantation_type_oilpalm_woodfiber_other.tif\", # Originally from gfw-data-lake, so it's in 400x400 windows\n",
    "    planted_forest_tree_crop_layer: f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/plantation_simpleType__planted_forest_tree_crop/SDPTv2/20230911/{tile_id}.tif\",  # Originally from gfw-data-lake, so it's in 400x400 windows\n",
    "    peat: f\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/{tile_id}_peat_mask_processed.tif\",\n",
    "    dadap: f\"s3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/dadap_{tile_id}.tif\"\n",
    "    }\n",
    "\n",
    "\"s3://gfw2-data/climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/00N_110E_peat_mask_processed.tif\"\n",
    "# Checks whether tile exists at all. Doesn't try to download chunk if the tile doesn't exist.\n",
    "tile_exists = check_for_tile(download_dict, is_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d3887-4b19-4510-ba80-8ad451b351ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
