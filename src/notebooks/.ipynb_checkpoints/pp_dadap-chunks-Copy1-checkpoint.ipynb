{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e36d71-c1b5-49ce-ac96-e442b07e0f6a",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to process the Dadap Canals density raster into 10x10 degree tiles and to set up a template for processing other input datasets. The code needs to check the CRS, projection, and cell size of the dataset and correct if necessary. The code also needs to export chunks of the input dataset to s3, which can later be merged into 10x10 degree tiles. Code is currently exporting files to s3, but they are all no data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "813967a9-0f3b-4b87-9735-cc6d90ef6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask\n",
    "import boto3\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "\n",
    "# scipy basics\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.windows\n",
    "from rasterio.windows import from_bounds\n",
    "#import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from rioxarray.merge import merge_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d8f6faf8-1247-440b-9176-2ac564525480",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_uri = \"s3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/raw/GFW_Global_Peatlands/00N_110E.tif\"\n",
    "dadap_uri = \"s3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/raw/Dadap_SEA_Drainage/canal_length_data/canal_length_1km.tif\"\n",
    "s3_base_dir = \"s3://gfw2-data/climate/AFOLU_flux_model/organic_soils/\"\n",
    "dadap_pattern = \"dadap_density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30b92832-71d2-4c94-8b30-ab57d468e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_dataset_rio(uri, bounds, chunk_length_pixels):\n",
    "    bounds_str = boundstr(bounds)\n",
    "    try:\n",
    "        with rasterio.open(uri) as ds:\n",
    "            no_data_val = 3.4028235e+38\n",
    "            window = from_bounds(*bounds, ds.transform)\n",
    "            data = ds.read(1, window=window)\n",
    "            if data.size == 0:  # Skip chunks with no data\n",
    "                print(f\"No data in chunk {bounds_str}, skipping.\")\n",
    "                return None\n",
    "\n",
    "            transform = ds.window_transform(window)\n",
    "            data_array = xr.DataArray(data, dims=[\"y\", \"x\"], coords={\n",
    "                \"x\": np.linspace(transform.c, transform.c + transform.a * (data.shape[1] - 1), num=data.shape[1]),\n",
    "                \"y\": np.linspace(transform.f, transform.f + transform.e * (data.shape[0] - 1), num=data.shape[0])\n",
    "            })\n",
    "            data_array.rio.write_crs(ds.crs, inplace=True)\n",
    "            data_array.rio.write_nodata(no_data_val, inplace=True)\n",
    "            return data_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data for bounds {bounds_str}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5900b792-62df-4e5a-ab0c-40a1df5cb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dadap_chunk(bounds, dadap_uri, template_uri, is_final):\n",
    "    print(f\"Processing chunk with bounds: {bounds}\")\n",
    "    chunk_length_pixels = calc_chunk_length_pixels(bounds)\n",
    "    tile_id = xy_to_tile_id(bounds[0], bounds[3])\n",
    "\n",
    "    dadap_data = get_tile_dataset_rio(dadap_uri, bounds, chunk_length_pixels)\n",
    "    if dadap_data is None:\n",
    "        return f\"Skipped chunk {bounds} due to no data\"\n",
    "\n",
    "    template_data = get_tile_dataset_rio(template_uri, bounds, chunk_length_pixels)\n",
    "    if template_data is None:\n",
    "        return f\"Skipped chunk {bounds} due to no template data\"\n",
    "\n",
    "    dadap_data_matched = dadap_data.rio.reproject_match(template_data)\n",
    "\n",
    "    out_dir = s3_processed_dir\n",
    "    \n",
    "    save_and_upload_small_raster_set(bounds, chunk_length_pixels, tile_id, boundstr(bounds), {\n",
    "        \"dadap_chunk\": [dadap_data_matched, 'float32', 'dadap_density', time.strftime('%Y')]\n",
    "    }, out_dir, is_final)\n",
    "    \n",
    "    return f\"Processed and uploaded chunk {bounds}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c59f2f87-d68c-4762-b3ee-481b69eb2037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 25 chunks\n",
      "Processing chunk with bounds: [112, -4, 114, -2]\n",
      "Processing chunk with bounds: [110, -6, 112, -4]\n",
      "Processing chunk with bounds: [118, -10, 120, -8]\n",
      "Processing chunk with bounds: [110, -8, 112, -6]\n",
      "Processing chunk with bounds: [110, -10, 112, -8]\n",
      "Processing chunk with bounds: [114, -8, 116, -6]\n",
      "Processing chunk with bounds: [112, -10, 114, -8]\n",
      "Processing chunk with bounds: [118, -8, 120, -6]\n",
      "Processing chunk with bounds: [110, -4, 112, -2]\n",
      "Processing chunk with bounds: [112, -2, 114, 0]\n",
      "Processing chunk with bounds: [110, -2, 112, 0]\n",
      "Processing chunk with bounds: [114, -10, 116, -8]\n",
      "No data in chunk 118_-8_120_-6, skipping.No data in chunk 110_-8_112_-6, skipping.\n",
      "No data in chunk 114_-10_116_-8, skipping.\n",
      "\n",
      "Processing chunk with bounds: [118, -6, 120, -4]\n",
      "No data in chunk 110_-10_112_-8, skipping.\n",
      "Processing chunk with bounds: [114, -6, 116, -4]\n",
      "No data in chunk 112_-10_114_-8, skipping.\n",
      "Processing chunk with bounds: [116, -6, 118, -4]\n",
      "No data in chunk 114_-8_116_-6, skipping.\n",
      "Processing chunk with bounds: [118, -4, 120, -2]\n",
      "Processing chunk with bounds: [118, -2, 120, 0]\n",
      "No data in chunk 118_-10_120_-8, skipping.\n",
      "Processing chunk with bounds: [116, -4, 118, -2]\n",
      "Processing chunk with bounds: [116, -10, 118, -8]\n",
      "No data in chunk 116_-10_118_-8, skipping.\n",
      "Processing chunk with bounds: [116, -8, 118, -6]\n",
      "No data in chunk 116_-8_118_-6, skipping.\n",
      "Processing chunk with bounds: [114, -2, 116, 0]\n",
      "Saving 110_-2_112_0 in 00N_110E for 2024: 20240510_13_30_08\n",
      "Saving 110_-6_112_-4 in 00N_110E for 2024: 20240510_13_30_08\n",
      "Saving 112_-4_114_-2 in 00N_110E for 2024: 20240510_13_30_08\n",
      "Uploading 110_-6_112_-4 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_15Uploading 110_-2_112_0 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_15\n",
      "\n",
      "Uploading 112_-4_114_-2 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_15\n",
      "Saving 110_-4_112_-2 in 00N_110E for 2024: 20240510_13_30_16\n",
      "Saving 114_-2_116_0 in 00N_110E for 2024: 20240510_13_30_16\n",
      "Saving 116_-6_118_-4 in 00N_110E for 2024: 20240510_13_30_16\n",
      "Saving 112_-2_114_0 in 00N_110E for 2024: 20240510_13_30_16\n",
      "Uploading 110_-4_112_-2 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_22Uploading 112_-2_114_0 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_22\n",
      "\n",
      "Uploading 114_-2_116_0 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_24\n",
      "Uploading 116_-6_118_-4 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_26\n",
      "Saving 118_-6_120_-4 in 00N_110E for 2024: 20240510_13_30_26\n",
      "Saving 118_-2_120_0 in 00N_110E for 2024: 20240510_13_30_26\n",
      "Saving 116_-4_118_-2 in 00N_110E for 2024: 20240510_13_30_26\n",
      "Saving 118_-4_120_-2 in 00N_110E for 2024: 20240510_13_30_26\n",
      "Saving 114_-6_116_-4 in 00N_110E for 2024: 20240510_13_30_26\n",
      "Processing chunk with bounds: [114, -4, 116, -2]\n",
      "Uploading 118_-6_120_-4 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_31\n",
      "Uploading 118_-4_120_-2 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_32\n",
      "Uploading 114_-6_116_-4 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_32\n",
      "Uploading 116_-4_118_-2 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_33\n",
      "Uploading 118_-2_120_0 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_33\n",
      "Processing chunk with bounds: [116, -2, 118, 0]\n",
      "Processing chunk with bounds: [112, -6, 114, -4]\n",
      "Processing chunk with bounds: [112, -8, 114, -6]\n",
      "No data in chunk 112_-8_114_-6, skipping.\n",
      "Saving 114_-4_116_-2 in 00N_110E for 2024: 20240510_13_30_38\n",
      "Uploading 114_-4_116_-2 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_40\n",
      "Saving 112_-6_114_-4 in 00N_110E for 2024: 20240510_13_30_40\n",
      "Saving 116_-2_118_0 in 00N_110E for 2024: 20240510_13_30_40\n",
      "Uploading 112_-6_114_-4 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_42\n",
      "Uploading 116_-2_118_0 in 00N_110E for 2024 to climate/AFOLU_flux_model/organic_soils/inputs/processed/dadap_density/2024/8000_pixels/20240510: 20240510_13_30_44\n",
      "('Skipped chunk [110, -10, 112, -8] due to no data', 'Skipped chunk [112, -10, 114, -8] due to no data', 'Skipped chunk [114, -10, 116, -8] due to no data', 'Skipped chunk [116, -10, 118, -8] due to no data', 'Skipped chunk [118, -10, 120, -8] due to no data', 'Skipped chunk [110, -8, 112, -6] due to no data', 'Skipped chunk [112, -8, 114, -6] due to no data', 'Skipped chunk [114, -8, 116, -6] due to no data', 'Skipped chunk [116, -8, 118, -6] due to no data', 'Skipped chunk [118, -8, 120, -6] due to no data', 'Processed and uploaded chunk [110, -6, 112, -4]', 'Processed and uploaded chunk [112, -6, 114, -4]', 'Processed and uploaded chunk [114, -6, 116, -4]', 'Processed and uploaded chunk [116, -6, 118, -4]', 'Processed and uploaded chunk [118, -6, 120, -4]', 'Processed and uploaded chunk [110, -4, 112, -2]', 'Processed and uploaded chunk [112, -4, 114, -2]', 'Processed and uploaded chunk [114, -4, 116, -2]', 'Processed and uploaded chunk [116, -4, 118, -2]', 'Processed and uploaded chunk [118, -4, 120, -2]', 'Processed and uploaded chunk [110, -2, 112, 0]', 'Processed and uploaded chunk [112, -2, 114, 0]', 'Processed and uploaded chunk [114, -2, 116, 0]', 'Processed and uploaded chunk [116, -2, 118, 0]', 'Processed and uploaded chunk [118, -2, 120, 0]')\n"
     ]
    }
   ],
   "source": [
    "# Makes list of chunks to analyze\n",
    "chunk_params = [110, -10, 120, 0, 2] # 1 tile, 25 chunks\n",
    "#chunk_params = [116, -6, 118, -4, 2] # 1 chunk, has data\n",
    "#chunk_params = [116, -10, 118, -8, 2] # 1 chunk\n",
    "chunks = get_chunk_bounds(chunk_params)  \n",
    "print(\"Processing\", len(chunks), \"chunks\")\n",
    "\n",
    "is_final = len(chunks) > 30\n",
    "if is_final:\n",
    "    print(\"Running as final model.\")\n",
    "\n",
    "# Correct the function name and parameters\n",
    "delayed_result = [dask.delayed(process_dadap_chunk)(chunk, dadap_uri, template_uri, is_final) for chunk in chunks]\n",
    "\n",
    "results = dask.compute(*delayed_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce3615-0bdf-49ea-a89f-46ceffd76cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
