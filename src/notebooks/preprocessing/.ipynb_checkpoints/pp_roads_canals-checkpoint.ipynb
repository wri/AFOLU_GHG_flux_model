{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea5040c7-252e-43ac-92e7-a6b47c8fb363",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to use dask_notebook_yaml_copy which has shapely and fiona installed \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.features import rasterize\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "import fiona\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "import gc\n",
    "import subprocess\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "import rioxarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd150d-3714-42f7-988e-41b8861dcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# AWS S3 setup\n",
    "s3_bucket_name = 'gfw2-data'\n",
    "s3_tiles_prefix = 'climate/carbon_model/other_emissions_inputs/peatlands/processed/20230315/'\n",
    "\n",
    "# Input directories\n",
    "feature_directories = {\n",
    "    'osm_roads': 's3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/raw/roads/osm_roads/roads_by_tile/',\n",
    "    'osm_canals': 's3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/raw/roads/osm_roads/canals_by_tile/',\n",
    "    'grip_roads': 's3://gfw2-data/climate/AFOLU_flux_model/organic_soils/inputs/raw/roads/grip_roads/roads_by_tile/'\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "output_directories = {\n",
    "    'osm_roads': {\n",
    "        'local': 'C:/GIS/Data/Global/OSM/osm_roads_density/',\n",
    "        's3': 'climate/AFOLU_flux_model/organic_soils/inputs/processed/osm_roads_density/'\n",
    "    },\n",
    "    'osm_canals': {\n",
    "        'local': 'C:/GIS/Data/Global/OSM/osm_canals_density/',\n",
    "        's3': 'climate/AFOLU_flux_model/organic_soils/inputs/processed/osm_canals_density/'\n",
    "    },\n",
    "    'grip_roads': {\n",
    "        'local': r'C:\\GIS\\Data\\Global\\Wetlands\\Processed\\grip_density',\n",
    "        's3': 'climate/AFOLU_flux_model/organic_soils/inputs/processed/grip_density/'\n",
    "    }\n",
    "}\n",
    "\n",
    "local_temp_dir = r\"C:\\GIS\\Data\\Global\\Wetlands\\Processed\\30_m_temp\"\n",
    "\n",
    "# Ensure local output directories exist\n",
    "for key, paths in output_directories.items():\n",
    "    os.makedirs(paths['local'], exist_ok=True)\n",
    "os.makedirs(local_temp_dir, exist_ok=True)\n",
    "\n",
    "logging.info(\"Directories and paths set up\")\n",
    "\n",
    "def get_raster_bounds(raster_path):\n",
    "    logging.info(f\"Reading raster bounds from {raster_path}\")\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        bounds = src.bounds\n",
    "    logging.info(f\"Bounds of the raster: {bounds}\")\n",
    "    return bounds\n",
    "\n",
    "def resample_raster(src, target_resolution_m):\n",
    "    logging.info(f\"Resampling raster to {target_resolution_m} meter resolution (1 km by 1 km)\")\n",
    "    target_resolution_deg = target_resolution_m / 111320  # Approximate conversion factor\n",
    "\n",
    "    width = int((src.bounds.right - src.bounds.left) / target_resolution_deg)\n",
    "    height = int((src.bounds.top - src.bounds.bottom) / target_resolution_deg)\n",
    "\n",
    "    new_transform = rasterio.transform.from_bounds(\n",
    "        src.bounds.left, src.bounds.bottom, src.bounds.right, src.bounds.top, width, height)\n",
    "\n",
    "    profile = src.profile\n",
    "    profile.update(transform=new_transform, width=width, height=height)\n",
    "\n",
    "    data = src.read(\n",
    "        out_shape=(src.count, height, width),\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "\n",
    "    return data, profile\n",
    "\n",
    "def mask_raster(data, profile):\n",
    "    logging.info(\"Masking raster in memory for values equal to 1\")\n",
    "    mask = data == 1\n",
    "    profile.update(dtype=rasterio.uint8)\n",
    "    return mask.astype(rasterio.uint8), profile\n",
    "\n",
    "def create_fishnet_from_raster(data, transform):\n",
    "    logging.info(\"Creating fishnet from raster data in memory\")\n",
    "    rows, cols = data.shape\n",
    "    polygons = []\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if data[row, col]:\n",
    "                x, y = transform * (col, row)\n",
    "                polygons.append(box(x, y, x + transform[0], y + transform[4]))\n",
    "\n",
    "    fishnet_gdf = gpd.GeoDataFrame({'geometry': polygons}, crs=\"EPSG:4326\")\n",
    "    logging.info(f\"Fishnet grid generated with {len(polygons)} cells\")\n",
    "    return fishnet_gdf\n",
    "\n",
    "def reproject_gdf(gdf, epsg):\n",
    "    logging.info(f\"Reprojecting GeoDataFrame to EPSG:{epsg}\")\n",
    "    return gdf.to_crs(epsg=epsg)\n",
    "\n",
    "def read_tiled_features(tile_id, feature_type):\n",
    "    feature_tile_dir = feature_directories[feature_type]\n",
    "    logging.info(f\"Reading tiled {feature_type} shapefile for tile ID: {tile_id}\")\n",
    "    try:\n",
    "        tile_id = '_'.join(tile_id.split('_')[:2])\n",
    "        file_path = os.path.join(feature_tile_dir, f\"{feature_type.split('_')[1]}_{tile_id}.shp\")\n",
    "        if os.path.exists(file_path) or file_path.startswith('s3://'):\n",
    "            features_gdf = gpd.read_file(file_path)\n",
    "            logging.info(f\"Read {len(features_gdf)} {feature_type} features for tile {tile_id}\")\n",
    "            features_gdf = reproject_gdf(features_gdf, 5070)\n",
    "            return features_gdf\n",
    "        else:\n",
    "            logging.warning(f\"No shapefile found for tile {tile_id}\")\n",
    "            return gpd.GeoDataFrame(columns=['geometry'])\n",
    "    except fiona.errors.DriverError as e:\n",
    "        logging.error(f\"Error reading {feature_type} shapefile: {e}\")\n",
    "        return gpd.GeoDataFrame(columns=['geometry'])\n",
    "\n",
    "def assign_segments_to_cells(fishnet_gdf, features_gdf):\n",
    "    logging.info(\"Assigning features segments to fishnet cells and calculating lengths\")\n",
    "    feature_lengths = []\n",
    "\n",
    "    for idx, cell in fishnet_gdf.iterrows():\n",
    "        features_in_cell = gpd.clip(features_gdf, cell.geometry)\n",
    "        total_length = features_in_cell.geometry.length.sum()\n",
    "        feature_lengths.append(total_length)\n",
    "\n",
    "    fishnet_gdf['length'] = feature_lengths\n",
    "    logging.info(f\"Fishnet with feature lengths: {fishnet_gdf.head()}\")\n",
    "    return fishnet_gdf\n",
    "\n",
    "def convert_length_to_density(fishnet_gdf, crs):\n",
    "    logging.info(\"Converting length to density (km/km2)\")\n",
    "    if crs.axis_info[0].unit_name == 'metre':\n",
    "        fishnet_gdf['density'] = fishnet_gdf['length'] / (1 * 1)  # lengths are in meters, cell area in km2\n",
    "    elif crs.axis_info[0].unit_name == 'kilometre':\n",
    "        fishnet_gdf['density'] = fishnet_gdf['length']  # lengths are already in km, cell area in km2\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported CRS units\")\n",
    "    return fishnet_gdf\n",
    "\n",
    "def fishnet_to_raster(fishnet_gdf, profile, output_raster_path):\n",
    "    logging.info(f\"Converting fishnet to raster and saving to {output_raster_path}\")\n",
    "    profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "    transform = profile['transform']\n",
    "    out_shape = (profile['height'], profile['width'])\n",
    "    fishnet_gdf = fishnet_gdf.to_crs(profile['crs'])\n",
    "\n",
    "    if fishnet_gdf.empty:\n",
    "        logging.info(f\"No valid geometries found for {output_raster_path}. Skipping rasterization.\")\n",
    "        return\n",
    "\n",
    "    rasterized = rasterize(\n",
    "        [(geom, value) for geom, value in zip(fishnet_gdf.geometry, fishnet_gdf['density'])],\n",
    "        out_shape=out_shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=rasterio.float32\n",
    "    )\n",
    "\n",
    "    if np.all(rasterized == 0) or np.all(np.isnan(rasterized)):\n",
    "        logging.info(f\"Skipping export of {output_raster_path} as all values are 0 or nodata\")\n",
    "        return\n",
    "\n",
    "    with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(rasterized, 1)\n",
    "\n",
    "    logging.info(\"Fishnet converted to raster and saved\")\n",
    "\n",
    "def resample_to_30m(input_path, output_path, reference_path):\n",
    "    input_raster = rioxarray.open_rasterio(input_path, masked=True)\n",
    "    reference_raster = rioxarray.open_rasterio(reference_path, masked=True)\n",
    "\n",
    "    logging.info(f\"Resampling {input_path} to match {reference_path}\")\n",
    "    clipped_resampled_raster = input_raster.rio.clip_box(*reference_raster.rio.bounds())\n",
    "    clipped_resampled_raster = clipped_resampled_raster.rio.reproject_match(reference_raster)\n",
    "\n",
    "    clipped_resampled_raster.rio.to_raster(output_path)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        logging.info(f\"Successfully saved resampled raster to {output_path}\")\n",
    "    else:\n",
    "        logging.error(f\"Failed to save resampled raster to {output_path}\")\n",
    "\n",
    "def compress_file(input_file, output_file):\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            ['gdal_translate', '-co', 'COMPRESS=LZW', '-co', 'TILED=YES', input_file, output_file],\n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Error compressing file {input_file}: {e}\")\n",
    "\n",
    "def get_existing_s3_files(s3_bucket, s3_prefix):\n",
    "    s3_client = boto3.client('s3')\n",
    "    existing_files = set()\n",
    "\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=s3_bucket, Prefix=s3_prefix)\n",
    "\n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                existing_files.add(obj['Key'])\n",
    "\n",
    "    return existing_files\n",
    "\n",
    "def compress_and_upload_directory_to_s3(local_directory, s3_bucket, s3_prefix):\n",
    "    s3_client = boto3.client('s3')\n",
    "    existing_files = get_existing_s3_files(s3_bucket, s3_prefix)\n",
    "\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            compressed_file_path = os.path.join(root, f\"compressed_{file}\")\n",
    "            s3_file_path = os.path.relpath(local_file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, s3_file_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            if s3_key in existing_files:\n",
    "                logging.info(f\"File {s3_key} already exists in S3. Skipping upload.\")\n",
    "            else:\n",
    "                try:\n",
    "                    logging.info(f\"Compressing {local_file_path}\")\n",
    "                    compress_file(local_file_path, compressed_file_path)\n",
    "\n",
    "                    logging.info(f\"Uploading {compressed_file_path} to s3://{s3_bucket}/{s3_key}\")\n",
    "                    s3_client.upload_file(compressed_file_path, s3_bucket, s3_key)\n",
    "\n",
    "                    logging.info(f\"Successfully uploaded {compressed_file_path} to s3://{s3_bucket}/{s3_key}\")\n",
    "\n",
    "                    os.remove(compressed_file_path)\n",
    "                except (NoCredentialsError, PartialCredentialsError) as e:\n",
    "                    logging.error(f\"Credentials error: {e}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to upload {local_file_path} to s3://{s3_bucket}/{s3_key}: {e}\")\n",
    "\n",
    "def process_tile(tile_key, feature_type, run_mode='default'):\n",
    "    output_dir = output_directories[feature_type]['local']\n",
    "    s3_output_dir = output_directories[feature_type]['s3']\n",
    "    tile_id = '_'.join(os.path.basename(tile_key).split('_')[:2])\n",
    "    local_output_path = os.path.join(output_dir, f\"{feature_type}_density_{tile_id}.tif\")\n",
    "    s3_output_path = f\"{s3_output_dir}{feature_type}_density_{tile_id}.tif\"\n",
    "\n",
    "    # Check if the file already exists on S3\n",
    "    s3_client = boto3.client('s3')\n",
    "    if run_mode != 'test':\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=s3_bucket_name, Key=s3_output_path)\n",
    "            logging.info(f\"{s3_output_path} already exists on S3. Skipping processing.\")\n",
    "            return\n",
    "        except:\n",
    "            logging.info(f\"{s3_output_path} does not exist on S3. Processing the tile.\")\n",
    "\n",
    "    logging.info(f\"Starting processing of the tile {tile_id}\")\n",
    "\n",
    "    s3_input_path = f'/vsis3/{s3_bucket_name}/{tile_key}'\n",
    "\n",
    "    try:\n",
    "        with rasterio.Env(AWS_SESSION=boto3.Session()):\n",
    "            with rasterio.open(s3_input_path) as src:\n",
    "                target_resolution = 1000\n",
    "\n",
    "                resampled_data, resampled_profile = resample_raster(src, target_resolution)\n",
    "                masked_data, masked_profile = mask_raster(resampled_data[0], resampled_profile)\n",
    "                fishnet_gdf = create_fishnet_from_raster(masked_data, resampled_profile['transform'])\n",
    "                fishnet_gdf = reproject_gdf(fishnet_gdf, 5070)\n",
    "                features_gdf = read_tiled_features(tile_id, feature_type)\n",
    "                fishnet_with_lengths = assign_segments_to_cells(fishnet_gdf, features_gdf)\n",
    "                fishnet_with_density = convert_length_to_density(fishnet_with_lengths, fishnet_gdf.crs)\n",
    "                fishnet_to_raster(fishnet_with_density, masked_profile, local_output_path)\n",
    "\n",
    "                logging.info(f\"Saved {local_output_path}\")\n",
    "\n",
    "                # Resample to 30 meters\n",
    "                reference_path = f'/vsis3/{s3_bucket_name}/{tile_key}'\n",
    "                local_30m_output_path = os.path.join(local_temp_dir, os.path.basename(local_output_path))\n",
    "                resample_to_30m(local_output_path, local_30m_output_path, reference_path)\n",
    "\n",
    "                if run_mode == 'test':\n",
    "                    logging.info(f\"Test mode: Outputs saved locally at {local_output_path} and {local_30m_output_path}\")\n",
    "                else:\n",
    "                    logging.info(f\"Uploading {local_output_path} to s3://{s3_bucket_name}/{s3_output_path}\")\n",
    "                    s3_client.upload_file(local_output_path, s3_bucket_name, s3_output_path)\n",
    "\n",
    "                    logging.info(f\"Uploading {local_30m_output_path} to s3://{s3_bucket_name}/{s3_output_path}\")\n",
    "                    s3_client.upload_file(local_30m_output_path, s3_bucket_name, s3_output_path)\n",
    "\n",
    "                    logging.info(f\"Uploaded {local_output_path} and {local_30m_output_path} to s3://{s3_bucket_name}/{s3_output_path}\")\n",
    "                    os.remove(local_output_path)\n",
    "                    os.remove(local_30m_output_path)\n",
    "\n",
    "                del resampled_data, masked_data, fishnet_gdf, features_gdf, fishnet_with_lengths, fishnet_with_density\n",
    "                gc.collect()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing tile {tile_id}: {e}\")\n",
    "\n",
    "def process_all_tiles(feature_type, run_mode='default'):\n",
    "    paginator = boto3.client('s3').get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=s3_bucket_name, Prefix=s3_tiles_prefix)\n",
    "    tile_keys = []\n",
    "\n",
    "    for page in page_iterator:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                tile_key = obj['Key']\n",
    "                if tile_key.endswith('_peat_mask_processed.tif'):\n",
    "                    tile_keys.append(tile_key)\n",
    "\n",
    "    dask_tiles = [dask.delayed(process_tile)(tile_key, feature_type, run_mode) for tile_key in tile_keys]\n",
    "    with ProgressBar():\n",
    "        dask.compute(*dask_tiles)\n",
    "\n",
    "def main(tile_id=None, feature_type='osm_roads', run_mode='default'):\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "\n",
    "    try:\n",
    "        if tile_id:\n",
    "            tile_key = f\"{s3_tiles_prefix}{tile_id}_peat_mask_processed.tif\"\n",
    "            process_tile(tile_key, feature_type, run_mode)\n",
    "        else:\n",
    "            process_all_tiles(feature_type, run_mode)\n",
    "\n",
    "        if run_mode != 'test':\n",
    "            compress_and_upload_directory_to_s3(output_directories[feature_type]['local'], s3_bucket_name, output_directories[feature_type]['s3'])\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace '00N_110E' with the tile ID you want to test\n",
    "\n",
    "    tile_id = '00N_110E'\n",
    "    run_mode = 'default'\n",
    "    \n",
    "    main(tile_id, feature_type='osm_canals')\n",
    "    # main(tile_id, feature_type='osm_roads')\n",
    "    # main(tile_id, feature_type='grip_roads')\n",
    "\n",
    "    # Process roads and canals separately\n",
    "    # main(feature_type='osm_roads', run_mode='default')\n",
    "    # main(feature_type='osm_canals', run_mode='default')\n",
    "    # main(feature_type='grip_roads', run_mode='default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f95c40-12f2-4710-a095-499237d7482b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
